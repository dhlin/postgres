<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>executor/nodeHash.c - pgsql17devel-backend</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

.nav-bar {
    font-size: 120%;
    margin-top: 5px;
    margin-bottom: 5px;
}

.nav-link {
    padding-left: 5em;
    padding-right: 5em;
}

ul.toc {
    line-height: 200%;
    font-size: 150%;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}

span.Constant {
    color: DarkGreen;
}

span.Special {
    color: #c06000;
}

span.Comment {
    color: DarkRed;
    font-style: italic;
}

span.Identifier {
    color: DarkCyan;
}

span.PreProc {
    color: DarkMagenta;
}

span.Statement, span.Type, span.Keyword, span.Repeat, span.Conditional,
    span.Operator, span.Exception
{
    color: DarkBlue;
}

span.Todo {
    color: DarkRed;
    background-color: Gold;
    font-style: italic;
}

span.Underlined {
    text-decoration: underline;
}

span.linkable {
    font-weight: bold;
}

code ol {
    counter-reset: item;
    list-style-type: none;
    margin-left: 0;
    padding-left: 0;
    list-style-position: inside;
}

code li {
    display: block;
}

code li:before {
    content: counter(item) "  ";
    counter-increment: item;
    color: #999;
    padding-right: 0.5em;
    padding-left: 0.4em;
    list-style-position: inside;
    text-align: right
}

  </style>
 </head>
 <body>
 <p class="nav-bar">
  <span class="nav-link"><a href="./index.html">One Level Up</a></span>
  <span class="nav-link"><a href="../index.html">Top Level</a></span>
 </p>

  <h1>executor/nodeHash.c - pgsql17devel-backend</h1>
 <h2>Functions defined</h2>
 <ul class="toc">
<li><a href="#L675">ExecChooseHashTableSize</a></li>
<li><a href="#L413">ExecEndHash</a></li>
<li><a href="#L91">ExecHash</a></li>
<li><a href="#L2850">ExecHashAccumInstrumentation</a></li>
<li><a href="#L2375">ExecHashBuildSkewHash</a></li>
<li><a href="#L2734">ExecHashEstimate</a></li>
<li><a href="#L1932">ExecHashGetBucketAndBatch</a></li>
<li><a href="#L1824">ExecHashGetHashValue</a></li>
<li><a href="#L2528">ExecHashGetSkewBucket</a></li>
<li><a href="#L916">ExecHashIncreaseNumBatches</a></li>
<li><a href="#L1462">ExecHashIncreaseNumBuckets</a></li>
<li><a href="#L2753">ExecHashInitializeDSM</a></li>
<li><a href="#L2778">ExecHashInitializeWorker</a></li>
<li><a href="#L2620">ExecHashRemoveNextSkewBucket</a></li>
<li><a href="#L2819">ExecHashRetrieveInstrumentation</a></li>
<li><a href="#L2574">ExecHashSkewTableInsert</a></li>
<li><a href="#L432">ExecHashTableCreate</a></li>
<li><a href="#L883">ExecHashTableDestroy</a></li>
<li><a href="#L3374">ExecHashTableDetach</a></li>
<li><a href="#L3282">ExecHashTableDetachBatch</a></li>
<li><a href="#L1624">ExecHashTableInsert</a></li>
<li><a href="#L2299">ExecHashTableReset</a></li>
<li><a href="#L2327">ExecHashTableResetMatchFlags</a></li>
<li><a href="#L360">ExecInitHash</a></li>
<li><a href="#L3177">ExecParallelHashCloseBatchAccessors</a></li>
<li><a href="#L3198">ExecParallelHashEnsureBatchAccessors</a></li>
<li><a href="#L3424">ExecParallelHashFirstTuple</a></li>
<li><a href="#L1080">ExecParallelHashIncreaseNumBatches</a></li>
<li><a href="#L1525">ExecParallelHashIncreaseNumBuckets</a></li>
<li><a href="#L3097">ExecParallelHashJoinSetUpBatches</a></li>
<li><a href="#L1432">ExecParallelHashMergeCounters</a></li>
<li><a href="#L3440">ExecParallelHashNextTuple</a></li>
<li><a href="#L3493">ExecParallelHashPopChunkQueue</a></li>
<li><a href="#L3454">ExecParallelHashPushTuple</a></li>
<li><a href="#L1305">ExecParallelHashRepartitionFirst</a></li>
<li><a href="#L1372">ExecParallelHashRepartitionRest</a></li>
<li><a href="#L3262">ExecParallelHashTableAlloc</a></li>
<li><a href="#L1714">ExecParallelHashTableInsert</a></li>
<li><a href="#L1780">ExecParallelHashTableInsertCurrentBatch</a></li>
<li><a href="#L3472">ExecParallelHashTableSetCurrentBatch</a></li>
<li><a href="#L2949">ExecParallelHashTupleAlloc</a></li>
<li><a href="#L3534">ExecParallelHashTuplePrealloc</a></li>
<li><a href="#L2097">ExecParallelPrepHashTableForUnmatched</a></li>
<li><a href="#L2025">ExecParallelScanHashBucket</a></li>
<li><a href="#L2236">ExecParallelScanHashTableForUnmatched</a></li>
<li><a href="#L2076">ExecPrepHashTableForUnmatched</a></li>
<li><a href="#L2353">ExecReScanHash</a></li>
<li><a href="#L1964">ExecScanHashBucket</a></li>
<li><a href="#L2162">ExecScanHashTableForUnmatched</a></li>
<li><a href="#L2804">ExecShutdownHash</a></li>
<li><a href="#L105">MultiExecHash</a></li>
<li><a href="#L214">MultiExecParallelHash</a></li>
<li><a href="#L138">MultiExecPrivateHash</a></li>
<li><a href="#L2869">dense_alloc</a></li>
<li><a href="#L3595">get_hash_memory_limit</a></li>
</ul>
 <h2>Macros defined</h2>
 <ul class="toc">
<li><a href="#L672">NTUP_PER_BUCKET</a></li>
</ul>
 <h2>Source code</h2>

  <code><ol><li><span class="Comment">/*-------------------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * nodeHash.c<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; Routines to <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> relations for hashjoin<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group<br/></li>
<li></span><span class="Comment"> * Portions Copyright (c) 1994, Regents of the University of California<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * IDENTIFICATION<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; src/backend/executor/nodeHash.c<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * See note on parallelism in nodeHashjoin.c.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *-------------------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * INTERFACE ROUTINES<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L105" title="executor/nodeHash.c:105">MultiExecHash</a>&nbsp; &nbsp; - generate an in-memory <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table of the relation<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L360" title="executor/nodeHash.c:360">ExecInitHash</a>&nbsp; &nbsp; - <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a> node and subnodes<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L413" title="executor/nodeHash.c:413">ExecEndHash</a>&nbsp; &nbsp; &nbsp; &nbsp; - shutdown node and subnodes<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><br/></li>
<li><span class="PreProc">#include </span><span class="Constant">&quot;postgres.h&quot;<br/></li>
<li></span><br/></li>
<li><span class="PreProc">#include </span><span class="Constant">&lt;math.h&gt;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&lt;limits.h&gt;<br/></li>
<li></span><br/></li>
<li><span class="PreProc">#include </span><span class="Constant">&quot;access/htup_details.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;access/parallel.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;catalog/pg_statistic.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;commands/tablespace.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;executor/executor.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;executor/hashjoin.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;executor/nodeHash.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;executor/nodeHashjoin.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;miscadmin.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;port/atomics.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;port/pg_bitutils.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/dynahash.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/lsyscache.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/memutils.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/syscache.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/wait_event.h&quot;<br/></li>
<li></span><br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L916" title="executor/nodeHash.c:916">ExecHashIncreaseNumBatches</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1462" title="executor/nodeHash.c:1462">ExecHashIncreaseNumBuckets</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1080" title="executor/nodeHash.c:1080">ExecParallelHashIncreaseNumBatches</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1525" title="executor/nodeHash.c:1525">ExecParallelHashIncreaseNumBuckets</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L2375" title="executor/nodeHash.c:2375">ExecHashBuildSkewHash</a>(HashJoinTable hashtable, Hash *node,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> mcvsToUse);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L2574" title="executor/nodeHash.c:2574">ExecHashSkewTableInsert</a>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *slot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32 hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> bucketNumber);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L2620" title="executor/nodeHash.c:2620">ExecHashRemoveNextSkewBucket</a>(HashJoinTable hashtable);<br/></li>
<li><br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> *<a href="#L2869" title="executor/nodeHash.c:2869">dense_alloc</a>(HashJoinTable hashtable, Size size);<br/></li>
<li><span class="Type">static</span> HashJoinTuple <a href="#L2949" title="executor/nodeHash.c:2949">ExecParallelHashTupleAlloc</a>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span> size,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer *shared);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L138" title="executor/nodeHash.c:138">MultiExecPrivateHash</a>(HashState *node);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L214" title="executor/nodeHash.c:214">MultiExecParallelHash</a>(HashState *node);<br/></li>
<li><span class="Type">static</span> <span class="Type">inline</span> HashJoinTuple <a href="#L3424" title="executor/nodeHash.c:3424">ExecParallelHashFirstTuple</a>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type">int</span> bucketno);<br/></li>
<li><span class="Type">static</span> <span class="Type">inline</span> HashJoinTuple <a href="#L3440" title="executor/nodeHash.c:3440">ExecParallelHashNextTuple</a>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple tuple);<br/></li>
<li><span class="Type">static</span> <span class="Type">inline</span> <span class="Type">void</span> <a href="#L3454" title="executor/nodeHash.c:3454">ExecParallelHashPushTuple</a>(dsa_pointer_atomic *head,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HashJoinTuple tuple,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; dsa_pointer tuple_shared);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L3097" title="executor/nodeHash.c:3097">ExecParallelHashJoinSetUpBatches</a>(HashJoinTable hashtable, <span class="Type">int</span> nbatch);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1305" title="executor/nodeHash.c:1305">ExecParallelHashRepartitionFirst</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1372" title="executor/nodeHash.c:1372">ExecParallelHashRepartitionRest</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> HashMemoryChunk <a href="#L3493" title="executor/nodeHash.c:3493">ExecParallelHashPopChunkQueue</a>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; dsa_pointer *shared);<br/></li>
<li><span class="Type">static</span> <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> <a href="#L3534" title="executor/nodeHash.c:3534">ExecParallelHashTuplePrealloc</a>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> batchno,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span> size);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1432" title="executor/nodeHash.c:1432">ExecParallelHashMergeCounters</a>(HashJoinTable hashtable);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L3177" title="executor/nodeHash.c:3177">ExecParallelHashCloseBatchAccessors</a>(HashJoinTable hashtable);<br/></li>
<li><br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L91" title="executor/nodeHash.c:91">ExecHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; stub for pro forma compliance<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> TupleTableSlot *<br/></li>
<li><a id="L91">&#x200c;</a><span class="linkable">ExecHash</span>(PlanState *pstate)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; elog(ERROR, <span class="Constant">&quot;Hash node does not support ExecProcNode call convention&quot;</span>);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">NULL</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L105" title="executor/nodeHash.c:105">MultiExecHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; build <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table for hashjoin, doing partitioning if more<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; than one batch is required.<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span>Node *<br/></li>
<li><a id="L105">&#x200c;</a><span class="linkable">MultiExecHash</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* must provide our own instrumentation support */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (node-&gt;ps.instrument)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="instrument.c.html#L68" title="executor/instrument.c:68">InstrStartNode</a>(node-&gt;ps.instrument);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (node-&gt;parallel_state != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L214" title="executor/nodeHash.c:214">MultiExecParallelHash</a>(node);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L138" title="executor/nodeHash.c:138">MultiExecPrivateHash</a>(node);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* must provide our own instrumentation support */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (node-&gt;ps.instrument)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="instrument.c.html#L84" title="executor/instrument.c:84">InstrStopNode</a>(node-&gt;ps.instrument, node-&gt;hashtable-&gt;partialTuples);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We do not return the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table directly because it's not a subtype of<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Node, and so would violate the <a href="execProcnode.c.html#L502" title="executor/execProcnode.c:502">MultiExecProcNode</a> API.&nbsp; Instead, our<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parent Hashjoin node is expected to know how to fish it out of our node<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * state.&nbsp; Ugly but not really worth cleaning up, since Hashjoin knows<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * quite a <a href="../utils/adt/varbit.c.html#L391" title="utils/adt/varbit.c:391">bit</a> more about Hash besides that.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">NULL</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L138" title="executor/nodeHash.c:138">MultiExecPrivateHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; parallel-oblivious version, building a backend-private<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table and (if necessary) batch files.<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L138">&#x200c;</a></span><span class="linkable">MultiExecPrivateHash</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; PlanState&nbsp; *outerNode;<br/></li>
<li>&nbsp; &nbsp; List&nbsp; &nbsp; &nbsp;&nbsp; *hashkeys;<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable;<br/></li>
<li>&nbsp; &nbsp; TupleTableSlot *slot;<br/></li>
<li>&nbsp; &nbsp; ExprContext *econtext;<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * get state info from node<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; outerNode = outerPlanState(node);<br/></li>
<li>&nbsp; &nbsp; hashtable = node-&gt;hashtable;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * set expression context<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashkeys = node-&gt;hashkeys;<br/></li>
<li>&nbsp; &nbsp; econtext = node-&gt;ps.ps_ExprContext;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Get all tuples from the node below the Hash node and insert into the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table (or temp files).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (;;)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; slot = ExecProcNode(outerNode);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (TupIsNull(slot))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* We have to compute the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; econtext-&gt;ecxt_outertuple = slot;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="#L1824" title="executor/nodeHash.c:1824">ExecHashGetHashValue</a>(hashtable, econtext, hashkeys,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>, hashtable-&gt;keepNulls,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;hashvalue))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketNumber;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketNumber = <a href="#L2528" title="executor/nodeHash.c:2528">ExecHashGetSkewBucket</a>(hashtable, hashvalue);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (bucketNumber != INVALID_SKEW_BUCKET_NO)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* It's a skew tuple, so put it into that <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L2574" title="executor/nodeHash.c:2574">ExecHashSkewTableInsert</a>(hashtable, slot, hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketNumber);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewTuples += <span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Not subject to skew optimization, so insert normally */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1624" title="executor/nodeHash.c:1624">ExecHashTableInsert</a>(hashtable, slot, hashvalue);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;totalTuples += <span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* <a href="../lib/dshash.c.html#L858" title="lib/dshash.c:858">resize</a> the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table if needed (<a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a> exceeded) */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbuckets != hashtable-&gt;nbuckets_optimal)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1462" title="executor/nodeHash.c:1462">ExecHashIncreaseNumBuckets</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Account for the buckets in spaceUsed (reported in EXPLAIN ANALYZE) */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;spaceUsed += hashtable-&gt;nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed &gt; hashtable-&gt;spacePeak)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak = hashtable-&gt;spaceUsed;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;partialTuples = hashtable-&gt;totalTuples;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L214" title="executor/nodeHash.c:214">MultiExecParallelHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; parallel-aware version, building a shared <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table and<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; (if necessary) batch files using the combined effort of<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; a set of co-operating backends.<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L214">&#x200c;</a></span><span class="linkable">MultiExecParallelHash</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate;<br/></li>
<li>&nbsp; &nbsp; PlanState&nbsp; *outerNode;<br/></li>
<li>&nbsp; &nbsp; List&nbsp; &nbsp; &nbsp;&nbsp; *hashkeys;<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable;<br/></li>
<li>&nbsp; &nbsp; TupleTableSlot *slot;<br/></li>
<li>&nbsp; &nbsp; ExprContext *econtext;<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue;<br/></li>
<li>&nbsp; &nbsp; Barrier&nbsp; &nbsp; *build_barrier;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * get state info from node<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; outerNode = outerPlanState(node);<br/></li>
<li>&nbsp; &nbsp; hashtable = node-&gt;hashtable;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * set expression context<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashkeys = node-&gt;hashkeys;<br/></li>
<li>&nbsp; &nbsp; econtext = node-&gt;ps.ps_ExprContext;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Synchronize the parallel <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table build.&nbsp; At this stage we know that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * the shared <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table has been or is being set up by<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="#L432" title="executor/nodeHash.c:432">ExecHashTableCreate</a>(), but we don't know if our peers have returned<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * from there or are here in <a href="#L214" title="executor/nodeHash.c:214">MultiExecParallelHash</a>(), and if so how far<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * through they are.&nbsp; To <a href="../regex/regexec.c.html#L419" title="regex/regexec.c:419">find</a> out, we check the build_barrier phase then<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * and jump to the right step in the build algorithm.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; build_barrier = &amp;pstate-&gt;build_barrier;<br/></li>
<li>&nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier) &gt;= PHJ_BUILD_ALLOCATE);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">switch</span> (<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_BUILD_ALLOCATE:<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Either I just allocated the initial <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L432" title="executor/nodeHash.c:432">ExecHashTableCreate</a>(), or someone else is doing that.&nbsp; Either<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * way, wait for everyone to arrive here so we can proceed.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(build_barrier, WAIT_EVENT_HASH_BUILD_ALLOCATE);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_BUILD_HASH_INNER:<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * It's time to begin hashing, or if we just arrived here then<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * hashing is already underway, so join in that effort.&nbsp; While<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * hashing we have to be prepared to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> increase the number of<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * batches or buckets at <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> time, and if we arrived here when<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * that was already underway we'll have to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> complete that work<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * immediately so that it's safe to access batches and buckets<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * below.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (PHJ_GROW_BATCHES_PHASE(<a href="../storage/ipc/barrier.c.html#L236" title="storage/ipc/barrier.c:236">BarrierAttach</a>(&amp;pstate-&gt;grow_batches_barrier)) !=<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PHJ_GROW_BATCHES_ELECT)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1080" title="executor/nodeHash.c:1080">ExecParallelHashIncreaseNumBatches</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (PHJ_GROW_BUCKETS_PHASE(<a href="../storage/ipc/barrier.c.html#L236" title="storage/ipc/barrier.c:236">BarrierAttach</a>(&amp;pstate-&gt;grow_buckets_barrier)) !=<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PHJ_GROW_BUCKETS_ELECT)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1525" title="executor/nodeHash.c:1525">ExecParallelHashIncreaseNumBuckets</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3472" title="executor/nodeHash.c:3472">ExecParallelHashTableSetCurrentBatch</a>(hashtable, <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (;;)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; slot = ExecProcNode(outerNode);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (TupIsNull(slot))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; econtext-&gt;ecxt_outertuple = slot;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="#L1824" title="executor/nodeHash.c:1824">ExecHashGetHashValue</a>(hashtable, econtext, hashkeys,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>, hashtable-&gt;keepNulls,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;hashvalue))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1714" title="executor/nodeHash.c:1714">ExecParallelHashTableInsert</a>(hashtable, slot, hashvalue);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;partialTuples++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Make sure that <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> tuples we wrote to disk are visible to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * others <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> anyone tries to load them.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L213" title="utils/sort/sharedtuplestore.c:213">sts_end_write</a>(hashtable-&gt;batches[i].inner_tuples);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Update shared counters.&nbsp; We need an accurate total tuple count<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * to control the empty table optimization.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1432" title="executor/nodeHash.c:1432">ExecParallelHashMergeCounters</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L256" title="storage/ipc/barrier.c:256">BarrierDetach</a>(&amp;pstate-&gt;grow_buckets_barrier);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L256" title="storage/ipc/barrier.c:256">BarrierDetach</a>(&amp;pstate-&gt;grow_batches_barrier);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Wait for everyone to finish building and flushing files and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * counters.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(build_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_BUILD_HASH_INNER))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Elect one backend to disable <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> further growth.&nbsp; Batches<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * are <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a> fixed.&nbsp; While building them we made sure they'd fit<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * in our memory budget when we load them back in later (or we<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * tried to do that and gave up because we detected extreme<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * skew).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_DISABLED;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We're not yet attached to a batch.&nbsp; We all agree on the dimensions and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * number of inner tuples (for the empty table optimization).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;curbatch = -<span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbuckets = pstate-&gt;nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;log2_nbuckets = <a href="../utils/hash/dynahash.c.html#L1751" title="utils/hash/dynahash.c:1751">my_log2</a>(hashtable-&gt;nbuckets);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;totalTuples = pstate-&gt;total_tuples;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Unless we're completely done and the batch state has been freed, make<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * sure we have accessors.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier) &lt; PHJ_BUILD_FREE)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * The <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> synchronization point is in <a href="nodeHashjoin.c.html#L677" title="executor/nodeHashjoin.c:677">ExecHashJoin</a>'s <a href="nodeHashjoin.c.html#L179" title="executor/nodeHashjoin.c:179">HJ_BUILD_HASHTABLE</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * case, which will bring the build phase to PHJ_BUILD_RUN (if it isn't<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * there already).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier) == PHJ_BUILD_HASH_OUTER ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier) == PHJ_BUILD_RUN ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier) == PHJ_BUILD_FREE);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L360" title="executor/nodeHash.c:360">ExecInitHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Init routine for Hash node<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span>HashState *<br/></li>
<li><a id="L360">&#x200c;</a><span class="linkable">ExecInitHash</span>(Hash *node, EState *estate, <span class="Type">int</span> eflags)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashState&nbsp; *hashstate;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* check for unsupported flags */<br/></li>
<li></span>&nbsp; &nbsp; Assert(!(eflags &amp; (EXEC_FLAG_BACKWARD | EXEC_FLAG_MARK)));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * create state structure<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashstate = makeNode(HashState);<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;ps.plan = (Plan *) node;<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;ps.state = estate;<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;ps.ExecProcNode = <a href="#L91" title="executor/nodeHash.c:91">ExecHash</a>;<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;hashtable = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;hashkeys = NIL;&nbsp; &nbsp; <span class="Comment">/* will be set by parent HashJoin */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Miscellaneous initialization<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * create expression context for node<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="execUtils.c.html#L483" title="executor/execUtils.c:483">ExecAssignExprContext</a>(estate, &amp;hashstate-&gt;ps);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a> child nodes<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; outerPlanState(hashstate) = <a href="execProcnode.c.html#L142" title="executor/execProcnode.c:142">ExecInitNode</a>(outerPlan(node), estate, eflags);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a> our result slot and type. No need to build projection<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * because this node doesn't do projections.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="execTuples.c.html#L1886" title="executor/execTuples.c:1886">ExecInitResultTupleSlotTL</a>(&amp;hashstate-&gt;ps, &amp;<a href="execTuples.c.html#L86" title="executor/execTuples.c:86">TTSOpsMinimalTuple</a>);<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;ps.ps_ProjInfo = <span class="Constant">NULL</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a> child expressions<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Assert(node-&gt;plan.qual == NIL);<br/></li>
<li>&nbsp; &nbsp; hashstate-&gt;hashkeys =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="execExpr.c.html#L326" title="executor/execExpr.c:326">ExecInitExprList</a>(node-&gt;hashkeys, (PlanState *) hashstate);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> hashstate;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/* ---------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L413" title="executor/nodeHash.c:413">ExecEndHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; clean up routine for Hash node<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L413">&#x200c;</a></span><span class="linkable">ExecEndHash</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; PlanState&nbsp; *outerPlan;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * shut down the subplan<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; outerPlan = outerPlanState(node);<br/></li>
<li>&nbsp; &nbsp; <a href="execProcnode.c.html#L557" title="executor/execProcnode.c:557">ExecEndNode</a>(outerPlan);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L432" title="executor/nodeHash.c:432">ExecHashTableCreate</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; create an empty hashtable data structure for hashjoin.<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span>HashJoinTable<br/></li>
<li><a id="L432">&#x200c;</a><span class="linkable">ExecHashTableCreate</span>(HashState *state, List *hashOperators, List *hashCollations, <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> keepNulls)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; Hash&nbsp; &nbsp; &nbsp;&nbsp; *node;<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable;<br/></li>
<li>&nbsp; &nbsp; Plan&nbsp; &nbsp; &nbsp;&nbsp; *outerNode;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; space_allowed;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbuckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbatch;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; rows;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_skew_mcvs;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log2_nbuckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nkeys;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li>&nbsp; &nbsp; ListCell&nbsp;&nbsp; *ho;<br/></li>
<li>&nbsp; &nbsp; ListCell&nbsp;&nbsp; *hc;<br/></li>
<li>&nbsp; &nbsp; MemoryContext oldcxt;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Get information about the size of the relation to be hashed (it's the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * &quot;outer&quot; subtree of this node, but the inner relation of the hashjoin).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Compute the appropriate size of the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; node = (Hash *) state-&gt;ps.plan;<br/></li>
<li>&nbsp; &nbsp; outerNode = outerPlan(node);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If this is shared <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table with a partial plan, then we can't use<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * outerNode-&gt;plan_rows to estimate its size.&nbsp; We need an estimate of the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * total number of rows across all copies of the partial plan.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; rows = node-&gt;plan.parallel_aware ? node-&gt;rows_total : outerNode-&gt;plan_rows;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="#L675" title="executor/nodeHash.c:675">ExecChooseHashTableSize</a>(rows, outerNode-&gt;plan_width,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; OidIsValid(node-&gt;skewTable),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state-&gt;parallel_state != <span class="Constant">NULL</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state-&gt;parallel_state != <span class="Constant">NULL</span> ?<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state-&gt;parallel_state-&gt;nparticipants - <span class="Constant">1</span> : <span class="Constant">0</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;space_allowed,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;nbuckets, &amp;nbatch, &amp;num_skew_mcvs);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* nbuckets must be a power of 2 */<br/></li>
<li></span>&nbsp; &nbsp; log2_nbuckets = <a href="../utils/hash/dynahash.c.html#L1751" title="utils/hash/dynahash.c:1751">my_log2</a>(nbuckets);<br/></li>
<li>&nbsp; &nbsp; Assert(nbuckets == (<span class="Constant">1</span> &lt;&lt; log2_nbuckets));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Initialize the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table control block.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * The hashtable control block is just <a href="../utils/mmgr/mcxt.c.html#L1316" title="utils/mmgr/mcxt.c:1316">palloc</a>'d from the executor's<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * per-query memory context.&nbsp; Everything else should be kept inside the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * subsidiary hashCxt, batchCxt or spillCxt.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashtable = palloc_object(HashJoinTableData);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbuckets = nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbuckets_original = nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbuckets_optimal = nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;log2_nbuckets = log2_nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;log2_nbuckets_optimal = log2_nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;buckets.unshared = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;keepNulls = keepNulls;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;skewEnabled = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;skewBucket = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;skewBucketLen = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nSkewBuckets = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;skewBucketNums = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbatch = nbatch;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;curbatch = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbatch_original = nbatch;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbatch_outstart = nbatch;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;growEnabled = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;totalTuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;partialTuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;skewTuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;innerBatchFile = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;outerBatchFile = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceUsed = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spacePeak = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceAllowed = space_allowed;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceUsedSkew = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceAllowedSkew =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceAllowed * SKEW_HASH_MEM_PERCENT / <span class="Constant">100</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;chunks = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;current_chunk = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;parallel_state = state-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;area = state-&gt;ps.state-&gt;es_query_dsa;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches = <span class="Constant">NULL</span>;<br/></li>
<li><br/></li>
<li><span class="PreProc">#ifdef HJDEBUG<br/></li>
<li></span>&nbsp; &nbsp; printf(<span class="Constant">&quot;Hashjoin </span><span class="Special">%p</span><span class="Constant">: initial nbatch = </span><span class="Special">%d</span><span class="Constant">, nbuckets = </span><span class="Special">%d\n</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable, nbatch, nbuckets);<br/></li>
<li><span class="PreProc">#endif<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Create temporary memory contexts in which to keep the hashtable working<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * storage.&nbsp; See notes in executor/hashjoin.h.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;hashCxt = AllocSetContextCreate(<a href="../utils/mmgr/mcxt.c.html#L143" title="utils/mmgr/mcxt.c:143">CurrentMemoryContext</a>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">&quot;HashTableContext&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ALLOCSET_DEFAULT_SIZES);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batchCxt = AllocSetContextCreate(hashtable-&gt;hashCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Constant">&quot;HashBatchContext&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ALLOCSET_DEFAULT_SIZES);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spillCxt = AllocSetContextCreate(hashtable-&gt;hashCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Constant">&quot;HashSpillContext&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ALLOCSET_DEFAULT_SIZES);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Allocate data that will live for the life of the hashjoin */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; oldcxt = MemoryContextSwitchTo(hashtable-&gt;hashCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Get info about the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> <a href="../regex/regcomp.c.html#L356" title="regex/regcomp.c:356">functions</a> to be used for each <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> key. Also<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * remember whether the join operators are strict.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; nkeys = list_length(hashOperators);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;outer_hashfunctions = palloc_array(FmgrInfo, nkeys);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;inner_hashfunctions = palloc_array(FmgrInfo, nkeys);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;hashStrict = palloc_array(<span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>, nkeys);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;collations = palloc_array(Oid, nkeys);<br/></li>
<li>&nbsp; &nbsp; i = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; forboth(ho, hashOperators, hc, hashCollations)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Oid&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashop = lfirst_oid(ho);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Oid&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; left_hashfn;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Oid&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; right_hashfn;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (!<a href="../utils/cache/lsyscache.c.html#L510" title="utils/cache/lsyscache.c:510">get_op_hash_functions</a>(hashop, &amp;left_hashfn, &amp;right_hashfn))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elog(ERROR, <span class="Constant">&quot;could not <a href="../regex/regexec.c.html#L419" title="regex/regexec.c:419">find</a> <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> function for <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> operator </span><span class="Special">%u</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashop);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/fmgr/fmgr.c.html#L127" title="utils/fmgr/fmgr.c:127">fmgr_info</a>(left_hashfn, &amp;hashtable-&gt;outer_hashfunctions[i]);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/fmgr/fmgr.c.html#L127" title="utils/fmgr/fmgr.c:127">fmgr_info</a>(right_hashfn, &amp;hashtable-&gt;inner_hashfunctions[i]);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;hashStrict[i] = <a href="../utils/cache/lsyscache.c.html#L1477" title="utils/cache/lsyscache.c:1477">op_strict</a>(hashop);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;collations[i] = lfirst_oid(hc);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; i++;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (nbatch &gt; <span class="Constant">1</span> &amp;&amp; hashtable-&gt;parallel_state == <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MemoryContext oldctx;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * allocate and <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a> the file arrays in hashCxt (not needed for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * parallel case which uses shared tuplestores instead of raw files)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; oldctx = MemoryContextSwitchTo(hashtable-&gt;spillCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;innerBatchFile = palloc0_array(<a href="../storage/file/buffile.c.html#L70" title="storage/file/buffile.c:70">BufFile</a> *, nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;outerBatchFile = palloc0_array(<a href="../storage/file/buffile.c.html#L70" title="storage/file/buffile.c:70">BufFile</a> *, nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MemoryContextSwitchTo(oldctx);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* The files will not be opened until needed... */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* ... but make sure we have temp tablespaces established for them */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../commands/tablespace.c.html#L1331" title="commands/tablespace.c:1331">PrepareTempTablespaces</a>();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; MemoryContextSwitchTo(oldcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;parallel_state)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Barrier&nbsp; &nbsp; *build_barrier;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Attach to the build barrier.&nbsp; The corresponding detach operation is<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * in <a href="#L3374" title="executor/nodeHash.c:3374">ExecHashTableDetach</a>.&nbsp; Note that we won't attach to the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * batch_barrier for batch 0 yet.&nbsp; We'll attach later and start it out<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * in PHJ_BATCH_PROBE phase, because batch 0 is allocated up front and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * then loaded while hashing (the standard hybrid <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> join<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * algorithm), and we'll coordinate that using build_barrier.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; build_barrier = &amp;pstate-&gt;build_barrier;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L236" title="storage/ipc/barrier.c:236">BarrierAttach</a>(build_barrier);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * So far we have no idea whether there are <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> other participants,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * and if so, what phase they are working on.&nbsp; The only thing we care<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * about at this point is whether someone has already created the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * SharedHashJoinBatch objects and the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table for batch 0.&nbsp; One<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * backend will be elected to do that <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a> if necessary.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(build_barrier) == PHJ_BUILD_ELECT &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(build_barrier, WAIT_EVENT_HASH_BUILD_ELECT))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;nbatch = nbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;space_allowed = space_allowed;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_OK;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Set up the shared state for coordinating batches. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3097" title="executor/nodeHash.c:3097">ExecParallelHashJoinSetUpBatches</a>(hashtable, nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Allocate batch 0's <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table up front so we can load it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * directly while hashing.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;nbuckets = nbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3262" title="executor/nodeHash.c:3262">ExecParallelHashTableAlloc</a>(hashtable, <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * The <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> Parallel Hash synchronization point is in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L214" title="executor/nodeHash.c:214">MultiExecParallelHash</a>(), which will progress it all the way to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * PHJ_BUILD_RUN.&nbsp; The caller must not return control from this<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * executor node between <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a> and then.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Prepare context for the first-scan space allocations; allocate the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * hashbucket array therein, and set each bucket &quot;empty&quot;.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; MemoryContextSwitchTo(hashtable-&gt;batchCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;buckets.unshared = palloc0_array(HashJoinTuple, nbuckets);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Set up for skew optimization, if possible and there's a need for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * more than one batch.&nbsp; (In a one-batch join, there's no point in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * it.)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (nbatch &gt; <span class="Constant">1</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L2375" title="executor/nodeHash.c:2375">ExecHashBuildSkewHash</a>(hashtable, node, num_skew_mcvs);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MemoryContextSwitchTo(oldcxt);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> hashtable;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Compute appropriate size for hashtable given the estimated size of the<br/></li>
<li></span><span class="Comment"> * relation to be hashed (number of rows and average row width).<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * This is exported so that the <a href="../optimizer/plan/planner.c.html#L274" title="optimizer/plan/planner.c:274">planner</a>'s costsize.c can use it.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><br/></li>
<li><span class="Comment">/* Target bucket loading (tuples per bucket) */<br/></li>
<li><a id="L672">&#x200c;</a></span><span class="PreProc">#define <span class="linkable">NTUP_PER_BUCKET</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="Constant">1<br/></li>
<li></span><br/></li>
<li><span class="Type">void<br/></li>
<li><a id="L675">&#x200c;</a></span><span class="linkable">ExecChooseHashTableSize</span>(<span class="Type">double</span> ntuples, <span class="Type">int</span> tupwidth, <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> useskew,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> try_combined_hash_mem,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> parallel_workers,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span> *space_allowed,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> *numbuckets,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> *numbatches,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> *num_skew_mcvs)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tupsize;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; inner_rel_bytes;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; hash_table_bytes;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; bucket_bytes;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; max_pointers;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbatch = <span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbuckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; dbuckets;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Force a plausible relation size if no info */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (ntuples &lt;= <span class="Constant">0.0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ntuples = <span class="Constant">1000.0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Estimate tupsize based on footprint of tuple in hashtable... note this<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * does not allow for <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> <a href="../utils/mmgr/mcxt.c.html#L1316" title="utils/mmgr/mcxt.c:1316">palloc</a> overhead.&nbsp; The manipulations of spaceUsed<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * don't count <a href="../utils/mmgr/mcxt.c.html#L1316" title="utils/mmgr/mcxt.c:1316">palloc</a> overhead either.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; tupsize = HJTUPLE_OVERHEAD +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MAXALIGN(SizeofMinimalTupleHeader) +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MAXALIGN(tupwidth);<br/></li>
<li>&nbsp; &nbsp; inner_rel_bytes = ntuples * tupsize;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Compute in-memory hashtable size limit from GUCs.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hash_table_bytes = <a href="#L3595" title="executor/nodeHash.c:3595">get_hash_memory_limit</a>();<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Parallel Hash tries to use the combined hash_mem of all workers to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * avoid the need to batch.&nbsp; If that won't work, it falls back to hash_mem<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * per worker and tries to process batches in parallel.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (try_combined_hash_mem)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Careful, this could overflow size_t */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; newlimit;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newlimit = (<span class="Type">double</span>) hash_table_bytes * (<span class="Type">double</span>) (parallel_workers + <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newlimit = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(newlimit, (<span class="Type">double</span>) <span class="Constant">SIZE_MAX</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hash_table_bytes = (<span class="Type">size_t</span>) newlimit;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; *space_allowed = hash_table_bytes;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If skew optimization is possible, estimate the number of skew buckets<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * that will fit in the memory allowed, and decrement the assumed space<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * available for the <a href="../storage/lmgr/s_lock.c.html#L257" title="storage/lmgr/s_lock.c:257">main</a> <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table accordingly.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We make the optimistic assumption that each skew bucket will contain<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * one inner-relation tuple.&nbsp; If that turns out to be low, we will recover<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * at runtime by reducing the number of skew buckets.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hashtable-&gt;skewBucket will have up to 8 times as many HashSkewBucket<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * pointers as the number of MCVs we allow, since <a href="#L2375" title="executor/nodeHash.c:2375">ExecHashBuildSkewHash</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * will round up to the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> power of 2 and then multiply by 4 to reduce<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * collisions.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (useskew)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; bytes_per_mcv;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; skew_mcvs;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*----------<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Compute number of MCVs we could hold in hash_table_bytes<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Divisor is:<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * size of a <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> tuple +<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * worst-case size of skewBucket[] per MCV +<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * size of skewBucketNums[] entry +<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * size of skew bucket struct itself<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; *----------<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; bytes_per_mcv = tupsize +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (<span class="Constant">8</span> * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashSkewBucket *)) +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<span class="Type">int</span>) +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; SKEW_BUCKET_OVERHEAD;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; skew_mcvs = hash_table_bytes / bytes_per_mcv;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Now scale by SKEW_HASH_MEM_PERCENT (we do it in this order so as<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * not to worry about size_t overflow in the multiplication)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; skew_mcvs = (skew_mcvs * SKEW_HASH_MEM_PERCENT) / <span class="Constant">100</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Now clamp to integer <a href="../regex/regc_locale.c.html#L412" title="regex/regc_locale.c:412">range</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; skew_mcvs = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(skew_mcvs, <span class="Constant">INT_MAX</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *num_skew_mcvs = (<span class="Type">int</span>) skew_mcvs;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Reduce hash_table_bytes by the amount needed for the skew table */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (skew_mcvs &gt; <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hash_table_bytes -= skew_mcvs * bytes_per_mcv;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; *num_skew_mcvs = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Set nbuckets to achieve an average bucket load of <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a> when<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * memory is filled, assuming a single batch; but limit the value so that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * the pointer arrays we'll try to allocate do not exceed hash_table_bytes<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * nor MaxAllocSize.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Note that both nbuckets and nbatch must be powers of 2 to make<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a> fast.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; max_pointers = hash_table_bytes / <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple);<br/></li>
<li>&nbsp; &nbsp; max_pointers = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(max_pointers, MaxAllocSize / <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple));<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* If max_pointers isn't a power of 2, must round it down to one */<br/></li>
<li></span>&nbsp; &nbsp; max_pointers = pg_prevpower2_size_t(max_pointers);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Also ensure we avoid integer overflow in nbatch and nbuckets */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Comment">/* (this step is redundant given the current value of MaxAllocSize) */<br/></li>
<li></span>&nbsp; &nbsp; max_pointers = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(max_pointers, <span class="Constant">INT_MAX</span> / <span class="Constant">2</span> + <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; dbuckets = ceil(ntuples / <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a>);<br/></li>
<li>&nbsp; &nbsp; dbuckets = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(dbuckets, max_pointers);<br/></li>
<li>&nbsp; &nbsp; nbuckets = (<span class="Type">int</span>) dbuckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* don't let nbuckets be really small, though ... */<br/></li>
<li></span>&nbsp; &nbsp; nbuckets = Max(nbuckets, <span class="Constant">1024</span>);<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* ... and force it to be a power of 2. */<br/></li>
<li></span>&nbsp; &nbsp; nbuckets = pg_nextpower2_32(nbuckets);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If there's not enough space to store the projected number of tuples and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * the required bucket headers, we will need multiple batches.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; bucket_bytes = <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple) * nbuckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (inner_rel_bytes + bucket_bytes &gt; hash_table_bytes)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* We'll need multiple batches */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; sbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; dbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; minbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; bucket_size;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * If Parallel Hash with combined hash_mem would still need multiple<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * batches, we'll have to fall back to regular hash_mem budget.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (try_combined_hash_mem)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L675" title="executor/nodeHash.c:675">ExecChooseHashTableSize</a>(ntuples, tupwidth, useskew,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Constant">false</span>, parallel_workers,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; space_allowed,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; numbuckets,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; numbatches,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_skew_mcvs);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Estimate the number of buckets we'll want to have when hash_mem is<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * entirely full.&nbsp; Each bucket will contain a bucket pointer plus<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a> tuples, whose projected size already includes<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * overhead for the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> code, pointer to the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> tuple, etc.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; bucket_size = (tupsize * <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a> + <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hash_table_bytes &lt;= bucket_size)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sbuckets = <span class="Constant">1</span>;&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* avoid pg_nextpower2_size_t(0) */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sbuckets = pg_nextpower2_size_t(hash_table_bytes / bucket_size);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; sbuckets = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(sbuckets, max_pointers);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; nbuckets = (<span class="Type">int</span>) sbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; nbuckets = pg_nextpower2_32(nbuckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; bucket_bytes = nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Buckets are simple pointers to hashjoin tuples, while tupsize<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * includes the pointer, <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> code, and MinimalTupleData.&nbsp; So buckets<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * should never really exceed 25% of hash_mem (even for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a>=1); except maybe for hash_mem <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a> that are not<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * 2^N bytes, where we might get more because of doubling. So let's<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * look for 50% here.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; Assert(bucket_bytes &lt;= hash_table_bytes / <span class="Constant">2</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Calculate required number of batches. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; dbatch = ceil(inner_rel_bytes / (hash_table_bytes - bucket_bytes));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; dbatch = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(dbatch, max_pointers);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; minbatch = (<span class="Type">int</span>) dbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; nbatch = pg_nextpower2_32(Max(<span class="Constant">2</span>, minbatch));<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(nbuckets &gt; <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; Assert(nbatch &gt; <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; *numbuckets = nbuckets;<br/></li>
<li>&nbsp; &nbsp; *numbatches = nbatch;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><br/></li>
<li><span class="Comment">/* ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L883" title="executor/nodeHash.c:883">ExecHashTableDestroy</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; destroy a <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table<br/></li>
<li></span><span class="Comment"> * ----------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L883">&#x200c;</a></span><span class="linkable">ExecHashTableDestroy</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Make sure all the temp files are closed.&nbsp; We <a href="../regex/regc_lex.c.html#L982" title="regex/regc_lex.c:982">skip</a> batch 0, since it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * can't have <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> temp files (and the arrays might not even exist if<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * nbatch is only 1).&nbsp; Parallel <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> joins don't use these files.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;innerBatchFile != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">1</span>; i &lt; hashtable-&gt;nbatch; i++)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;innerBatchFile[i])<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/file/buffile.c.html#L412" title="storage/file/buffile.c:412">BufFileClose</a>(hashtable-&gt;innerBatchFile[i]);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;outerBatchFile[i])<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/file/buffile.c.html#L412" title="storage/file/buffile.c:412">BufFileClose</a>(hashtable-&gt;outerBatchFile[i]);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Release working memory (batchCxt is a child, so it goes away too) */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L454" title="utils/mmgr/mcxt.c:454">MemoryContextDelete</a>(hashtable-&gt;hashCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* And drop the control block */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(hashtable);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L916" title="executor/nodeHash.c:916">ExecHashIncreaseNumBatches</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; increase the original number of batches in order to reduce<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; current memory consumption<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L916">&#x200c;</a></span><span class="linkable">ExecHashIncreaseNumBatches</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; oldnbatch = hashtable-&gt;nbatch;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; curbatch = hashtable-&gt;curbatch;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbatch;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">long</span>&nbsp; &nbsp; &nbsp; &nbsp; ninmemory;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">long</span>&nbsp; &nbsp; &nbsp; &nbsp; nfreed;<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk oldchunks;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* do nothing if we've decided to shut off growth */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!hashtable-&gt;growEnabled)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* safety check to avoid overflow */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (oldnbatch &gt; <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(<span class="Constant">INT_MAX</span> / <span class="Constant">2</span>, MaxAllocSize / (<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<span class="Type">void</span> *) * <span class="Constant">2</span>)))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; nbatch = oldnbatch * <span class="Constant">2</span>;<br/></li>
<li>&nbsp; &nbsp; Assert(nbatch &gt; <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li><span class="PreProc">#ifdef HJDEBUG<br/></li>
<li></span>&nbsp; &nbsp; printf(<span class="Constant">&quot;Hashjoin </span><span class="Special">%p</span><span class="Constant">: increasing nbatch to </span><span class="Special">%d</span><span class="Constant"> because space = </span><span class="Special">%zu\n</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable, nbatch, hashtable-&gt;spaceUsed);<br/></li>
<li><span class="PreProc">#endif<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;innerBatchFile == <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MemoryContext oldcxt = MemoryContextSwitchTo(hashtable-&gt;spillCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* we had no file arrays <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;innerBatchFile = palloc0_array(<a href="../storage/file/buffile.c.html#L70" title="storage/file/buffile.c:70">BufFile</a> *, nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;outerBatchFile = palloc0_array(<a href="../storage/file/buffile.c.html#L70" title="storage/file/buffile.c:70">BufFile</a> *, nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MemoryContextSwitchTo(oldcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* time to establish the temp tablespaces, too */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../commands/tablespace.c.html#L1331" title="commands/tablespace.c:1331">PrepareTempTablespaces</a>();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* enlarge arrays and zero out added entries */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;innerBatchFile = repalloc0_array(hashtable-&gt;innerBatchFile, <a href="../storage/file/buffile.c.html#L70" title="storage/file/buffile.c:70">BufFile</a> *, oldnbatch, nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;outerBatchFile = repalloc0_array(hashtable-&gt;outerBatchFile, <a href="../storage/file/buffile.c.html#L70" title="storage/file/buffile.c:70">BufFile</a> *, oldnbatch, nbatch);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbatch = nbatch;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Scan through the existing <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table entries and <a href="../regex/regcomp.c.html#L2491" title="regex/regcomp.c:2491">dump</a> out <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> that are<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * no longer of the current batch.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; ninmemory = nfreed = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* If know we need to <a href="../lib/dshash.c.html#L858" title="lib/dshash.c:858">resize</a> nbuckets, we can do it while rebatching. */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbuckets_optimal != hashtable-&gt;nbuckets)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* we never decrease the number of buckets */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; Assert(hashtable-&gt;nbuckets_optimal &gt; hashtable-&gt;nbuckets);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets = hashtable-&gt;nbuckets_optimal;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;log2_nbuckets = hashtable-&gt;log2_nbuckets_optimal;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;buckets.unshared =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; repalloc_array(hashtable-&gt;buckets.unshared,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HashJoinTuple, hashtable-&gt;nbuckets);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We will scan through the chunks directly, so that we can reset the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * buckets <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a> and not have to keep track which tuples in the buckets have<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * already been processed. We will free the old chunks as we go.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; memset(hashtable-&gt;buckets.unshared, <span class="Constant">0</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple) * hashtable-&gt;nbuckets);<br/></li>
<li>&nbsp; &nbsp; oldchunks = hashtable-&gt;chunks;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;chunks = <span class="Constant">NULL</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* so, let's scan through the old chunks, and all tuples in each chunk */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">while</span> (oldchunks != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; HashMemoryChunk nextchunk = oldchunks-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* position within the buffer (up to oldchunks-&gt;used) */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; idx = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* process all tuples stored in this chunk (and then free it) */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (idx &lt; oldchunks-&gt;used)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple hashTuple = (HashJoinTuple) (HASH_CHUNK_DATA(oldchunks) + idx);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; MinimalTuple tuple = HJTUPLE_MINTUPLE(hashTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTupleSize = (HJTUPLE_OVERHEAD + tuple-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ninmemory++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashTuple-&gt;hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;bucketno, &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (batchno == curbatch)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* keep tuple in memory - copy it into the new chunk */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple copyTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple = (HashJoinTuple) <a href="#L2869" title="executor/nodeHash.c:2869">dense_alloc</a>(hashtable, hashTupleSize);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; memcpy(copyTuple, hashTuple, hashTupleSize);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* and add it back to the appropriate bucket */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;buckets.unshared[bucketno];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;buckets.unshared[bucketno] = copyTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* <a href="../regex/regcomp.c.html#L2491" title="regex/regcomp.c:2491">dump</a> it out */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(batchno &gt; curbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="nodeHashjoin.c.html#L1314" title="executor/nodeHashjoin.c:1314">ExecHashJoinSaveTuple</a>(HJTUPLE_MINTUPLE(hashTuple),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple-&gt;hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;hashtable-&gt;innerBatchFile[batchno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsed -= hashTupleSize;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nfreed++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> tuple in this chunk */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; idx += MAXALIGN(hashTupleSize);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allow this loop to be cancellable */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* we're done with this chunk - free it and proceed to the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> one */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(oldchunks);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; oldchunks = nextchunk;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li><span class="PreProc">#ifdef HJDEBUG<br/></li>
<li></span>&nbsp; &nbsp; printf(<span class="Constant">&quot;Hashjoin </span><span class="Special">%p</span><span class="Constant">: freed </span><span class="Special">%ld</span><span class="Constant"> of </span><span class="Special">%ld</span><span class="Constant"> tuples, space <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a> </span><span class="Special">%zu\n</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable, nfreed, ninmemory, hashtable-&gt;spaceUsed);<br/></li>
<li><span class="PreProc">#endif<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If we dumped out either all or <a href="../optimizer/util/predtest.c.html#L1670" title="optimizer/util/predtest.c:1670">none</a> of the tuples in the table, disable<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * further expansion of nbatch.&nbsp; This situation implies that we have<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * enough tuples of identical hashvalues to overflow spaceAllowed.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Increasing nbatch will not fix it since there's no way to subdivide the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * group <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> more finely. We have to just gut it out and hope the server<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * has enough RAM.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (nfreed == <span class="Constant">0</span> || nfreed == ninmemory)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;growEnabled = <span class="Constant">false</span>;<br/></li>
<li><span class="PreProc">#ifdef HJDEBUG<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; printf(<span class="Constant">&quot;Hashjoin </span><span class="Special">%p</span><span class="Constant">: disabling further increase of nbatch</span><span class="Special">\n</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable);<br/></li>
<li><span class="PreProc">#endif<br/></li>
<li></span>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1080" title="executor/nodeHash.c:1080">ExecParallelHashIncreaseNumBatches</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Every participant attached to grow_batches_barrier must run this<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; function when it observes growth == PHJ_GROWTH_NEED_MORE_BATCHES.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1080">&#x200c;</a></span><span class="linkable">ExecParallelHashIncreaseNumBatches</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;build_barrier) == PHJ_BUILD_HASH_INNER);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * It's unlikely, but we need to be prepared for new participants to show<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * up while we're in the middle of this operation so we need to switch on<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * barrier phase here.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">switch</span> (PHJ_GROW_BATCHES_PHASE(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;grow_batches_barrier)))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BATCHES_ELECT:<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Elect one participant to prepare to grow the number of batches.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * This involves reallocating or resetting the buckets of batch 0<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * in preparation for all participants to begin repartitioning the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * tuples.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_batches_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BATCHES_ELECT))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer_atomic *buckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatch *old_batch0;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Move the old batch out of the way. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; old_batch0 = hashtable-&gt;batches[<span class="Constant">0</span>].shared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;old_batches = pstate-&gt;batches;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;old_nbatch = hashtable-&gt;nbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;batches = InvalidDsaPointer;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Free this backend's old accessors. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3177" title="executor/nodeHash.c:3177">ExecParallelHashCloseBatchAccessors</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Figure out how many batches to use. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbatch == <span class="Constant">1</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We are going from single-batch to multi-batch.&nbsp; We need<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * to switch from one large combined memory budget to the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * regular hash_mem budget.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;space_allowed = <a href="#L3595" title="executor/nodeHash.c:3595">get_hash_memory_limit</a>();<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * The combined hash_mem of all participants wasn't<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * enough. Therefore one batch per participant would be<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * approximately equivalent and would probably also be<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * insufficient.&nbsp; So try two batches per participant,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * rounded up to a power of two.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbatch = pg_nextpower2_32(pstate-&gt;nparticipants * <span class="Constant">2</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We were already multi-batched.&nbsp; Try doubling the number<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * of batches.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbatch = hashtable-&gt;nbatch * <span class="Constant">2</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Allocate new larger generation of batches. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(hashtable-&gt;nbatch == pstate-&gt;nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3097" title="executor/nodeHash.c:3097">ExecParallelHashJoinSetUpBatches</a>(hashtable, new_nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(hashtable-&gt;nbatch == pstate-&gt;nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Replace or recycle batch 0's bucket array. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (pstate-&gt;old_nbatch == <span class="Constant">1</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; dtuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; dbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; max_buckets;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We probably also need a smaller bucket array.&nbsp; How many<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * tuples do we expect per batch, assuming we have only<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * half of them so far?&nbsp; Normally we don't need to change<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * the bucket array's size, because the size of each batch<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * stays the same as we add more batches, but in this<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * special case we move from a large batch to many smaller<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * batches and it would be wasteful to keep the large<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * array.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dtuples = (old_batch0-&gt;ntuples * <span class="Constant">2.0</span>) / new_nbatch;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We need to calculate the maximum number of buckets to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * stay within the MaxAllocSize boundary.&nbsp; Round the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * maximum number to the previous power of 2 given that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * later we round the number to the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> power of 2.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; max_buckets = pg_prevpower2_32((uint32)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; (MaxAllocSize / <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic)));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dbuckets = ceil(dtuples / <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dbuckets = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(dbuckets, max_buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbuckets = (<span class="Type">int</span>) dbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbuckets = Max(new_nbuckets, <span class="Constant">1024</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_nbuckets = pg_nextpower2_32(new_nbuckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, old_batch0-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;buckets =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_allocate(hashtable-&gt;area,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic) * new_nbuckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; buckets = (dsa_pointer_atomic *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; new_nbuckets; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer_atomic_init(&amp;buckets[i], InvalidDsaPointer);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;nbuckets = new_nbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Recycle the existing bucket array. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;buckets = old_batch0-&gt;buckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; buckets = (dsa_pointer_atomic *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, old_batch0-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbuckets; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer_atomic_write(&amp;buckets[i], InvalidDsaPointer);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Move all chunks to the work queue for parallel processing. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;chunk_work_queue = old_batch0-&gt;chunks;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Disable further growth temporarily while we're growing. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_DISABLED;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* All other participants just flush their tuples to disk. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3177" title="executor/nodeHash.c:3177">ExecParallelHashCloseBatchAccessors</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BATCHES_REALLOCATE:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Wait for the above to be finished. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_batches_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BATCHES_REALLOCATE);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BATCHES_REPARTITION:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Make sure that we have the current dimensions and buckets. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3472" title="executor/nodeHash.c:3472">ExecParallelHashTableSetCurrentBatch</a>(hashtable, <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Then partition, flush counters. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1305" title="executor/nodeHash.c:1305">ExecParallelHashRepartitionFirst</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1372" title="executor/nodeHash.c:1372">ExecParallelHashRepartitionRest</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1432" title="executor/nodeHash.c:1432">ExecParallelHashMergeCounters</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Wait for the above to be finished. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_batches_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BATCHES_REPARTITION);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BATCHES_DECIDE:<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Elect one participant to clean up and decide whether further<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * repartitioning is needed, or should be disabled because it's<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * not helping.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_batches_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BATCHES_DECIDE))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; space_exhausted = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; extreme_skew_detected = <span class="Constant">false</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Make sure that we have the current dimensions and buckets. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3472" title="executor/nodeHash.c:3472">ExecParallelHashTableSetCurrentBatch</a>(hashtable, <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Are <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> of the new generation of batches exhausted? */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatch *batch = hashtable-&gt;batches[i].shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (batch-&gt;space_exhausted ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;estimated_size &gt; pstate-&gt;space_allowed)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; parent;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; space_exhausted = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Did this batch receive ALL of the tuples from its<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * parent batch?&nbsp; That would indicate that further<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * repartitioning isn't going to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> (the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * are probably all the same).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; parent = i % pstate-&gt;old_nbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (batch-&gt;ntuples == hashtable-&gt;batches[parent].shared-&gt;old_ntuples)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; extreme_skew_detected = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Don't keep growing if it's not helping or we'd overflow. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (extreme_skew_detected || hashtable-&gt;nbatch &gt;= <span class="Constant">INT_MAX</span> / <span class="Constant">2</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_DISABLED;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (space_exhausted)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_NEED_MORE_BATCHES;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_OK;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Free the old batches in shared memory. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, pstate-&gt;old_batches);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;old_batches = InvalidDsaPointer;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BATCHES_FINISH:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Wait for the above to complete. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_batches_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BATCHES_FINISH);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Repartition the tuples currently loaded into memory for inner batch 0<br/></li>
<li></span><span class="Comment"> * because the number of batches has been increased.&nbsp; Some tuples are retained<br/></li>
<li></span><span class="Comment"> * in memory and some are written out to a later batch.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1305">&#x200c;</a></span><span class="linkable">ExecParallelHashRepartitionFirst</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; dsa_pointer chunk_shared;<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk chunk;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;nbatch == hashtable-&gt;parallel_state-&gt;nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">while</span> ((chunk = <a href="#L3493" title="executor/nodeHash.c:3493">ExecParallelHashPopChunkQueue</a>(hashtable, &amp;chunk_shared)))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; idx = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Repartition all tuples in this chunk. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (idx &lt; chunk-&gt;used)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple hashTuple = (HashJoinTuple) (HASH_CHUNK_DATA(chunk) + idx);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; MinimalTuple tuple = HJTUPLE_MINTUPLE(hashTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple copyTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer shared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashTuple-&gt;hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;bucketno, &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(batchno &lt; hashtable-&gt;nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (batchno == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* It still belongs in batch 0.&nbsp; Copy to a new chunk. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L2949" title="executor/nodeHash.c:2949">ExecParallelHashTupleAlloc</a>(hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HJTUPLE_OVERHEAD + tuple-&gt;t_len,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;shared);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple-&gt;hashvalue = hashTuple-&gt;hashvalue;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; memcpy(HJTUPLE_MINTUPLE(copyTuple), tuple, tuple-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3454" title="executor/nodeHash.c:3454">ExecParallelHashPushTuple</a>(&amp;hashtable-&gt;buckets.shared[bucketno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple, shared);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; tuple_size =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; MAXALIGN(HJTUPLE_OVERHEAD + tuple-&gt;t_len);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* It belongs in a later batch. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[batchno].estimated_size += tuple_size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L300" title="utils/sort/sharedtuplestore.c:300">sts_puttuple</a>(hashtable-&gt;batches[batchno].inner_tuples,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;hashTuple-&gt;hashvalue, tuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Count this tuple. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ++hashtable-&gt;batches[<span class="Constant">0</span>].old_ntuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ++hashtable-&gt;batches[batchno].ntuples;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; idx += MAXALIGN(HJTUPLE_OVERHEAD +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HJTUPLE_MINTUPLE(hashTuple)-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Free this chunk. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, chunk_shared);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Help repartition inner batches 1..n.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1372">&#x200c;</a></span><span class="linkable">ExecParallelHashRepartitionRest</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; old_nbatch = pstate-&gt;old_nbatch;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L71" title="utils/sort/sharedtuplestore.c:71">SharedTuplestoreAccessor</a> **old_inner_tuples;<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinBatch *old_batches;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Get our hands on the previous generation of batches. */<br/></li>
<li></span>&nbsp; &nbsp; old_batches = (ParallelHashJoinBatch *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, pstate-&gt;old_batches);<br/></li>
<li>&nbsp; &nbsp; old_inner_tuples = palloc0_array(<a href="../utils/sort/sharedtuplestore.c.html#L71" title="utils/sort/sharedtuplestore.c:71">SharedTuplestoreAccessor</a> *, old_nbatch);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">1</span>; i &lt; old_nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatch *shared =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; NthParallelHashJoinBatch(old_batches, i);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; old_inner_tuples[i] = <a href="../utils/sort/sharedtuplestore.c.html#L178" title="utils/sort/sharedtuplestore.c:178">sts_attach</a>(ParallelHashJoinBatchInner(shared),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a> + <span class="Constant">1</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;pstate-&gt;fileset);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Join in the effort to repartition them. */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">1</span>; i &lt; old_nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MinimalTuple tuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Scan one partition from the previous generation. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L253" title="utils/sort/sharedtuplestore.c:253">sts_begin_parallel_scan</a>(old_inner_tuples[i]);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> ((tuple = <a href="../utils/sort/sharedtuplestore.c.html#L495" title="utils/sort/sharedtuplestore.c:495">sts_parallel_scan_next</a>(old_inner_tuples[i], &amp;hashvalue)))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; tuple_size = MAXALIGN(HJTUPLE_OVERHEAD + tuple-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Decide which partition it goes to in the new generation. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashvalue, &amp;bucketno,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[batchno].estimated_size += tuple_size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ++hashtable-&gt;batches[batchno].ntuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ++hashtable-&gt;batches[i].old_ntuples;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Store the tuple its new batch. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L300" title="utils/sort/sharedtuplestore.c:300">sts_puttuple</a>(hashtable-&gt;batches[batchno].inner_tuples,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;hashvalue, tuple);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(old_inner_tuples[i]);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(old_inner_tuples);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Transfer the backend-local per-batch counters to the shared totals.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1432">&#x200c;</a></span><span class="linkable">ExecParallelHashMergeCounters</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1170" title="storage/lmgr/lwlock.c:1170">LWLockAcquire</a>(&amp;pstate-&gt;lock, LW_EXCLUSIVE);<br/></li>
<li>&nbsp; &nbsp; pstate-&gt;total_tuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatchAccessor *batch = &amp;hashtable-&gt;batches[i];<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;shared-&gt;size += batch-&gt;size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;shared-&gt;estimated_size += batch-&gt;estimated_size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;shared-&gt;ntuples += batch-&gt;ntuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;shared-&gt;old_ntuples += batch-&gt;old_ntuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;size = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;estimated_size = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;ntuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;old_ntuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;total_tuples += batch-&gt;shared-&gt;ntuples;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1462" title="executor/nodeHash.c:1462">ExecHashIncreaseNumBuckets</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; increase the original number of buckets in order to reduce<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; number of tuples per bucket<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1462">&#x200c;</a></span><span class="linkable">ExecHashIncreaseNumBuckets</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk chunk;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* do nothing if not an increase (it's called increase for a reason) */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbuckets &gt;= hashtable-&gt;nbuckets_optimal)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li><span class="PreProc">#ifdef HJDEBUG<br/></li>
<li></span>&nbsp; &nbsp; printf(<span class="Constant">&quot;Hashjoin </span><span class="Special">%p</span><span class="Constant">: increasing nbuckets </span><span class="Special">%d</span><span class="Constant"> =&gt; </span><span class="Special">%d\n</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable, hashtable-&gt;nbuckets, hashtable-&gt;nbuckets_optimal);<br/></li>
<li><span class="PreProc">#endif<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbuckets = hashtable-&gt;nbuckets_optimal;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;log2_nbuckets = hashtable-&gt;log2_nbuckets_optimal;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;nbuckets &gt; <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;nbuckets &lt;= (<span class="Constant">INT_MAX</span> / <span class="Constant">2</span>));<br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;nbuckets == (<span class="Constant">1</span> &lt;&lt; hashtable-&gt;log2_nbuckets));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Just reallocate the proper number of buckets - we don't need to walk<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * through them - we can walk the dense-allocated chunks (just like in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="#L916" title="executor/nodeHash.c:916">ExecHashIncreaseNumBatches</a>, but without all the copying into new<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * chunks)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;buckets.unshared =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; repalloc_array(hashtable-&gt;buckets.unshared,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HashJoinTuple, hashtable-&gt;nbuckets);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; memset(hashtable-&gt;buckets.unshared, <span class="Constant">0</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* scan through all tuples in all chunks to rebuild the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (chunk = hashtable-&gt;chunks; chunk != <span class="Constant">NULL</span>; chunk = chunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* process all tuples stored in this chunk */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; idx = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (idx &lt; chunk-&gt;used)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple hashTuple = (HashJoinTuple) (HASH_CHUNK_DATA(chunk) + idx);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashTuple-&gt;hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;bucketno, &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* add the tuple to the proper bucket */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;buckets.unshared[bucketno];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;buckets.unshared[bucketno] = hashTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* advance index past the tuple */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; idx += MAXALIGN(HJTUPLE_OVERHEAD +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HJTUPLE_MINTUPLE(hashTuple)-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allow this loop to be cancellable */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1525">&#x200c;</a></span><span class="linkable">ExecParallelHashIncreaseNumBuckets</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk chunk;<br/></li>
<li>&nbsp; &nbsp; dsa_pointer chunk_s;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;build_barrier) == PHJ_BUILD_HASH_INNER);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * It's unlikely, but we need to be prepared for new participants to show<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * up while we're in the middle of this operation so we need to switch on<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * barrier phase here.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">switch</span> (PHJ_GROW_BUCKETS_PHASE(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;grow_buckets_barrier)))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BUCKETS_ELECT:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Elect one participant to prepare to increase nbuckets. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_buckets_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BUCKETS_ELECT))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer_atomic *buckets;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Double the size of the bucket array. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;nbuckets *= <span class="Constant">2</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; size = pstate-&gt;nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;size += size / <span class="Constant">2</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;buckets =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_allocate(hashtable-&gt;area, size);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; buckets = (dsa_pointer_atomic *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; pstate-&gt;nbuckets; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer_atomic_init(&amp;buckets[i], InvalidDsaPointer);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Put the chunk list onto the work queue. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;chunk_work_queue = hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;chunks;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Clear the flag. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_OK;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BUCKETS_REALLOCATE:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Wait for the above to complete. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_buckets_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BUCKETS_REALLOCATE);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Fall through. */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PHJ_GROW_BUCKETS_REINSERT:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Reinsert all tuples into the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3472" title="executor/nodeHash.c:3472">ExecParallelHashTableSetCurrentBatch</a>(hashtable, <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> ((chunk = <a href="#L3493" title="executor/nodeHash.c:3493">ExecParallelHashPopChunkQueue</a>(hashtable, &amp;chunk_s)))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; idx = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (idx &lt; chunk-&gt;used)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple hashTuple = (HashJoinTuple) (HASH_CHUNK_DATA(chunk) + idx);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer shared = chunk_s + HASH_CHUNK_HEADER_SIZE + idx;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashTuple-&gt;hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;bucketno, &amp;batchno);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(batchno == <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* add the tuple to the proper bucket */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3454" title="executor/nodeHash.c:3454">ExecParallelHashPushTuple</a>(&amp;hashtable-&gt;buckets.shared[bucketno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple, shared);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* advance index past the tuple */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; idx += MAXALIGN(HJTUPLE_OVERHEAD +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HJTUPLE_MINTUPLE(hashTuple)-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allow this loop to be cancellable */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;pstate-&gt;grow_buckets_barrier,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; WAIT_EVENT_HASH_GROW_BUCKETS_REINSERT);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1624" title="executor/nodeHash.c:1624">ExecHashTableInsert</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; insert a tuple into the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table depending on the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; it may just go to a temp file for later batches<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Note: the passed TupleTableSlot may contain a regular, minimal, or virtual<br/></li>
<li></span><span class="Comment"> * tuple; the minimal case in particular is certain to happen while reloading<br/></li>
<li></span><span class="Comment"> * tuples from batch files.&nbsp; We could save some cycles in the regular-tuple<br/></li>
<li></span><span class="Comment"> * case by not forcing the slot contents into minimal form; not clear if it's<br/></li>
<li></span><span class="Comment"> * worth the messiness required.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L1624">&#x200c;</a></span><span class="linkable">ExecHashTableInsert</span>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *slot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32 hashvalue)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; shouldFree;<br/></li>
<li>&nbsp; &nbsp; MinimalTuple tuple = <a href="execTuples.c.html#L1779" title="executor/execTuples.c:1779">ExecFetchSlotMinimalTuple</a>(slot, &amp;shouldFree);<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;bucketno, &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * decide whether to put the tuple in the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table or a temp file<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (batchno == hashtable-&gt;curbatch)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * put the tuple in <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple hashTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTupleSize;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; ntuples = (hashtable-&gt;totalTuples - hashtable-&gt;skewTuples);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Create the HashJoinTuple */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashTupleSize = HJTUPLE_OVERHEAD + tuple-&gt;t_len;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = (HashJoinTuple) <a href="#L2869" title="executor/nodeHash.c:2869">dense_alloc</a>(hashtable, hashTupleSize);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple-&gt;hashvalue = hashvalue;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; memcpy(HJTUPLE_MINTUPLE(hashTuple), tuple, tuple-&gt;t_len);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We always reset the tuple-matched flag on insertion.&nbsp; This is okay<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * even when reloading a tuple from a batch file, since the tuple<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * could not possibly have been matched to an outer tuple <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * went into the batch file.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; HeapTupleHeaderClearMatch(HJTUPLE_MINTUPLE(hashTuple));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Push it onto the front of the bucket's list */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;buckets.unshared[bucketno];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;buckets.unshared[bucketno] = hashTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Increase the (optimal) number of buckets if we just exceeded the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a> threshold, but only when there's still a single<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * batch.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbatch == <span class="Constant">1</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ntuples &gt; (hashtable-&gt;nbuckets_optimal * <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a>))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Guard against integer overflow and alloc size overflow */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbuckets_optimal &lt;= <span class="Constant">INT_MAX</span> / <span class="Constant">2</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets_optimal * <span class="Constant">2</span> &lt;= MaxAllocSize / <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets_optimal *= <span class="Constant">2</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;log2_nbuckets_optimal += <span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Account for space used, and back off if we've used too much */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsed += hashTupleSize;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed &gt; hashtable-&gt;spacePeak)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak = hashtable-&gt;spaceUsed;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets_optimal * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashJoinTuple)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &gt; hashtable-&gt;spaceAllowed)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L916" title="executor/nodeHash.c:916">ExecHashIncreaseNumBatches</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * put the tuple into a temp file for later batches<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; Assert(batchno &gt; hashtable-&gt;curbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="nodeHashjoin.c.html#L1314" title="executor/nodeHashjoin.c:1314">ExecHashJoinSaveTuple</a>(tuple,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;hashtable-&gt;innerBatchFile[batchno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (shouldFree)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/common/heaptuple.c.html#L1523" title="access/common/heaptuple.c:1523">heap_free_minimal_tuple</a>(tuple);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1714" title="executor/nodeHash.c:1714">ExecParallelHashTableInsert</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; insert a tuple into a shared <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table or shared batch tuplestore<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L1714">&#x200c;</a></span><span class="linkable">ExecParallelHashTableInsert</span>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *slot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32 hashvalue)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; shouldFree;<br/></li>
<li>&nbsp; &nbsp; MinimalTuple tuple = <a href="execTuples.c.html#L1779" title="executor/execTuples.c:1779">ExecFetchSlotMinimalTuple</a>(slot, &amp;shouldFree);<br/></li>
<li>&nbsp; &nbsp; dsa_pointer shared;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li><br/></li>
<li><span class="Statement">retry</span><span class="cUserCont">:<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashvalue, &amp;bucketno, &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (batchno == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple hashTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Try to load it into memory. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;hashtable-&gt;parallel_state-&gt;build_barrier) ==<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; PHJ_BUILD_HASH_INNER);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L2949" title="executor/nodeHash.c:2949">ExecParallelHashTupleAlloc</a>(hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HJTUPLE_OVERHEAD + tuple-&gt;t_len,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;shared);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashTuple == <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">goto</span> retry;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Store the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value in the HashJoinTuple header. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple-&gt;hashvalue = hashvalue;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; memcpy(HJTUPLE_MINTUPLE(hashTuple), tuple, tuple-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; HeapTupleHeaderClearMatch(HJTUPLE_MINTUPLE(hashTuple));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Push it onto the front of the bucket's list */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3454" title="executor/nodeHash.c:3454">ExecParallelHashPushTuple</a>(&amp;hashtable-&gt;buckets.shared[bucketno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple, shared);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; tuple_size = MAXALIGN(HJTUPLE_OVERHEAD + tuple-&gt;t_len);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(batchno &gt; <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Try to preallocate space in the batch if necessary. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;batches[batchno].preallocated &lt; tuple_size)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (!<a href="#L3534" title="executor/nodeHash.c:3534">ExecParallelHashTuplePrealloc</a>(hashtable, batchno, tuple_size))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">goto</span> retry;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(hashtable-&gt;batches[batchno].preallocated &gt;= tuple_size);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[batchno].preallocated -= tuple_size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L300" title="utils/sort/sharedtuplestore.c:300">sts_puttuple</a>(hashtable-&gt;batches[batchno].inner_tuples, &amp;hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; tuple);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; ++hashtable-&gt;batches[batchno].ntuples;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (shouldFree)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/common/heaptuple.c.html#L1523" title="access/common/heaptuple.c:1523">heap_free_minimal_tuple</a>(tuple);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="../storage/file/fd.c.html#L1313" title="storage/file/fd.c:1313">Insert</a> a tuple into the current <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table.&nbsp; Unlike<br/></li>
<li></span><span class="Comment"> * <a href="#L1714" title="executor/nodeHash.c:1714">ExecParallelHashTableInsert</a>, this version is not prepared to <a href="../port/win32/socket.c.html#L38" title="port/win32/socket.c:38">send</a> the tuple<br/></li>
<li></span><span class="Comment"> * to other batches or to run out of memory, and should only be called with<br/></li>
<li></span><span class="Comment"> * tuples that belong in the current batch once growth has been disabled.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L1780">&#x200c;</a></span><span class="linkable">ExecParallelHashTableInsertCurrentBatch</span>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *slot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32 hashvalue)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; shouldFree;<br/></li>
<li>&nbsp; &nbsp; MinimalTuple tuple = <a href="execTuples.c.html#L1779" title="executor/execTuples.c:1779">ExecFetchSlotMinimalTuple</a>(slot, &amp;shouldFree);<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple;<br/></li>
<li>&nbsp; &nbsp; dsa_pointer shared;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashvalue, &amp;bucketno, &amp;batchno);<br/></li>
<li>&nbsp; &nbsp; Assert(batchno == hashtable-&gt;curbatch);<br/></li>
<li>&nbsp; &nbsp; hashTuple = <a href="#L2949" title="executor/nodeHash.c:2949">ExecParallelHashTupleAlloc</a>(hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HJTUPLE_OVERHEAD + tuple-&gt;t_len,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;shared);<br/></li>
<li>&nbsp; &nbsp; hashTuple-&gt;hashvalue = hashvalue;<br/></li>
<li>&nbsp; &nbsp; memcpy(HJTUPLE_MINTUPLE(hashTuple), tuple, tuple-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; HeapTupleHeaderClearMatch(HJTUPLE_MINTUPLE(hashTuple));<br/></li>
<li>&nbsp; &nbsp; <a href="#L3454" title="executor/nodeHash.c:3454">ExecParallelHashPushTuple</a>(&amp;hashtable-&gt;buckets.shared[bucketno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple, shared);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (shouldFree)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/common/heaptuple.c.html#L1523" title="access/common/heaptuple.c:1523">heap_free_minimal_tuple</a>(tuple);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1824" title="executor/nodeHash.c:1824">ExecHashGetHashValue</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Compute the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value for a tuple<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * The tuple to be tested must be in econtext-&gt;ecxt_outertuple (thus Vars in<br/></li>
<li></span><span class="Comment"> * the hashkeys expressions need to have OUTER_VAR as varno). If outer_tuple<br/></li>
<li></span><span class="Comment"> * is false (meaning it's the HashJoin's inner node, Hash), econtext,<br/></li>
<li></span><span class="Comment"> * hashkeys, and slot need to be from Hash, with hashkeys/slot referencing and<br/></li>
<li></span><span class="Comment"> * being suitable for tuples from the node below the Hash. Conversely, if<br/></li>
<li></span><span class="Comment"> * outer_tuple is true, econtext is from HashJoin, and hashkeys/slot need to<br/></li>
<li></span><span class="Comment"> * be appropriate for tuples from HashJoin's outer node.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * A true result means the tuple's <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value has been successfully computed<br/></li>
<li></span><span class="Comment"> * and stored at *hashvalue.&nbsp; A false result means the tuple cannot match<br/></li>
<li></span><span class="Comment"> * because it contains a null attribute, and hence it should be discarded<br/></li>
<li></span><span class="Comment"> * immediately.&nbsp; (If keep_nulls is true then false is never returned.)<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L1824">&#x200c;</a></span><span class="linkable">ExecHashGetHashValue</span>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ExprContext *econtext,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; List *hashkeys,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> outer_tuple,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> keep_nulls,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; uint32 *hashvalue)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashkey = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; FmgrInfo&nbsp;&nbsp; *hashfunctions;<br/></li>
<li>&nbsp; &nbsp; ListCell&nbsp;&nbsp; *hk;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; MemoryContext oldContext;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We reset the eval context each time to reclaim <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> memory leaked in the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hashkey expressions.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; ResetExprContext(econtext);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; oldContext = MemoryContextSwitchTo(econtext-&gt;ecxt_per_tuple_memory);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (outer_tuple)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashfunctions = hashtable-&gt;outer_hashfunctions;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashfunctions = hashtable-&gt;inner_hashfunctions;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; foreach(hk, hashkeys)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ExprState&nbsp; *keyexpr = (ExprState *) lfirst(hk);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Datum&nbsp; &nbsp; &nbsp; &nbsp; keyval;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; isNull;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* <a href="../regex/regc_nfa.c.html#L1980" title="regex/regc_nfa.c:1980">combine</a> successive hashkeys by rotating */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashkey = pg_rotate_left32(hashkey, <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Get the join attribute value of the tuple<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; keyval = ExecEvalExpr(keyexpr, econtext, &amp;isNull);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * If the attribute is NULL, and the join operator is strict, then<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * this tuple cannot pass the join qual so we can reject it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * immediately (unless we're scanning the outside of an outer join, in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * which case we must not reject it).&nbsp; Otherwise we act like the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * hashcode of NULL is zero (this will support operators that act like<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * IS NOT DISTINCT, though not <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> more-random behavior).&nbsp; We treat<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> support function as strict even if the operator is not.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Note: currently, all hashjoinable operators must be strict since<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> index AM assumes that.&nbsp; However, it takes so little extra<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * code here to allow non-strict that we may as well do it.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (isNull)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;hashStrict[i] &amp;&amp; !keep_nulls)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; MemoryContextSwitchTo(oldContext);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;&nbsp; &nbsp; <span class="Comment">/* cannot match */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* else, leave hashkey unmodified, equivalent to hashcode 0 */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Compute the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> function */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hkey;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hkey = DatumGetUInt32(<a href="../utils/fmgr/fmgr.c.html#L1129" title="utils/fmgr/fmgr.c:1129">FunctionCall1Coll</a>(&amp;hashfunctions[i], hashtable-&gt;collations[i], keyval));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashkey ^= hkey;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; i++;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; MemoryContextSwitchTo(oldContext);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; *hashvalue = hashkey;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Determine the bucket number and batch number for a <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Note: on-the-fly increases of nbatch must not change the bucket number<br/></li>
<li></span><span class="Comment"> * for a given <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> code (since we don't move tuples to different <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a><br/></li>
<li></span><span class="Comment"> * chains), and must only cause the batch number to remain the same or<br/></li>
<li></span><span class="Comment"> * increase.&nbsp; Our algorithm is<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; bucketno = hashvalue <a href="../utils/hash/dynahash.c.html#L255" title="utils/hash/dynahash.c:255">MOD</a> nbuckets<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; batchno = ROR(hashvalue, log2_nbuckets) <a href="../utils/hash/dynahash.c.html#L255" title="utils/hash/dynahash.c:255">MOD</a> nbatch<br/></li>
<li></span><span class="Comment"> * where nbuckets and nbatch are both expected to be powers of 2, so we can<br/></li>
<li></span><span class="Comment"> * do the computations by shifting and masking.&nbsp; (This assumes that all <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a><br/></li>
<li></span><span class="Comment"> * <a href="../regex/regcomp.c.html#L356" title="regex/regcomp.c:356">functions</a> are good about randomizing all their output bits, else we are<br/></li>
<li></span><span class="Comment"> * likely to have very skewed bucket or batch occupancy.)<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * nbuckets and log2_nbuckets may change while nbatch == 1 because of dynamic<br/></li>
<li></span><span class="Comment"> * bucket count growth.&nbsp; Once we start batching, the value is fixed and does<br/></li>
<li></span><span class="Comment"> * not change over the course of the join (making it possible to compute batch<br/></li>
<li></span><span class="Comment"> * number the way we do here).<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * nbatch is always a power of 2; we increase it only by doubling it.&nbsp; This<br/></li>
<li></span><span class="Comment"> * effectively adds one more <a href="../utils/adt/varbit.c.html#L391" title="utils/adt/varbit.c:391">bit</a> to the top of the batchno.&nbsp; In very large<br/></li>
<li></span><span class="Comment"> * joins, we might run out of bits to add, so we do this by rotating the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a><br/></li>
<li></span><span class="Comment"> * value.&nbsp; This causes batchno to steal bits from bucketno when the number of<br/></li>
<li></span><span class="Comment"> * virtual buckets exceeds 2^32.&nbsp; It's better to have longer bucket chains<br/></li>
<li></span><span class="Comment"> * than to lose the ability to divide batches.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L1932">&#x200c;</a></span><span class="linkable">ExecHashGetBucketAndBatch</span>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32 hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> *bucketno,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> *batchno)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; nbuckets = (uint32) hashtable-&gt;nbuckets;<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; nbatch = (uint32) hashtable-&gt;nbatch;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (nbatch &gt; <span class="Constant">1</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *bucketno = hashvalue &amp; (nbuckets - <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *batchno = pg_rotate_right32(hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;log2_nbuckets) &amp; (nbatch - <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *bucketno = hashvalue &amp; (nbuckets - <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *batchno = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L1964" title="executor/nodeHash.c:1964">ExecScanHashBucket</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; scan a <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> bucket for matches to the current outer tuple<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * The current outer tuple must be stored in econtext-&gt;ecxt_outertuple.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and<br/></li>
<li></span><span class="Comment"> * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot<br/></li>
<li></span><span class="Comment"> * for the latter.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L1964">&#x200c;</a></span><span class="linkable">ExecScanHashBucket</span>(HashJoinState *hjstate,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ExprContext *econtext)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ExprState&nbsp; *hjclauses = hjstate-&gt;hashclauses;<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable = hjstate-&gt;hj_HashTable;<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple = hjstate-&gt;hj_CurTuple;<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue = hjstate-&gt;hj_CurHashValue;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hj_CurTuple is the address of the tuple last returned from the current<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * bucket, or NULL if it's time to start scanning a new bucket.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If the tuple hashed to a skew bucket then scan the skew bucket<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * otherwise scan the standard hashtable bucket.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (hjstate-&gt;hj_CurSkewBucketNo != INVALID_SKEW_BUCKET_NO)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashtable-&gt;skewBucket[hjstate-&gt;hj_CurSkewBucketNo]-&gt;tuples;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashtable-&gt;buckets.unshared[hjstate-&gt;hj_CurBucketNo];<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">while</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashTuple-&gt;hashvalue == hashvalue)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* insert hashtable's tuple into exec slot so ExecQual sees it */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; inntuple = <a href="execTuples.c.html#L1533" title="executor/execTuples.c:1533">ExecStoreMinimalTuple</a>(HJTUPLE_MINTUPLE(hashTuple),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hjstate-&gt;hj_HashTupleSlot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>);&nbsp; &nbsp; <span class="Comment">/* do not <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; econtext-&gt;ecxt_innertuple = inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (ExecQualAndReset(hjclauses, econtext))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hjstate-&gt;hj_CurTuple = hashTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * no match<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2025" title="executor/nodeHash.c:2025">ExecParallelScanHashBucket</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; scan a <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> bucket for matches to the current outer tuple<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * The current outer tuple must be stored in econtext-&gt;ecxt_outertuple.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and<br/></li>
<li></span><span class="Comment"> * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot<br/></li>
<li></span><span class="Comment"> * for the latter.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L2025">&#x200c;</a></span><span class="linkable">ExecParallelScanHashBucket</span>(HashJoinState *hjstate,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ExprContext *econtext)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ExprState&nbsp; *hjclauses = hjstate-&gt;hashclauses;<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable = hjstate-&gt;hj_HashTable;<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple = hjstate-&gt;hj_CurTuple;<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue = hjstate-&gt;hj_CurHashValue;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hj_CurTuple is the address of the tuple last returned from the current<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * bucket, or NULL if it's time to start scanning a new bucket.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L3440" title="executor/nodeHash.c:3440">ExecParallelHashNextTuple</a>(hashtable, hashTuple);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L3424" title="executor/nodeHash.c:3424">ExecParallelHashFirstTuple</a>(hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hjstate-&gt;hj_CurBucketNo);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">while</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashTuple-&gt;hashvalue == hashvalue)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* insert hashtable's tuple into exec slot so ExecQual sees it */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; inntuple = <a href="execTuples.c.html#L1533" title="executor/execTuples.c:1533">ExecStoreMinimalTuple</a>(HJTUPLE_MINTUPLE(hashTuple),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hjstate-&gt;hj_HashTupleSlot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>);&nbsp; &nbsp; <span class="Comment">/* do not <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; econtext-&gt;ecxt_innertuple = inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (ExecQualAndReset(hjclauses, econtext))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hjstate-&gt;hj_CurTuple = hashTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L3440" title="executor/nodeHash.c:3440">ExecParallelHashNextTuple</a>(hashtable, hashTuple);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * no match<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2076" title="executor/nodeHash.c:2076">ExecPrepHashTableForUnmatched</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; set up for a series of <a href="#L2162" title="executor/nodeHash.c:2162">ExecScanHashTableForUnmatched</a> calls<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2076">&#x200c;</a></span><span class="linkable">ExecPrepHashTableForUnmatched</span>(HashJoinState *hjstate)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*----------<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * During this scan we use the HashJoinState fields as follows:<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hj_CurBucketNo: <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> regular bucket to scan<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hj_CurSkewBucketNo: <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> skew bucket (an index into skewBucketNums)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hj_CurTuple: last tuple returned, or NULL to start <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> bucket<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *----------<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hjstate-&gt;hj_CurBucketNo = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hjstate-&gt;hj_CurSkewBucketNo = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; hjstate-&gt;hj_CurTuple = <span class="Constant">NULL</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Decide if this process is allowed to run the unmatched scan.&nbsp; If so, the<br/></li>
<li></span><span class="Comment"> * batch barrier is advanced to PHJ_BATCH_SCAN and true is returned.<br/></li>
<li></span><span class="Comment"> * Otherwise the batch is detached and false is returned.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L2097">&#x200c;</a></span><span class="linkable">ExecParallelPrepHashTableForUnmatched</span>(HashJoinState *hjstate)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable = hjstate-&gt;hj_HashTable;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; curbatch = hashtable-&gt;curbatch;<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinBatch *batch = hashtable-&gt;batches[curbatch].shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_PROBE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * It would not be deadlock-free to wait on the batch barrier, because it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * is in PHJ_BATCH_PROBE phase, and thus processes attached to it have<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * already emitted tuples.&nbsp; Therefore, we'll hold a wait-free election:<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * only one process can continue to the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> phase, and all others detach<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * from this batch.&nbsp; They can still go <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> work on other batches, if there<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * are <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!<a href="../storage/ipc/barrier.c.html#L213" title="storage/ipc/barrier.c:213">BarrierArriveAndDetachExceptLast</a>(&amp;batch-&gt;batch_barrier))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* This process considers the batch to be done. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[hashtable-&gt;curbatch].done = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Make sure <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> temporary files are closed. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[curbatch].inner_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[curbatch].outer_tuples);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Track largest batch we've seen, which would normally happen in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L3282" title="executor/nodeHash.c:3282">ExecHashTableDetachBatch</a>().<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Max(hashtable-&gt;spacePeak,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;size + <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic) * hashtable-&gt;nbuckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;curbatch = -<span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Now we are alone with this batch. */<br/></li>
<li></span>&nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_SCAN);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Has another process decided to give up early and command all processes<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * to <a href="../regex/regc_lex.c.html#L982" title="regex/regc_lex.c:982">skip</a> the unmatched scan?<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (batch-&gt;skip_unmatched)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[hashtable-&gt;curbatch].done = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3282" title="executor/nodeHash.c:3282">ExecHashTableDetachBatch</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Now prepare the process local state, just as for non-parallel join. */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L2076" title="executor/nodeHash.c:2076">ExecPrepHashTableForUnmatched</a>(hjstate);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2162" title="executor/nodeHash.c:2162">ExecScanHashTableForUnmatched</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; scan the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table for unmatched inner tuples<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and<br/></li>
<li></span><span class="Comment"> * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot<br/></li>
<li></span><span class="Comment"> * for the latter.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L2162">&#x200c;</a></span><span class="linkable">ExecScanHashTableForUnmatched</span>(HashJoinState *hjstate, ExprContext *econtext)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable = hjstate-&gt;hj_HashTable;<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple = hjstate-&gt;hj_CurTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (;;)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * hj_CurTuple is the address of the tuple last returned from the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * current bucket, or NULL if it's time to start scanning a new<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * bucket.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (hjstate-&gt;hj_CurBucketNo &lt; hashtable-&gt;nbuckets)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashtable-&gt;buckets.unshared[hjstate-&gt;hj_CurBucketNo];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hjstate-&gt;hj_CurBucketNo++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (hjstate-&gt;hj_CurSkewBucketNo &lt; hashtable-&gt;nSkewBuckets)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; j = hashtable-&gt;skewBucketNums[hjstate-&gt;hj_CurSkewBucketNo];<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashtable-&gt;skewBucket[j]-&gt;tuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hjstate-&gt;hj_CurSkewBucketNo++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* finished all buckets */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (!HeapTupleHeaderHasMatch(HJTUPLE_MINTUPLE(hashTuple)))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* insert hashtable's tuple into exec slot */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; inntuple = <a href="execTuples.c.html#L1533" title="executor/execTuples.c:1533">ExecStoreMinimalTuple</a>(HJTUPLE_MINTUPLE(hashTuple),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hjstate-&gt;hj_HashTupleSlot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>);&nbsp; &nbsp; <span class="Comment">/* do not <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; econtext-&gt;ecxt_innertuple = inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Reset temp memory each time; although this function doesn't<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * do <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> qual eval, the caller will, so let's keep it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * parallel to <a href="#L1964" title="executor/nodeHash.c:1964">ExecScanHashBucket</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ResetExprContext(econtext);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hjstate-&gt;hj_CurTuple = hashTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allow this loop to be cancellable */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * no more unmatched tuples<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2236" title="executor/nodeHash.c:2236">ExecParallelScanHashTableForUnmatched</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; scan the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table for unmatched inner tuples, in parallel join<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and<br/></li>
<li></span><span class="Comment"> * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot<br/></li>
<li></span><span class="Comment"> * for the latter.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L2236">&#x200c;</a></span><span class="linkable">ExecParallelScanHashTableForUnmatched</span>(HashJoinState *hjstate,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ExprContext *econtext)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashJoinTable hashtable = hjstate-&gt;hj_HashTable;<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple = hjstate-&gt;hj_CurTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (;;)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * hj_CurTuple is the address of the tuple last returned from the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * current bucket, or NULL if it's time to start scanning a new<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * bucket.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L3440" title="executor/nodeHash.c:3440">ExecParallelHashNextTuple</a>(hashtable, hashTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (hjstate-&gt;hj_CurBucketNo &lt; hashtable-&gt;nbuckets)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L3424" title="executor/nodeHash.c:3424">ExecParallelHashFirstTuple</a>(hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hjstate-&gt;hj_CurBucketNo++);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* finished all buckets */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (!HeapTupleHeaderHasMatch(HJTUPLE_MINTUPLE(hashTuple)))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* insert hashtable's tuple into exec slot */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; inntuple = <a href="execTuples.c.html#L1533" title="executor/execTuples.c:1533">ExecStoreMinimalTuple</a>(HJTUPLE_MINTUPLE(hashTuple),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hjstate-&gt;hj_HashTupleSlot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>);&nbsp; &nbsp; <span class="Comment">/* do not <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; econtext-&gt;ecxt_innertuple = inntuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Reset temp memory each time; although this function doesn't<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * do <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> qual eval, the caller will, so let's keep it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * parallel to <a href="#L1964" title="executor/nodeHash.c:1964">ExecScanHashBucket</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ResetExprContext(econtext);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hjstate-&gt;hj_CurTuple = hashTuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTuple = <a href="#L3440" title="executor/nodeHash.c:3440">ExecParallelHashNextTuple</a>(hashtable, hashTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allow this loop to be cancellable */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * no more unmatched tuples<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2299" title="executor/nodeHash.c:2299">ExecHashTableReset</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; reset <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table header for new batch<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2299">&#x200c;</a></span><span class="linkable">ExecHashTableReset</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; MemoryContext oldcxt;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbuckets = hashtable-&gt;nbuckets;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Release all the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> buckets and tuples acquired in the prior pass, and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * reinitialize the context for a new pass.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L383" title="utils/mmgr/mcxt.c:383">MemoryContextReset</a>(hashtable-&gt;batchCxt);<br/></li>
<li>&nbsp; &nbsp; oldcxt = MemoryContextSwitchTo(hashtable-&gt;batchCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Reallocate and reinitialize the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> bucket headers. */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;buckets.unshared = palloc0_array(HashJoinTuple, nbuckets);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceUsed = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; MemoryContextSwitchTo(oldcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Forget the chunks (the memory was freed by the context reset above). */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;chunks = <span class="Constant">NULL</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2327" title="executor/nodeHash.c:2327">ExecHashTableResetMatchFlags</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Clear all the HeapTupleHeaderHasMatch flags in the table<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2327">&#x200c;</a></span><span class="linkable">ExecHashTableResetMatchFlags</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple tuple;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Reset all flags in the <a href="../storage/lmgr/s_lock.c.html#L257" title="storage/lmgr/s_lock.c:257">main</a> table ... */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbuckets; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (tuple = hashtable-&gt;buckets.unshared[i]; tuple != <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; tuple = tuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HeapTupleHeaderClearMatch(HJTUPLE_MINTUPLE(tuple));<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* ... and the same for the skew buckets, if <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nSkewBuckets; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; j = hashtable-&gt;skewBucketNums[i];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; HashSkewBucket *skewBucket = hashtable-&gt;skewBucket[j];<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (tuple = skewBucket-&gt;tuples; tuple != <span class="Constant">NULL</span>; tuple = tuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HeapTupleHeaderClearMatch(HJTUPLE_MINTUPLE(tuple));<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><br/></li>
<li><span class="Type">void<br/></li>
<li><a id="L2353">&#x200c;</a></span><span class="linkable">ExecReScanHash</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; PlanState&nbsp; *outerPlan = outerPlanState(node);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * if chgParam of subnode is not null then plan will be re-scanned by<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * first ExecProcNode.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (outerPlan-&gt;chgParam == <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="execAmi.c.html#L76" title="executor/execAmi.c:76">ExecReScan</a>(outerPlan);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2375" title="executor/nodeHash.c:2375">ExecHashBuildSkewHash</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Set up for skew optimization if we can identify the most common <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a><br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; (MCVs) of the outer relation's join key.&nbsp; We make a skew <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> bucket<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; for the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value of each MCV, up to the number of slots allowed<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; based on available memory.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L2375">&#x200c;</a></span><span class="linkable">ExecHashBuildSkewHash</span>(HashJoinTable hashtable, Hash *node, <span class="Type">int</span> mcvsToUse)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HeapTupleData *statsTuple;<br/></li>
<li>&nbsp; &nbsp; AttStatsSlot sslot;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Do nothing if <a href="../optimizer/plan/planner.c.html#L274" title="optimizer/plan/planner.c:274">planner</a> didn't identify the outer relation's join key */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!OidIsValid(node-&gt;skewTable))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Also, do nothing if we don't have room for at least one skew bucket */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (mcvsToUse &lt;= <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Try to <a href="../regex/regexec.c.html#L419" title="regex/regexec.c:419">find</a> the MCV statistics for the outer relation's join key.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; statsTuple = <a href="../utils/cache/syscache.c.html#L240" title="utils/cache/syscache.c:240">SearchSysCache3</a>(STATRELATTINH,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ObjectIdGetDatum(node-&gt;skewTable),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; Int16GetDatum(node-&gt;skewColumn),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; BoolGetDatum(node-&gt;skewInherit));<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (!HeapTupleIsValid(statsTuple))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="../utils/cache/lsyscache.c.html#L3234" title="utils/cache/lsyscache.c:3234">get_attstatsslot</a>(&amp;sslot, statsTuple,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; STATISTIC_KIND_MCV, InvalidOid,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ATTSTATSSLOT_VALUES | ATTSTATSSLOT_NUMBERS))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; frac;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbuckets;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; FmgrInfo&nbsp;&nbsp; *hashfunctions;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (mcvsToUse &gt; sslot.nvalues)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mcvsToUse = sslot.nvalues;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Calculate the expected fraction of outer relation that will<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * participate in the skew optimization.&nbsp; If this isn't at least<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * SKEW_MIN_OUTER_FRACTION, don't use skew optimization.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; frac = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; mcvsToUse; i++)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; frac += sslot.numbers[i];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (frac &lt; SKEW_MIN_OUTER_FRACTION)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/cache/lsyscache.c.html#L3344" title="utils/cache/lsyscache.c:3344">free_attstatsslot</a>(&amp;sslot);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/cache/syscache.c.html#L266" title="utils/cache/syscache.c:266">ReleaseSysCache</a>(statsTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Okay, set up the skew hashtable.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * skewBucket[] is an open addressing hashtable with a power of 2 size<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * that is greater than the number of MCV <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a>.&nbsp; (This ensures there<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * will be at least one null entry, so searches will always<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * terminate.)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Note: this code could fail if mcvsToUse exceeds INT_MAX/8 or<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * MaxAllocSize/<a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a>(void *)/8, but that is not currently possible<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * since we limit pg_statistic entries to much less than that.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; nbuckets = pg_nextpower2_32(mcvsToUse + <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* use two more bits just to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> avoid collisions */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; nbuckets &lt;&lt;= <span class="Constant">2</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewEnabled = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucketLen = nbuckets;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We allocate the bucket memory in the hashtable's batch context. It<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * is only needed during the first batch, and this ensures it will be<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * automatically removed once the first batch is done.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucket = (HashSkewBucket **)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1214" title="utils/mmgr/mcxt.c:1214">MemoryContextAllocZero</a>(hashtable-&gt;batchCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashSkewBucket *));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucketNums = (<span class="Type">int</span> *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1214" title="utils/mmgr/mcxt.c:1214">MemoryContextAllocZero</a>(hashtable-&gt;batchCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; mcvsToUse * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<span class="Type">int</span>));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsed += nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashSkewBucket *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; + mcvsToUse * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<span class="Type">int</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsedSkew += nbuckets * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashSkewBucket *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; + mcvsToUse * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<span class="Type">int</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed &gt; hashtable-&gt;spacePeak)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak = hashtable-&gt;spaceUsed;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Create a skew bucket for each MCV <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Note: it is very important that we create the buckets in order of<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * decreasing MCV frequency.&nbsp; If we have to remove some buckets, they<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * must be removed in reverse order of creation (see notes in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L2620" title="executor/nodeHash.c:2620">ExecHashRemoveNextSkewBucket</a>) and we want the least common MCVs to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * be removed first.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashfunctions = hashtable-&gt;outer_hashfunctions;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; mcvsToUse; i++)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucket;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashvalue = DatumGetUInt32(<a href="../utils/fmgr/fmgr.c.html#L1129" title="utils/fmgr/fmgr.c:1129">FunctionCall1Coll</a>(&amp;hashfunctions[<span class="Constant">0</span>],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;collations[<span class="Constant">0</span>],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; sslot.<a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a>[i]));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * While we have not hit a hole in the hashtable and have not hit<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * the desired bucket, we have collided with some previous <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * value, so try the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> bucket location.&nbsp; NB: this code must<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * match <a href="#L2528" title="executor/nodeHash.c:2528">ExecHashGetSkewBucket</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucket = hashvalue &amp; (nbuckets - <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (hashtable-&gt;skewBucket[bucket] != <span class="Constant">NULL</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;skewBucket[bucket]-&gt;hashvalue != hashvalue)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucket = (bucket + <span class="Constant">1</span>) &amp; (nbuckets - <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * If we found an existing bucket with the same hashvalue, leave<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * it alone.&nbsp; It's okay for two MCVs to share a hashvalue.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;skewBucket[bucket] != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">continue</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Okay, create a new skew bucket for this hashvalue. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucket[bucket] = (HashSkewBucket *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1180" title="utils/mmgr/mcxt.c:1180">MemoryContextAlloc</a>(hashtable-&gt;batchCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashSkewBucket));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucket[bucket]-&gt;hashvalue = hashvalue;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucket[bucket]-&gt;tuples = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucketNums[hashtable-&gt;nSkewBuckets] = bucket;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nSkewBuckets++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsed += SKEW_BUCKET_OVERHEAD;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsedSkew += SKEW_BUCKET_OVERHEAD;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed &gt; hashtable-&gt;spacePeak)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak = hashtable-&gt;spaceUsed;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/cache/lsyscache.c.html#L3344" title="utils/cache/lsyscache.c:3344">free_attstatsslot</a>(&amp;sslot);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../utils/cache/syscache.c.html#L266" title="utils/cache/syscache.c:266">ReleaseSysCache</a>(statsTuple);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2528" title="executor/nodeHash.c:2528">ExecHashGetSkewBucket</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Returns the index of the skew bucket for this hashvalue,<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; or INVALID_SKEW_BUCKET_NO if the hashvalue is not<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; associated with <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> active skew bucket.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">int<br/></li>
<li><a id="L2528">&#x200c;</a></span><span class="linkable">ExecHashGetSkewBucket</span>(HashJoinTable hashtable, uint32 hashvalue)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucket;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Always return INVALID_SKEW_BUCKET_NO if not doing skew optimization (in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * particular, this happens after the initial batch is done).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!hashtable-&gt;skewEnabled)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> INVALID_SKEW_BUCKET_NO;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Since skewBucketLen is a power of 2, we can do a modulo by ANDing.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; bucket = hashvalue &amp; (hashtable-&gt;skewBucketLen - <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * While we have not hit a hole in the hashtable and have not hit the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * desired bucket, we have collided with some other <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value, so try the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> bucket location.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">while</span> (hashtable-&gt;skewBucket[bucket] != <span class="Constant">NULL</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;skewBucket[bucket]-&gt;hashvalue != hashvalue)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; bucket = (bucket + <span class="Constant">1</span>) &amp; (hashtable-&gt;skewBucketLen - <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Found the desired bucket?<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;skewBucket[bucket] != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> bucket;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * There must not be <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> hashtable entry for this <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> INVALID_SKEW_BUCKET_NO;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="#L2574" title="executor/nodeHash.c:2574">ExecHashSkewTableInsert</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/file/fd.c.html#L1313" title="storage/file/fd.c:1313">Insert</a> a tuple into the skew hashtable.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * This should generally match up with the current-batch case in<br/></li>
<li></span><span class="Comment"> * <a href="#L1624" title="executor/nodeHash.c:1624">ExecHashTableInsert</a>.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L2574">&#x200c;</a></span><span class="linkable">ExecHashSkewTableInsert</span>(HashJoinTable hashtable,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TupleTableSlot *slot,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; uint32 hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> bucketNumber)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; shouldFree;<br/></li>
<li>&nbsp; &nbsp; MinimalTuple tuple = <a href="execTuples.c.html#L1779" title="executor/execTuples.c:1779">ExecFetchSlotMinimalTuple</a>(slot, &amp;shouldFree);<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTupleSize;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Create the HashJoinTuple */<br/></li>
<li></span>&nbsp; &nbsp; hashTupleSize = HJTUPLE_OVERHEAD + tuple-&gt;t_len;<br/></li>
<li>&nbsp; &nbsp; hashTuple = (HashJoinTuple) <a href="../utils/mmgr/mcxt.c.html#L1180" title="utils/mmgr/mcxt.c:1180">MemoryContextAlloc</a>(hashtable-&gt;batchCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashTupleSize);<br/></li>
<li>&nbsp; &nbsp; hashTuple-&gt;hashvalue = hashvalue;<br/></li>
<li>&nbsp; &nbsp; memcpy(HJTUPLE_MINTUPLE(hashTuple), tuple, tuple-&gt;t_len);<br/></li>
<li>&nbsp; &nbsp; HeapTupleHeaderClearMatch(HJTUPLE_MINTUPLE(hashTuple));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Push it onto the front of the skew bucket's list */<br/></li>
<li></span>&nbsp; &nbsp; hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;skewBucket[bucketNumber]-&gt;tuples;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;skewBucket[bucketNumber]-&gt;tuples = hashTuple;<br/></li>
<li>&nbsp; &nbsp; Assert(hashTuple != hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Account for space used, and back off if we've used too much */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;spaceUsed += hashTupleSize;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceUsedSkew += hashTupleSize;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed &gt; hashtable-&gt;spacePeak)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak = hashtable-&gt;spaceUsed;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">while</span> (hashtable-&gt;spaceUsedSkew &gt; hashtable-&gt;spaceAllowedSkew)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L2620" title="executor/nodeHash.c:2620">ExecHashRemoveNextSkewBucket</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Check we are not over the total spaceAllowed, either */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;spaceUsed &gt; hashtable-&gt;spaceAllowed)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L916" title="executor/nodeHash.c:916">ExecHashIncreaseNumBatches</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (shouldFree)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/common/heaptuple.c.html#L1523" title="access/common/heaptuple.c:1523">heap_free_minimal_tuple</a>(tuple);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L2620" title="executor/nodeHash.c:2620">ExecHashRemoveNextSkewBucket</a><br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; Remove the least valuable skew bucket by pushing its tuples into<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; &nbsp; the <a href="../storage/lmgr/s_lock.c.html#L257" title="storage/lmgr/s_lock.c:257">main</a> <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L2620">&#x200c;</a></span><span class="linkable">ExecHashRemoveNextSkewBucket</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketToRemove;<br/></li>
<li>&nbsp; &nbsp; HashSkewBucket *bucket;<br/></li>
<li>&nbsp; &nbsp; uint32&nbsp; &nbsp; &nbsp; &nbsp; hashvalue;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bucketno;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batchno;<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple hashTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Locate the bucket to remove */<br/></li>
<li></span>&nbsp; &nbsp; bucketToRemove = hashtable-&gt;skewBucketNums[hashtable-&gt;nSkewBuckets - <span class="Constant">1</span>];<br/></li>
<li>&nbsp; &nbsp; bucket = hashtable-&gt;skewBucket[bucketToRemove];<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Calculate which bucket and batch the tuples belong to in the <a href="../storage/lmgr/s_lock.c.html#L257" title="storage/lmgr/s_lock.c:257">main</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * hashtable.&nbsp; They all have the same <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> value, so it's the same for all<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * of them.&nbsp; Also note that it's not possible for nbatch to increase while<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * we are processing the tuples.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashvalue = bucket-&gt;hashvalue;<br/></li>
<li>&nbsp; &nbsp; <a href="#L1932" title="executor/nodeHash.c:1932">ExecHashGetBucketAndBatch</a>(hashtable, hashvalue, &amp;bucketno, &amp;batchno);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Process all tuples in the bucket */<br/></li>
<li></span>&nbsp; &nbsp; hashTuple = bucket-&gt;tuples;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">while</span> (hashTuple != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple nextHashTuple = hashTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; MinimalTuple tuple;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Size&nbsp; &nbsp; &nbsp; &nbsp; tupleSize;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * This code must agree with <a href="#L1624" title="executor/nodeHash.c:1624">ExecHashTableInsert</a>.&nbsp; We do not use<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L1624" title="executor/nodeHash.c:1624">ExecHashTableInsert</a> directly as <a href="#L1624" title="executor/nodeHash.c:1624">ExecHashTableInsert</a> expects a<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * TupleTableSlot while we already have HashJoinTuples.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; tuple = HJTUPLE_MINTUPLE(hashTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; tupleSize = HJTUPLE_OVERHEAD + tuple-&gt;t_len;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Decide whether to put the tuple in the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table or a temp file */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (batchno == hashtable-&gt;curbatch)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Move the tuple to the <a href="../storage/lmgr/s_lock.c.html#L257" title="storage/lmgr/s_lock.c:257">main</a> <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple copyTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We must copy the tuple into the dense storage, else it will not<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * be found by, eg, <a href="#L916" title="executor/nodeHash.c:916">ExecHashIncreaseNumBatches</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple = (HashJoinTuple) <a href="#L2869" title="executor/nodeHash.c:2869">dense_alloc</a>(hashtable, tupleSize);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; memcpy(copyTuple, hashTuple, tupleSize);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(hashTuple);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; copyTuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;buckets.unshared[bucketno];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;buckets.unshared[bucketno] = copyTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* We have reduced skew space, but overall space doesn't change */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsedSkew -= tupleSize;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Put the tuple into a temp file for later batches */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(batchno &gt; hashtable-&gt;curbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="nodeHashjoin.c.html#L1314" title="executor/nodeHashjoin.c:1314">ExecHashJoinSaveTuple</a>(tuple, hashvalue,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;hashtable-&gt;innerBatchFile[batchno],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(hashTuple);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsed -= tupleSize;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsedSkew -= tupleSize;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashTuple = nextHashTuple;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allow this loop to be cancellable */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; CHECK_FOR_INTERRUPTS();<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Free the bucket struct itself and reset the hashtable entry to NULL.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/regcomp.c.html#L324" title="regex/regcomp.c:324">NOTE</a>: this is not nearly as simple as it looks on the surface, because<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * of the possibility of collisions in the hashtable.&nbsp; Suppose that <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a> A and B collide at a particular hashtable entry, and that A was<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * entered first so B gets shifted to a different table entry.&nbsp; If we were<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * to remove A first then <a href="#L2528" title="executor/nodeHash.c:2528">ExecHashGetSkewBucket</a> would mistakenly start<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * reporting that B is not in the hashtable, because it would hit the NULL<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> finding B.&nbsp; However, we always remove entries in the reverse<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * order of creation, so this failure cannot happen.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;skewBucket[bucketToRemove] = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nSkewBuckets--;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(bucket);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceUsed -= SKEW_BUCKET_OVERHEAD;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;spaceUsedSkew -= SKEW_BUCKET_OVERHEAD;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If we have removed all skew buckets then give up on skew optimization.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Release the arrays since they aren't useful <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> more.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nSkewBuckets == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewEnabled = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(hashtable-&gt;skewBucket);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(hashtable-&gt;skewBucketNums);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucket = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;skewBucketNums = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsed -= hashtable-&gt;spaceUsedSkew;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spaceUsedSkew = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Reserve space in the DSM segment for instrumentation data.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2734">&#x200c;</a></span><span class="linkable">ExecHashEstimate</span>(HashState *node, ParallelContext *pcxt)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; size;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* don't need this if not instrumenting or no workers */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!node-&gt;ps.instrument || pcxt-&gt;nworkers == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; size = <a href="../storage/ipc/shmem.c.html#L510" title="storage/ipc/shmem.c:510">mul_size</a>(pcxt-&gt;nworkers, <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashInstrumentation));<br/></li>
<li>&nbsp; &nbsp; size = <a href="../storage/ipc/shmem.c.html#L493" title="storage/ipc/shmem.c:493">add_size</a>(size, offsetof(SharedHashInfo, hinstrument));<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, size);<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, <span class="Constant">1</span>);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Set up a space in the DSM for all workers to record instrumentation data<br/></li>
<li></span><span class="Comment"> * about their <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2753">&#x200c;</a></span><span class="linkable">ExecHashInitializeDSM</span>(HashState *node, ParallelContext *pcxt)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; size;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* don't need this if not instrumenting or no workers */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!node-&gt;ps.instrument || pcxt-&gt;nworkers == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; size = offsetof(SharedHashInfo, hinstrument) +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pcxt-&gt;nworkers * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashInstrumentation);<br/></li>
<li>&nbsp; &nbsp; node-&gt;shared_info = (SharedHashInfo *) <a href="../storage/ipc/shm_toc.c.html#L88" title="storage/ipc/shm_toc.c:88">shm_toc_allocate</a>(pcxt-&gt;toc, size);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Each per-worker area must start out as zeroes. */<br/></li>
<li></span>&nbsp; &nbsp; memset(node-&gt;shared_info, <span class="Constant">0</span>, size);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; node-&gt;shared_info-&gt;num_workers = pcxt-&gt;nworkers;<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L171" title="storage/ipc/shm_toc.c:171">shm_toc_insert</a>(pcxt-&gt;toc, node-&gt;ps.plan-&gt;plan_node_id,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; node-&gt;shared_info);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Locate the DSM space for <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table instrumentation data that we'll write<br/></li>
<li></span><span class="Comment"> * to at shutdown time.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2778">&#x200c;</a></span><span class="linkable">ExecHashInitializeWorker</span>(HashState *node, ParallelWorkerContext *pwcxt)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; SharedHashInfo *shared_info;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* don't need this if not instrumenting */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!node-&gt;ps.instrument)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Find our entry in the shared area, and set up a pointer to it so that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * we'll accumulate stats there when shutting down or rebuilding the <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * table.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; shared_info = (SharedHashInfo *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L232" title="storage/ipc/shm_toc.c:232">shm_toc_lookup</a>(pwcxt-&gt;toc, node-&gt;ps.plan-&gt;plan_node_id, <span class="Constant">false</span>);<br/></li>
<li>&nbsp; &nbsp; node-&gt;hinstrument = &amp;shared_info-&gt;hinstrument[<a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a>];<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Collect EXPLAIN stats if needed, saving them into DSM memory if<br/></li>
<li></span><span class="Comment"> * <a href="#L2778" title="executor/nodeHash.c:2778">ExecHashInitializeWorker</a> was called, or local storage if not.&nbsp; In the<br/></li>
<li></span><span class="Comment"> * parallel case, this must be done in <a href="#L2804" title="executor/nodeHash.c:2804">ExecShutdownHash</a>() rather than<br/></li>
<li></span><span class="Comment"> * <a href="#L413" title="executor/nodeHash.c:413">ExecEndHash</a>() because the latter runs after we've detached from the DSM<br/></li>
<li></span><span class="Comment"> * segment.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2804">&#x200c;</a></span><span class="linkable">ExecShutdownHash</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Allocate save space if EXPLAIN'ing and we didn't do so already */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (node-&gt;ps.instrument &amp;&amp; !node-&gt;hinstrument)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; node-&gt;hinstrument = palloc0_object(HashInstrumentation);<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Now accumulate data for the current (final) <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (node-&gt;hinstrument &amp;&amp; node-&gt;hashtable)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L2850" title="executor/nodeHash.c:2850">ExecHashAccumInstrumentation</a>(node-&gt;hinstrument, node-&gt;hashtable);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Retrieve instrumentation data from workers <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> the DSM segment is<br/></li>
<li></span><span class="Comment"> * detached, so that EXPLAIN can access it.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2819">&#x200c;</a></span><span class="linkable">ExecHashRetrieveInstrumentation</span>(HashState *node)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; SharedHashInfo *shared_info = node-&gt;shared_info;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; size;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (shared_info == <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Replace node-&gt;shared_info with a copy in backend-local memory. */<br/></li>
<li></span>&nbsp; &nbsp; size = offsetof(SharedHashInfo, hinstrument) +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; shared_info-&gt;num_workers * <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(HashInstrumentation);<br/></li>
<li>&nbsp; &nbsp; node-&gt;shared_info = <a href="../utils/mmgr/mcxt.c.html#L1316" title="utils/mmgr/mcxt.c:1316">palloc</a>(size);<br/></li>
<li>&nbsp; &nbsp; memcpy(node-&gt;shared_info, shared_info, size);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Accumulate instrumentation data from 'hashtable' into an<br/></li>
<li></span><span class="Comment"> * initially-zeroed HashInstrumentation struct.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * This is used to <a href="../lib/pairingheap.c.html#L79" title="lib/pairingheap.c:79">merge</a> information across successive <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table instances<br/></li>
<li></span><span class="Comment"> * within a single plan node.&nbsp; We take the maximum <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a> of each interesting<br/></li>
<li></span><span class="Comment"> * number.&nbsp; The largest nbuckets and largest nbatch <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a> might have occurred<br/></li>
<li></span><span class="Comment"> * in different instances, so there's some risk of confusion from reporting<br/></li>
<li></span><span class="Comment"> * unrelated numbers; but there's a bigger risk of misdiagnosing a performance<br/></li>
<li></span><span class="Comment"> * issue if we don't report the largest <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a>.&nbsp; Similarly, we want to report<br/></li>
<li></span><span class="Comment"> * the largest spacePeak regardless of whether it happened in the same<br/></li>
<li></span><span class="Comment"> * instance as the largest nbuckets or nbatch.&nbsp; All the instances should have<br/></li>
<li></span><span class="Comment"> * the same nbuckets_original and nbatch_original; but there's little value<br/></li>
<li></span><span class="Comment"> * in depending on that here, so handle them the same way.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L2850">&#x200c;</a></span><span class="linkable">ExecHashAccumInstrumentation</span>(HashInstrumentation *instrument,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; instrument-&gt;nbuckets = Max(instrument-&gt;nbuckets,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;nbuckets);<br/></li>
<li>&nbsp; &nbsp; instrument-&gt;nbuckets_original = Max(instrument-&gt;nbuckets_original,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets_original);<br/></li>
<li>&nbsp; &nbsp; instrument-&gt;nbatch = Max(instrument-&gt;nbatch,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;nbatch);<br/></li>
<li>&nbsp; &nbsp; instrument-&gt;nbatch_original = Max(instrument-&gt;nbatch_original,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbatch_original);<br/></li>
<li>&nbsp; &nbsp; instrument-&gt;space_peak = Max(instrument-&gt;space_peak,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; hashtable-&gt;spacePeak);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Allocate 'size' bytes from the currently active HashMemoryChunk<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void</span> *<br/></li>
<li><a id="L2869">&#x200c;</a><span class="linkable">dense_alloc</span>(HashJoinTable hashtable, Size size)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk newChunk;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp;&nbsp; *ptr;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* just in case the size is not already aligned properly */<br/></li>
<li></span>&nbsp; &nbsp; size = MAXALIGN(size);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If tuple size is larger than threshold, allocate a separate chunk.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (size &gt; HASH_CHUNK_THRESHOLD)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allocate new chunk and put it at the beginning of the list */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; newChunk = (HashMemoryChunk) <a href="../utils/mmgr/mcxt.c.html#L1180" title="utils/mmgr/mcxt.c:1180">MemoryContextAlloc</a>(hashtable-&gt;batchCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HASH_CHUNK_HEADER_SIZE + size);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;maxlen = size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;used = size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;ntuples = <span class="Constant">1</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Add this chunk to the list after the first existing chunk, so that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * we don't lose the remaining space in the &quot;current&quot; chunk.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;chunks != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> = hashtable-&gt;chunks-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;chunks-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = newChunk;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;chunks;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;chunks = newChunk;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> HASH_CHUNK_DATA(newChunk);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * See if we have enough space for it in the current chunk (if <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a>). If<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * not, allocate a fresh chunk.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> ((hashtable-&gt;chunks == <span class="Constant">NULL</span>) ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; (hashtable-&gt;chunks-&gt;maxlen - hashtable-&gt;chunks-&gt;used) &lt; size)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* allocate new chunk and put it at the beginning of the list */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; newChunk = (HashMemoryChunk) <a href="../utils/mmgr/mcxt.c.html#L1180" title="utils/mmgr/mcxt.c:1180">MemoryContextAlloc</a>(hashtable-&gt;batchCxt,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HASH_CHUNK_HEADER_SIZE + HASH_CHUNK_SIZE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;maxlen = HASH_CHUNK_SIZE;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;used = size;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;ntuples = <span class="Constant">1</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; newChunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.unshared = hashtable-&gt;chunks;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;chunks = newChunk;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> HASH_CHUNK_DATA(newChunk);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* There is enough space in the current chunk, let's add the tuple */<br/></li>
<li></span>&nbsp; &nbsp; ptr = HASH_CHUNK_DATA(hashtable-&gt;chunks) + hashtable-&gt;chunks-&gt;used;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;chunks-&gt;used += size;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;chunks-&gt;ntuples += <span class="Constant">1</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* return pointer to the start of the tuple memory */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> ptr;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Allocate space for a tuple in shared dense storage.&nbsp; This is equivalent to<br/></li>
<li></span><span class="Comment"> * <a href="#L2869" title="executor/nodeHash.c:2869">dense_alloc</a> but for Parallel Hash using shared memory.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * While loading a tuple into shared memory, we might run out of memory and<br/></li>
<li></span><span class="Comment"> * decide to repartition, or determine that the load factor is too high and<br/></li>
<li></span><span class="Comment"> * decide to expand the bucket array, or discover that another participant has<br/></li>
<li></span><span class="Comment"> * commanded us to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> do that.&nbsp; Return NULL if number of buckets or batches<br/></li>
<li></span><span class="Comment"> * has changed, indicating that the caller must retry (considering the<br/></li>
<li></span><span class="Comment"> * possibility that the tuple no longer belongs in the same batch).<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> HashJoinTuple<br/></li>
<li><a id="L2949">&#x200c;</a><span class="linkable">ExecParallelHashTupleAlloc</span>(HashJoinTable hashtable, <span class="Type">size_t</span> size,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; dsa_pointer *shared)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; dsa_pointer chunk_shared;<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk chunk;<br/></li>
<li>&nbsp; &nbsp; Size&nbsp; &nbsp; &nbsp; &nbsp; chunk_size;<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple result;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; curbatch = hashtable-&gt;curbatch;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; size = MAXALIGN(size);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Fast path: if there is enough space in this backend's current chunk,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * then we can allocate without <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> locking.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; chunk = hashtable-&gt;current_chunk;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (chunk != <span class="Constant">NULL</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; size &lt;= HASH_CHUNK_THRESHOLD &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; chunk-&gt;maxlen - chunk-&gt;used &gt;= size)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; chunk_shared = hashtable-&gt;current_chunk_shared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(chunk == <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, chunk_shared));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *shared = chunk_shared + HASH_CHUNK_HEADER_SIZE + chunk-&gt;used;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; result = (HashJoinTuple) (HASH_CHUNK_DATA(chunk) + chunk-&gt;used);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; chunk-&gt;used += size;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(chunk-&gt;used &lt;= chunk-&gt;maxlen);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(result == <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, *shared));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> result;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Slow path: try to allocate a new chunk. */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1170" title="storage/lmgr/lwlock.c:1170">LWLockAcquire</a>(&amp;pstate-&gt;lock, LW_EXCLUSIVE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Check if we need to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> increase the number of buckets or batches.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (pstate-&gt;growth == PHJ_GROWTH_NEED_MORE_BATCHES ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth == PHJ_GROWTH_NEED_MORE_BUCKETS)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashGrowth growth = pstate-&gt;growth;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;current_chunk = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Another participant has commanded us to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> grow. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (growth == PHJ_GROWTH_NEED_MORE_BATCHES)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1080" title="executor/nodeHash.c:1080">ExecParallelHashIncreaseNumBatches</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (growth == PHJ_GROWTH_NEED_MORE_BUCKETS)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1525" title="executor/nodeHash.c:1525">ExecParallelHashIncreaseNumBuckets</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* The caller must retry. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Oversized tuples get their own chunk. */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (size &gt; HASH_CHUNK_THRESHOLD)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; chunk_size = size + HASH_CHUNK_HEADER_SIZE;<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; chunk_size = HASH_CHUNK_SIZE;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Check if it's time to grow batches or buckets. */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (pstate-&gt;growth != PHJ_GROWTH_DISABLED)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(curbatch == <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;build_barrier) == PHJ_BUILD_HASH_INNER);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Check if our space limit would be exceeded.&nbsp; To avoid choking on<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * very large tuples or very low hash_mem setting, we'll always allow<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * each backend to allocate at least one chunk.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;batches[<span class="Constant">0</span>].at_least_one_chunk &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;size +<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; chunk_size &gt; pstate-&gt;space_allowed)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_NEED_MORE_BATCHES;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;space_exhausted = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Check if our load factor limit would be exceeded. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbatch == <span class="Constant">1</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;ntuples += hashtable-&gt;batches[<span class="Constant">0</span>].ntuples;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[<span class="Constant">0</span>].ntuples = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Guard against integer overflow and alloc size overflow */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;batches[<span class="Constant">0</span>].shared-&gt;ntuples + <span class="Constant">1</span> &gt;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets * <a href="#L672" title="executor/nodeHash.c:672">NTUP_PER_BUCKET</a> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets &lt; (<span class="Constant">INT_MAX</span> / <span class="Constant">2</span>) &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;nbuckets * <span class="Constant">2</span> &lt;=<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; MaxAllocSize / <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_NEED_MORE_BUCKETS;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* We are cleared to allocate a new chunk. */<br/></li>
<li></span>&nbsp; &nbsp; chunk_shared = dsa_allocate(hashtable-&gt;area, chunk_size);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches[curbatch].shared-&gt;size += chunk_size;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches[curbatch].at_least_one_chunk = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set up the chunk. */<br/></li>
<li></span>&nbsp; &nbsp; chunk = (HashMemoryChunk) <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, chunk_shared);<br/></li>
<li>&nbsp; &nbsp; *shared = chunk_shared + HASH_CHUNK_HEADER_SIZE;<br/></li>
<li>&nbsp; &nbsp; chunk-&gt;maxlen = chunk_size - HASH_CHUNK_HEADER_SIZE;<br/></li>
<li>&nbsp; &nbsp; chunk-&gt;used = size;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Push it onto the list of chunks, so that it can be found if we need to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * increase the number of buckets or batches (batch 0 only) and later for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * freeing the memory (all batches).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; chunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.shared = hashtable-&gt;batches[curbatch].shared-&gt;chunks;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches[curbatch].shared-&gt;chunks = chunk_shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (size &lt;= HASH_CHUNK_THRESHOLD)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Make this the current chunk so that we can use the fast path to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * fill the rest of it up in future calls.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;current_chunk = chunk;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;current_chunk_shared = chunk_shared;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(HASH_CHUNK_DATA(chunk) == <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, *shared));<br/></li>
<li>&nbsp; &nbsp; result = (HashJoinTuple) HASH_CHUNK_DATA(chunk);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> result;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * One backend needs to set up the shared batch state including tuplestores.<br/></li>
<li></span><span class="Comment"> * Other backends will ensure they have correctly configured accessors by<br/></li>
<li></span><span class="Comment"> * called <a href="#L3198" title="executor/nodeHash.c:3198">ExecParallelHashEnsureBatchAccessors</a>().<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L3097">&#x200c;</a></span><span class="linkable">ExecParallelHashJoinSetUpBatches</span>(HashJoinTable hashtable, <span class="Type">int</span> nbatch)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinBatch *batches;<br/></li>
<li>&nbsp; &nbsp; MemoryContext oldcxt;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;batches == <span class="Constant">NULL</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Allocate space. */<br/></li>
<li></span>&nbsp; &nbsp; pstate-&gt;batches =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; dsa_allocate0(hashtable-&gt;area,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; EstimateParallelHashJoinBatch(hashtable) * nbatch);<br/></li>
<li>&nbsp; &nbsp; pstate-&gt;nbatch = nbatch;<br/></li>
<li>&nbsp; &nbsp; batches = <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, pstate-&gt;batches);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Use <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> join spill memory context to allocate accessors, including<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * buffers for the temporary files.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; oldcxt = MemoryContextSwitchTo(hashtable-&gt;spillCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Allocate this backend's accessor array. */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;nbatch = nbatch;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; palloc0_array(ParallelHashJoinBatchAccessor, hashtable-&gt;nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set up the shared state, tuplestores and backend-local accessors. */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatchAccessor *accessor = &amp;hashtable-&gt;batches[i];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatch *shared = NthParallelHashJoinBatch(batches, i);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp; &nbsp; name[MAXPGPATH];<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * All members of shared were zero-initialized.&nbsp; We just need to set<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * up the Barrier.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L100" title="storage/ipc/barrier.c:100">BarrierInit</a>(&amp;shared-&gt;batch_barrier, <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (i == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Batch 0 doesn't need to be loaded. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L236" title="storage/ipc/barrier.c:236">BarrierAttach</a>(&amp;shared-&gt;batch_barrier);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;shared-&gt;batch_barrier) &lt; PHJ_BATCH_PROBE)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L125" title="storage/ipc/barrier.c:125">BarrierArriveAndWait</a>(&amp;shared-&gt;batch_barrier, <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/barrier.c.html#L256" title="storage/ipc/barrier.c:256">BarrierDetach</a>(&amp;shared-&gt;batch_barrier);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Initialize accessor state.&nbsp; All members were zero-initialized. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;shared = shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Initialize the shared tuplestores. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; snprintf(name, <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(name), <span class="Constant">&quot;i</span><span class="Special">%d</span><span class="Constant">of</span><span class="Special">%d</span><span class="Constant">&quot;</span>, i, hashtable-&gt;nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;inner_tuples =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L126" title="utils/sort/sharedtuplestore.c:126">sts_initialize</a>(ParallelHashJoinBatchInner(shared),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; pstate-&gt;nparticipants,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a> + <span class="Constant">1</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(uint32),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; SHARED_TUPLESTORE_SINGLE_PASS,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;pstate-&gt;fileset,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; name);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; snprintf(name, <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(name), <span class="Constant">&quot;o</span><span class="Special">%d</span><span class="Constant">of</span><span class="Special">%d</span><span class="Constant">&quot;</span>, i, hashtable-&gt;nbatch);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;outer_tuples =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L126" title="utils/sort/sharedtuplestore.c:126">sts_initialize</a>(ParallelHashJoinBatchOuter(shared,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;nparticipants),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; pstate-&gt;nparticipants,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a> + <span class="Constant">1</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(uint32),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; SHARED_TUPLESTORE_SINGLE_PASS,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;pstate-&gt;fileset,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; name);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; MemoryContextSwitchTo(oldcxt);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Free the current set of ParallelHashJoinBatchAccessor objects.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L3177">&#x200c;</a></span><span class="linkable">ExecParallelHashCloseBatchAccessors</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Make sure no files are left open. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L213" title="utils/sort/sharedtuplestore.c:213">sts_end_write</a>(hashtable-&gt;batches[i].inner_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L213" title="utils/sort/sharedtuplestore.c:213">sts_end_write</a>(hashtable-&gt;batches[i].outer_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[i].inner_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[i].outer_tuples);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(hashtable-&gt;batches);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches = <span class="Constant">NULL</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Make sure this backend has up-to-date accessors for the current set of<br/></li>
<li></span><span class="Comment"> * batches.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L3198">&#x200c;</a></span><span class="linkable">ExecParallelHashEnsureBatchAccessors</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinBatch *batches;<br/></li>
<li>&nbsp; &nbsp; MemoryContext oldcxt;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;batches != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;nbatch == pstate-&gt;nbatch)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L3177" title="executor/nodeHash.c:3177">ExecParallelHashCloseBatchAccessors</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We should never see a state where the batch-tracking array is freed,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * because we should have given up sooner if we join when the build<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * barrier has reached the PHJ_BUILD_FREE phase.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Assert(DsaPointerIsValid(pstate-&gt;batches));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Use <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> join spill memory context to allocate accessors, including<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * buffers for the temporary files.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; oldcxt = MemoryContextSwitchTo(hashtable-&gt;spillCxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Allocate this backend's accessor array. */<br/></li>
<li></span>&nbsp; &nbsp; hashtable-&gt;nbatch = pstate-&gt;nbatch;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; palloc0_array(ParallelHashJoinBatchAccessor, hashtable-&gt;nbatch);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Find the base of the pseudo-array of ParallelHashJoinBatch objects. */<br/></li>
<li></span>&nbsp; &nbsp; batches = (ParallelHashJoinBatch *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, pstate-&gt;batches);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set up the accessor array and attach to the tuplestores. */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatchAccessor *accessor = &amp;hashtable-&gt;batches[i];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatch *shared = NthParallelHashJoinBatch(batches, i);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;shared = shared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;preallocated = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;done = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;outer_eof = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;inner_tuples =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L178" title="utils/sort/sharedtuplestore.c:178">sts_attach</a>(ParallelHashJoinBatchInner(shared),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a> + <span class="Constant">1</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;pstate-&gt;fileset);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; accessor-&gt;outer_tuples =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L178" title="utils/sort/sharedtuplestore.c:178">sts_attach</a>(ParallelHashJoinBatchOuter(shared,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;nparticipants),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a> + <span class="Constant">1</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &amp;pstate-&gt;fileset);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; MemoryContextSwitchTo(oldcxt);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Allocate an empty shared memory <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> table for a given batch.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L3262">&#x200c;</a></span><span class="linkable">ExecParallelHashTableAlloc</span>(HashJoinTable hashtable, <span class="Type">int</span> batchno)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinBatch *batch = hashtable-&gt;batches[batchno].shared;<br/></li>
<li>&nbsp; &nbsp; dsa_pointer_atomic *buckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nbuckets = hashtable-&gt;parallel_state-&gt;nbuckets;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; batch-&gt;buckets =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; dsa_allocate(hashtable-&gt;area, <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic) * nbuckets);<br/></li>
<li>&nbsp; &nbsp; buckets = (dsa_pointer_atomic *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, batch-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; nbuckets; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer_atomic_init(&amp;buckets[i], InvalidDsaPointer);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * If we are currently attached to a shared <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a> join batch, detach.&nbsp; If we<br/></li>
<li></span><span class="Comment"> * are last to detach, clean up.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L3282">&#x200c;</a></span><span class="linkable">ExecHashTableDetachBatch</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;parallel_state != <span class="Constant">NULL</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;curbatch &gt;= <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; curbatch = hashtable-&gt;curbatch;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashJoinBatch *batch = hashtable-&gt;batches[curbatch].shared;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; attached = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Make sure <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> temporary files are closed. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[curbatch].inner_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[curbatch].outer_tuples);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* After attaching we always get at least to PHJ_BATCH_PROBE. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_PROBE ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_SCAN);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * If we're abandoning the PHJ_BATCH_PROBE phase early without having<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * reached the end of it, it means the plan doesn't want <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> more<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * tuples, and it is happy to abandon <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> tuples buffered in this<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * process's subplans.&nbsp; For correctness, we can't allow <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> process to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * execute the PHJ_BATCH_SCAN phase, because we will never have the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * complete set of match bits.&nbsp; Therefore we <a href="../regex/regc_lex.c.html#L982" title="regex/regc_lex.c:982">skip</a> emitting unmatched<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * tuples in all backends (if this is a full/right join), as if those<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * tuples were all due to be emitted by this process and it has<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * abandoned them too.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_PROBE &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; !hashtable-&gt;batches[curbatch].outer_eof)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * This flag may be written to by multiple backends during<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * PHJ_BATCH_PROBE phase, but will only be read in PHJ_BATCH_SCAN<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * phase so requires no extra locking.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;skip_unmatched = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Even if we aren't doing a full/right outer join, we'll step through<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * the PHJ_BATCH_SCAN phase just to maintain the invariant that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * freeing happens in PHJ_BATCH_FREE, but that'll be wait-free.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_PROBE)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; attached = <a href="../storage/ipc/barrier.c.html#L213" title="storage/ipc/barrier.c:213">BarrierArriveAndDetachExceptLast</a>(&amp;batch-&gt;batch_barrier);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (attached &amp;&amp; <a href="../storage/ipc/barrier.c.html#L203" title="storage/ipc/barrier.c:203">BarrierArriveAndDetach</a>(&amp;batch-&gt;batch_barrier))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We are not longer attached to the batch barrier, but we're the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * process that was chosen to free resources and it's safe to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * assert the current phase.&nbsp; The ParallelHashJoinBatch can't go<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * away underneath us while we are attached to the build barrier,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * making this access safe.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;batch-&gt;batch_barrier) == PHJ_BATCH_FREE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Free shared chunks and buckets. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">while</span> (DsaPointerIsValid(batch-&gt;chunks))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashMemoryChunk chunk =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, batch-&gt;chunks);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> = chunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, batch-&gt;chunks);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;chunks = <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (DsaPointerIsValid(batch-&gt;buckets))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, batch-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;buckets = InvalidDsaPointer;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Track the largest batch we've been attached to.&nbsp; Though each<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * backend might see a different <a href="../regex/regexec.c.html#L702" title="regex/regexec.c:702">subset</a> of batches, explain.c will<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * scan the results from all backends to <a href="../regex/regexec.c.html#L419" title="regex/regexec.c:419">find</a> the largest value.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;spacePeak =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Max(hashtable-&gt;spacePeak,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;size + <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(dsa_pointer_atomic) * hashtable-&gt;nbuckets);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Remember that we are not attached to a batch. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;curbatch = -<span class="Constant">1</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Detach from all shared resources.&nbsp; If we are last to detach, clean up.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L3374">&#x200c;</a></span><span class="linkable">ExecHashTableDetach</span>(HashJoinTable hashtable)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If we're involved in a parallel query, we must either have gotten all<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * the way to PHJ_BUILD_RUN, or joined too late and be in PHJ_BUILD_FREE.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Assert(!pstate ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;build_barrier) &gt;= PHJ_BUILD_RUN);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (pstate &amp;&amp; <a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;build_barrier) == PHJ_BUILD_RUN)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Make sure <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> temporary files are closed. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (hashtable-&gt;batches)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (i = <span class="Constant">0</span>; i &lt; hashtable-&gt;nbatch; ++i)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L213" title="utils/sort/sharedtuplestore.c:213">sts_end_write</a>(hashtable-&gt;batches[i].inner_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L213" title="utils/sort/sharedtuplestore.c:213">sts_end_write</a>(hashtable-&gt;batches[i].outer_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[i].inner_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/sort/sharedtuplestore.c.html#L281" title="utils/sort/sharedtuplestore.c:281">sts_end_parallel_scan</a>(hashtable-&gt;batches[i].outer_tuples);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* If we're last to detach, clean up shared memory. */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="../storage/ipc/barrier.c.html#L203" title="storage/ipc/barrier.c:203">BarrierArriveAndDetach</a>(&amp;pstate-&gt;build_barrier))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Late joining processes will see this state and give up<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * immediately.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Assert(<a href="../storage/ipc/barrier.c.html#L265" title="storage/ipc/barrier.c:265">BarrierPhase</a>(&amp;pstate-&gt;build_barrier) == PHJ_BUILD_FREE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (DsaPointerIsValid(pstate-&gt;batches))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L826" title="utils/mmgr/dsa.c:826">dsa_free</a>(hashtable-&gt;area, pstate-&gt;batches);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;batches = InvalidDsaPointer;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;parallel_state = <span class="Constant">NULL</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Get the first tuple in a given bucket identified by number.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">inline</span> HashJoinTuple<br/></li>
<li><a id="L3424">&#x200c;</a><span class="linkable">ExecParallelHashFirstTuple</span>(HashJoinTable hashtable, <span class="Type">int</span> bucketno)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple tuple;<br/></li>
<li>&nbsp; &nbsp; dsa_pointer p;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;parallel_state);<br/></li>
<li>&nbsp; &nbsp; p = dsa_pointer_atomic_read(&amp;hashtable-&gt;buckets.shared[bucketno]);<br/></li>
<li>&nbsp; &nbsp; tuple = (HashJoinTuple) <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, p);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> tuple;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Get the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> tuple in the same bucket as 'tuple'.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">inline</span> HashJoinTuple<br/></li>
<li><a id="L3440">&#x200c;</a><span class="linkable">ExecParallelHashNextTuple</span>(HashJoinTable hashtable, HashJoinTuple tuple)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; HashJoinTuple <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;parallel_state);<br/></li>
<li>&nbsp; &nbsp; <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> = (HashJoinTuple) <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, tuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.shared);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * <a href="../storage/file/fd.c.html#L1313" title="storage/file/fd.c:1313">Insert</a> a tuple at the front of a chain of tuples in DSA memory atomically.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">inline</span> <span class="Type">void<br/></li>
<li><a id="L3454">&#x200c;</a></span><span class="linkable">ExecParallelHashPushTuple</span>(dsa_pointer_atomic *head,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; HashJoinTuple tuple,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dsa_pointer tuple_shared)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (;;)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; tuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.shared = dsa_pointer_atomic_read(head);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (dsa_pointer_atomic_compare_exchange(head,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;tuple-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.shared,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tuple_shared))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Prepare to work on a given batch.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L3472">&#x200c;</a></span><span class="linkable">ExecParallelHashTableSetCurrentBatch</span>(HashJoinTable hashtable, <span class="Type">int</span> batchno)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; Assert(hashtable-&gt;batches[batchno].shared-&gt;buckets != InvalidDsaPointer);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;curbatch = batchno;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;buckets.shared = (dsa_pointer_atomic *)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashtable-&gt;batches[batchno].shared-&gt;buckets);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;nbuckets = hashtable-&gt;parallel_state-&gt;nbuckets;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;log2_nbuckets = <a href="../utils/hash/dynahash.c.html#L1751" title="utils/hash/dynahash.c:1751">my_log2</a>(hashtable-&gt;nbuckets);<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;current_chunk = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;current_chunk_shared = InvalidDsaPointer;<br/></li>
<li>&nbsp; &nbsp; hashtable-&gt;batches[batchno].at_least_one_chunk = <span class="Constant">false</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Take the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> available chunk from the queue of chunks being worked on in<br/></li>
<li></span><span class="Comment"> * parallel.&nbsp; Return NULL if there are <a href="../optimizer/util/predtest.c.html#L1670" title="optimizer/util/predtest.c:1670">none</a> left.&nbsp; Otherwise return a pointer<br/></li>
<li></span><span class="Comment"> * to the chunk, and set *shared to the DSA pointer to the chunk.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> HashMemoryChunk<br/></li>
<li><a id="L3493">&#x200c;</a><span class="linkable">ExecParallelHashPopChunkQueue</span>(HashJoinTable hashtable, dsa_pointer *shared)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; HashMemoryChunk chunk;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1170" title="storage/lmgr/lwlock.c:1170">LWLockAcquire</a>(&amp;pstate-&gt;lock, LW_EXCLUSIVE);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (DsaPointerIsValid(pstate-&gt;chunk_work_queue))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; *shared = pstate-&gt;chunk_work_queue;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; chunk = (HashMemoryChunk)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/dsa.c.html#L942" title="utils/mmgr/dsa.c:942">dsa_get_address</a>(hashtable-&gt;area, *shared);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;chunk_work_queue = chunk-&gt;<a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a>.shared;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; chunk = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> chunk;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Increase the space preallocated in this backend for a given inner batch by<br/></li>
<li></span><span class="Comment"> * at least a given amount.&nbsp; This allows us to track whether a given batch<br/></li>
<li></span><span class="Comment"> * would fit in memory when loaded back in.&nbsp; Also increase the number of<br/></li>
<li></span><span class="Comment"> * batches or buckets if required.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * This maintains a running estimation of how much space will be taken when we<br/></li>
<li></span><span class="Comment"> * load the batch back into memory by simulating the way chunks will be handed<br/></li>
<li></span><span class="Comment"> * out to workers.&nbsp; It's not perfectly accurate because the tuples will be<br/></li>
<li></span><span class="Comment"> * packed into memory chunks differently by <a href="#L2949" title="executor/nodeHash.c:2949">ExecParallelHashTupleAlloc</a>(), but<br/></li>
<li></span><span class="Comment"> * it should be pretty close.&nbsp; It tends to overestimate by a fraction of a<br/></li>
<li></span><span class="Comment"> * chunk per worker since all workers gang up to preallocate during hashing,<br/></li>
<li></span><span class="Comment"> * but workers tend to reload batches alone if there are enough to go around,<br/></li>
<li></span><span class="Comment"> * leaving fewer partially filled chunks.&nbsp; This effect is bounded by<br/></li>
<li></span><span class="Comment"> * nparticipants.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Return false if the number of batches or buckets has changed, and the<br/></li>
<li></span><span class="Comment"> * caller should reconsider which batch a given tuple <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a> belongs in and call<br/></li>
<li></span><span class="Comment"> * again.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L3534">&#x200c;</a></span><span class="linkable">ExecParallelHashTuplePrealloc</span>(HashJoinTable hashtable, <span class="Type">int</span> batchno, <span class="Type">size_t</span> size)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinState *pstate = hashtable-&gt;parallel_state;<br/></li>
<li>&nbsp; &nbsp; ParallelHashJoinBatchAccessor *batch = &amp;hashtable-&gt;batches[batchno];<br/></li>
<li>&nbsp; &nbsp; <span class="Type">size_t</span>&nbsp; &nbsp; &nbsp; &nbsp; want = Max(size, HASH_CHUNK_SIZE - HASH_CHUNK_HEADER_SIZE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(batchno &gt; <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; Assert(batchno &lt; hashtable-&gt;nbatch);<br/></li>
<li>&nbsp; &nbsp; Assert(size == MAXALIGN(size));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1170" title="storage/lmgr/lwlock.c:1170">LWLockAcquire</a>(&amp;pstate-&gt;lock, LW_EXCLUSIVE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Has another participant commanded us to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> grow? */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (pstate-&gt;growth == PHJ_GROWTH_NEED_MORE_BATCHES ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth == PHJ_GROWTH_NEED_MORE_BUCKETS)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ParallelHashGrowth growth = pstate-&gt;growth;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (growth == PHJ_GROWTH_NEED_MORE_BATCHES)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1080" title="executor/nodeHash.c:1080">ExecParallelHashIncreaseNumBatches</a>(hashtable);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else</span> <span class="Statement">if</span> (growth == PHJ_GROWTH_NEED_MORE_BUCKETS)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L1525" title="executor/nodeHash.c:1525">ExecParallelHashIncreaseNumBuckets</a>(hashtable);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (pstate-&gt;growth != PHJ_GROWTH_DISABLED &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;at_least_one_chunk &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; (batch-&gt;shared-&gt;estimated_size + want + HASH_CHUNK_HEADER_SIZE<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &gt; pstate-&gt;space_allowed))<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * We have determined that this batch would exceed the space budget if<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * loaded into memory.&nbsp; Command all participants to <a href="../main/main.c.html#L320" title="main/main.c:320">help</a> repartition.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; batch-&gt;shared-&gt;space_exhausted = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pstate-&gt;growth = PHJ_GROWTH_NEED_MORE_BATCHES;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; batch-&gt;at_least_one_chunk = <span class="Constant">true</span>;<br/></li>
<li>&nbsp; &nbsp; batch-&gt;shared-&gt;estimated_size += want + HASH_CHUNK_HEADER_SIZE;<br/></li>
<li>&nbsp; &nbsp; batch-&gt;preallocated = want;<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/lmgr/lwlock.c.html#L1783" title="storage/lmgr/lwlock.c:1783">LWLockRelease</a>(&amp;pstate-&gt;lock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Calculate the limit on how much memory can be used by Hash and similar<br/></li>
<li></span><span class="Comment"> * plan types.&nbsp; This is <a href="../utils/init/globals.c.html#L128" title="utils/init/globals.c:128">work_mem</a> times <a href="../utils/init/globals.c.html#L129" title="utils/init/globals.c:129">hash_mem_multiplier</a>, and is<br/></li>
<li></span><span class="Comment"> * expressed in bytes.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Exported for use by the <a href="../optimizer/plan/planner.c.html#L274" title="optimizer/plan/planner.c:274">planner</a>, as well as other <a href="../regex/rege_dfa.c.html#L715" title="regex/rege_dfa.c:715">hash</a>-like executor<br/></li>
<li></span><span class="Comment"> * nodes.&nbsp; This is a rather random place for this, but there is no better<br/></li>
<li></span><span class="Comment"> * place.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">size_t<br/></li>
<li><a id="L3595">&#x200c;</a></span><span class="linkable">get_hash_memory_limit</span>(<span class="Type">void</span>)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; mem_limit;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Do initial calculation in double arithmetic */<br/></li>
<li></span>&nbsp; &nbsp; mem_limit = (<span class="Type">double</span>) <a href="../utils/init/globals.c.html#L128" title="utils/init/globals.c:128">work_mem</a> * <a href="../utils/init/globals.c.html#L129" title="utils/init/globals.c:129">hash_mem_multiplier</a> * <span class="Constant">1024.0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Clamp in case it doesn't fit in size_t */<br/></li>
<li></span>&nbsp; &nbsp; mem_limit = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(mem_limit, (<span class="Type">double</span>) <span class="Constant">SIZE_MAX</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> (<span class="Type">size_t</span>) mem_limit;<br/></li>
<li>}<br/></li>
</ol></code>
 <p class="nav-bar">
  <span class="nav-link"><a href="./index.html">One Level Up</a></span>
  <span class="nav-link"><a href="../index.html">Top Level</a></span>
 </p>

 </body>
</html>
