<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>commands/vacuumparallel.c - pgsql17devel-backend</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

.nav-bar {
    font-size: 120%;
    margin-top: 5px;
    margin-bottom: 5px;
}

.nav-link {
    padding-left: 5em;
    padding-right: 5em;
}

ul.toc {
    line-height: 200%;
    font-size: 150%;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}

span.Constant {
    color: DarkGreen;
}

span.Special {
    color: #c06000;
}

span.Comment {
    color: DarkRed;
    font-style: italic;
}

span.Identifier {
    color: DarkCyan;
}

span.PreProc {
    color: DarkMagenta;
}

span.Statement, span.Type, span.Keyword, span.Repeat, span.Conditional,
    span.Operator, span.Exception
{
    color: DarkBlue;
}

span.Todo {
    color: DarkRed;
    background-color: Gold;
    font-style: italic;
}

span.Underlined {
    text-decoration: underline;
}

span.linkable {
    font-weight: bold;
}

code ol {
    counter-reset: item;
    list-style-type: none;
    margin-left: 0;
    padding-left: 0;
    list-style-position: inside;
}

code li {
    display: block;
}

code li:before {
    content: counter(item) "  ";
    counter-increment: item;
    color: #999;
    padding-right: 0.5em;
    padding-left: 0.4em;
    list-style-position: inside;
    text-align: right
}

  </style>
 </head>
 <body>
 <p class="nav-bar">
  <span class="nav-link"><a href="./index.html">One Level Up</a></span>
  <span class="nav-link"><a href="../index.html">Top Level</a></span>
 </p>

  <h1>commands/vacuumparallel.c - pgsql17devel-backend</h1>
 <h2>Data types defined</h2>
 <ul class="toc">
<li><a href="#L136">PVIndStats</a></li>
<li><a href="#L156">PVIndStats</a></li>
<li><a href="#L124">PVIndVacStatus</a></li>
<li><a href="#L130">PVIndVacStatus</a></li>
<li><a href="#L57">PVShared</a></li>
<li><a href="#L121">PVShared</a></li>
<li><a href="#L161">ParallelVacuumState</a></li>
</ul>
 <h2>Functions defined</h2>
 <ul class="toc">
<li><a href="#L499">parallel_vacuum_bulkdel_all_indexes</a></li>
<li><a href="#L518">parallel_vacuum_cleanup_all_indexes</a></li>
<li><a href="#L548">parallel_vacuum_compute_workers</a></li>
<li><a href="#L434">parallel_vacuum_end</a></li>
<li><a href="#L1106">parallel_vacuum_error_callback</a></li>
<li><a href="#L465">parallel_vacuum_get_dead_items</a></li>
<li><a href="#L950">parallel_vacuum_index_is_parallel_safe</a></li>
<li><a href="#L242">parallel_vacuum_init</a></li>
<li><a href="#L988">parallel_vacuum_main</a></li>
<li><a href="#L610">parallel_vacuum_process_all_indexes</a></li>
<li><a href="#L864">parallel_vacuum_process_one_index</a></li>
<li><a href="#L773">parallel_vacuum_process_safe_indexes</a></li>
<li><a href="#L827">parallel_vacuum_process_unsafe_indexes</a></li>
<li><a href="#L473">parallel_vacuum_reset_dead_items</a></li>
</ul>
 <h2>Macros defined</h2>
 <ul class="toc">
<li><a href="#L49">PARALLEL_VACUUM_KEY_BUFFER_USAGE</a></li>
<li><a href="#L51">PARALLEL_VACUUM_KEY_INDEX_STATS</a></li>
<li><a href="#L48">PARALLEL_VACUUM_KEY_QUERY_TEXT</a></li>
<li><a href="#L47">PARALLEL_VACUUM_KEY_SHARED</a></li>
<li><a href="#L50">PARALLEL_VACUUM_KEY_WAL_USAGE</a></li>
</ul>
 <h2>Source code</h2>

  <code><ol><li><span class="Comment">/*-------------------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * vacuumparallel.c<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; Support routines for parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> execution.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * This file contains routines that are intended to support setting up, using,<br/></li>
<li></span><span class="Comment"> * and tearing down a <a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a>.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * In a parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>, we perform both index bulk deletion and index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a><br/></li>
<li></span><span class="Comment"> * with parallel worker processes.&nbsp; Individual indexes are processed by one<br/></li>
<li></span><span class="Comment"> * <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> process.&nbsp; <a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> contains shared information as well as<br/></li>
<li></span><span class="Comment"> * the memory space for storing dead items allocated in the DSA area.&nbsp; We<br/></li>
<li></span><span class="Comment"> * launch parallel worker processes at the start of parallel index<br/></li>
<li></span><span class="Comment"> * bulk-deletion and index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> and once all indexes are processed, the<br/></li>
<li></span><span class="Comment"> * parallel worker processes exit.&nbsp; Each time we process indexes in parallel,<br/></li>
<li></span><span class="Comment"> * the parallel context is re-initialized so that the same DSM can be used for<br/></li>
<li></span><span class="Comment"> * multiple passes of index bulk-deletion and index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group<br/></li>
<li></span><span class="Comment"> * Portions Copyright (c) 1994, Regents of the University of California<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * IDENTIFICATION<br/></li>
<li></span><span class="Comment"> *&nbsp; &nbsp; &nbsp; src/backend/commands/vacuumparallel.c<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> *-------------------------------------------------------------------------<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;postgres.h&quot;<br/></li>
<li></span><br/></li>
<li><span class="PreProc">#include </span><span class="Constant">&quot;access/amapi.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;access/table.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;access/xact.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;commands/progress.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;commands/<a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;executor/instrument.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;optimizer/paths.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;pgstat.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;storage/bufmgr.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;tcop/tcopprot.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/lsyscache.h&quot;<br/></li>
<li></span><span class="PreProc">#include </span><span class="Constant">&quot;utils/rel.h&quot;<br/></li>
<li></span><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * DSM keys for parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.&nbsp; Unlike other parallel execution code, since<br/></li>
<li></span><span class="Comment"> * we don't need to worry about DSM keys conflicting with plan_node_id we can<br/></li>
<li></span><span class="Comment"> * use small integers.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li><a id="L47">&#x200c;</a></span><span class="PreProc">#define <span class="linkable">PARALLEL_VACUUM_KEY_SHARED</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="Constant">1<br/></li>
<li><a id="L48">&#x200c;</a></span><span class="PreProc">#define <span class="linkable">PARALLEL_VACUUM_KEY_QUERY_TEXT</span>&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="Constant">2<br/></li>
<li><a id="L49">&#x200c;</a></span><span class="PreProc">#define <span class="linkable">PARALLEL_VACUUM_KEY_BUFFER_USAGE</span>&nbsp; &nbsp; </span><span class="Constant">3<br/></li>
<li><a id="L50">&#x200c;</a></span><span class="PreProc">#define <span class="linkable">PARALLEL_VACUUM_KEY_WAL_USAGE</span>&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="Constant">4<br/></li>
<li><a id="L51">&#x200c;</a></span><span class="PreProc">#define <span class="linkable">PARALLEL_VACUUM_KEY_INDEX_STATS</span>&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="Constant">5<br/></li>
<li></span><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Shared information among parallel workers.&nbsp; So this is allocated in the DSM<br/></li>
<li></span><span class="Comment"> * segment.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li><a id="L57">&#x200c;</a></span><span class="Type">typedef</span> <span class="Type">struct</span> <span class="linkable">PVShared</span><br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Target table relid and log level (for messages about parallel workers<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * launched during VACUUM VERBOSE).&nbsp; These fields are not modified during<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * the parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Oid&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; relid;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elevel;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Fields for both index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> and <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * reltuples is the total number of input heap tuples.&nbsp; We set either old<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * live tuples in the index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> case or the new live tuples in the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> case.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * estimated_count is true if reltuples is an estimated value.&nbsp; (Note that<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * reltuples could be -1 in this case, indicating we have no idea.)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type">double</span>&nbsp; &nbsp; &nbsp; &nbsp; reltuples;<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; estimated_count;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * In single process <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> we could consume more memory during index<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * vacuuming or <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> apart from the memory for heap scanning.&nbsp; In<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>, since individual <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers can consume memory<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../nodes/equalfuncs.c.html#L223" title="nodes/equalfuncs.c:223">equal</a> to <a href="../utils/init/globals.c.html#L130" title="utils/init/globals.c:130">maintenance_work_mem</a>, the new <a href="../utils/init/globals.c.html#L130" title="utils/init/globals.c:130">maintenance_work_mem</a> for each<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * worker is set such that the parallel operation doesn't consume more<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * memory than single process <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; maintenance_work_mem_worker;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * The number of buffers each worker's Buffer Access Strategy ring should<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * contain.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ring_nbuffers;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Shared <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> cost balance.&nbsp; During parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="vacuum.c.html#L102" title="commands/vacuum.c:102">VacuumSharedCostBalance</a> points to this value and it accumulates the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * balance of each parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; pg_atomic_uint32 cost_balance;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Number of active parallel workers.&nbsp; This is used for computing the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * minimum threshold of the <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> cost balance <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> a worker sleeps for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * cost-based delay.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; pg_atomic_uint32 active_nworkers;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Counter for vacuuming and <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> */<br/></li>
<li></span>&nbsp; &nbsp; pg_atomic_uint32 idx;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* DSA handle where the <a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a> lives */<br/></li>
<li></span>&nbsp; &nbsp; dsa_handle&nbsp; &nbsp; dead_items_dsa_handle;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* DSA pointer to the shared <a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a> */<br/></li>
<li></span>&nbsp; &nbsp; dsa_pointer dead_items_handle;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Statistics of shared dead items */<br/></li>
<li></span>&nbsp; &nbsp; VacDeadItemsInfo dead_items_info;<br/></li>
<li><a id="L121">&#x200c;</a>} <span class="linkable">PVShared</span>;<br/></li>
<li><br/></li>
<li><span class="Comment">/* Status used during parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> */<br/></li>
<li><a id="L124">&#x200c;</a></span><span class="Type">typedef</span> <span class="Type">enum</span> <span class="linkable">PVIndVacStatus</span><br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; PARALLEL_INDVAC_STATUS_INITIAL = <span class="Constant">0</span>,<br/></li>
<li>&nbsp; &nbsp; PARALLEL_INDVAC_STATUS_NEED_BULKDELETE,<br/></li>
<li>&nbsp; &nbsp; PARALLEL_INDVAC_STATUS_NEED_CLEANUP,<br/></li>
<li>&nbsp; &nbsp; PARALLEL_INDVAC_STATUS_COMPLETED,<br/></li>
<li><a id="L130">&#x200c;</a>} <span class="linkable">PVIndVacStatus</span>;<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Struct for index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> statistics of an index that is used for parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment"> * This includes the status of parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> as well as index statistics.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li><a id="L136">&#x200c;</a></span><span class="Type">typedef</span> <span class="Type">struct</span> <span class="linkable">PVIndStats</span><br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * The following two fields are set by leader process <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> executing<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or parallel index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>.&nbsp; These fields are not<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * fixed for the entire VACUUM operation.&nbsp; They are only fixed for an<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * individual parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> and <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parallel_workers_can_process is true if both leader and worker can<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * process the index, otherwise only leader can process it.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L124" title="commands/vacuumparallel.c:124">PVIndVacStatus</a> status;<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; parallel_workers_can_process;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Individual worker or leader stores the result of index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp; &nbsp; istat_updated;&nbsp; &nbsp; <span class="Comment">/* are the stats updated? */<br/></li>
<li></span>&nbsp; &nbsp; IndexBulkDeleteResult istat;<br/></li>
<li><a id="L156">&#x200c;</a>} <span class="linkable">PVIndStats</span>;<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Struct for maintaining a parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> state. typedef appears in <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.h.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li><a id="L161">&#x200c;</a></span><span class="Type">struct</span> <span class="linkable">ParallelVacuumState</span><br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* NULL for worker processes */<br/></li>
<li></span>&nbsp; &nbsp; ParallelContext *pcxt;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Parent Heap Relation */<br/></li>
<li></span>&nbsp; &nbsp; Relation&nbsp; &nbsp; heaprel;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Target indexes */<br/></li>
<li></span>&nbsp; &nbsp; Relation&nbsp;&nbsp; *indrels;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Shared information among parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L57" title="commands/vacuumparallel.c:57">PVShared</a>&nbsp;&nbsp; *shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Shared index statistics among parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers. The array<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/regc_locale.c.html#L376" title="regex/regc_locale.c:376">element</a> is allocated for every index, even those indexes where parallel<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * index vacuuming is unsafe or not worthwhile (e.g.,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * will_parallel_vacuum[] is false).&nbsp; During parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>,<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * IndexBulkDeleteResult of each index is kept in DSM and is copied into<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * local memory at the end of parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Shared dead items space among parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a>&nbsp;&nbsp; *dead_items;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Points to buffer usage area in DSM */<br/></li>
<li></span>&nbsp; &nbsp; BufferUsage *buffer_usage;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Points to WAL usage area in DSM */<br/></li>
<li></span>&nbsp; &nbsp; WalUsage&nbsp;&nbsp; *wal_usage;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * False if the index is totally unsuitable target for all parallel<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * processing. For example, the index could be &lt;<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../optimizer/path/allpaths.c.html#L82" title="optimizer/path/allpaths.c:82">min_parallel_index_scan_size</a> cutoff.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp;&nbsp; *will_parallel_vacuum;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * The number of indexes that support parallel index bulk-deletion and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parallel index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> respectively.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_bulkdel;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_cleanup;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_condcleanup;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Buffer access strategy used by leader process */<br/></li>
<li></span>&nbsp; &nbsp; BufferAccessStrategy bstrategy;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Error reporting state.&nbsp; The error callback is set only for workers<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * processes during parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp;&nbsp; *relnamespace;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp;&nbsp; *relname;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp;&nbsp; *indname;<br/></li>
<li>&nbsp; &nbsp; <a href="#L124" title="commands/vacuumparallel.c:124">PVIndVacStatus</a> status;<br/></li>
<li>};<br/></li>
<li><br/></li>
<li><span class="Type">static</span> <span class="Type">int</span>&nbsp; &nbsp; <a href="#L548" title="commands/vacuumparallel.c:548">parallel_vacuum_compute_workers</a>(Relation *indrels, <span class="Type">int</span> nindexes, <span class="Type">int</span> nrequested,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> *will_parallel_vacuum);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L610" title="commands/vacuumparallel.c:610">parallel_vacuum_process_all_indexes</a>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, <span class="Type">int</span> num_index_scans,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L773" title="commands/vacuumparallel.c:773">parallel_vacuum_process_safe_indexes</a>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L827" title="commands/vacuumparallel.c:827">parallel_vacuum_process_unsafe_indexes</a>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L864" title="commands/vacuumparallel.c:864">parallel_vacuum_process_one_index</a>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, Relation indrel,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats);<br/></li>
<li><span class="Type">static</span> <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> <a href="#L950" title="commands/vacuumparallel.c:950">parallel_vacuum_index_is_parallel_safe</a>(Relation indrel, <span class="Type">int</span> num_index_scans,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>);<br/></li>
<li><span class="Type">static</span> <span class="Type">void</span> <a href="#L1106" title="commands/vacuumparallel.c:1106">parallel_vacuum_error_callback</a>(<span class="Type">void</span> *arg);<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Try to enter parallel mode and create a parallel context.&nbsp; Then <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a><br/></li>
<li></span><span class="Comment"> * shared memory state.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * On success, return parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> state.&nbsp; Otherwise return NULL.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *<br/></li>
<li><a id="L242">&#x200c;</a><span class="linkable">parallel_vacuum_init</span>(Relation rel, Relation *indrels, <span class="Type">int</span> nindexes,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type">int</span> nrequested_workers, <span class="Type">int</span> vac_work_mem,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type">int</span> elevel, BufferAccessStrategy bstrategy)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs;<br/></li>
<li>&nbsp; &nbsp; ParallelContext *pcxt;<br/></li>
<li>&nbsp; &nbsp; <a href="#L57" title="commands/vacuumparallel.c:57">PVShared</a>&nbsp;&nbsp; *shared;<br/></li>
<li>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a>&nbsp;&nbsp; *dead_items;<br/></li>
<li>&nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats;<br/></li>
<li>&nbsp; &nbsp; BufferUsage *buffer_usage;<br/></li>
<li>&nbsp; &nbsp; WalUsage&nbsp;&nbsp; *wal_usage;<br/></li>
<li>&nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>&nbsp; &nbsp; &nbsp;&nbsp; *will_parallel_vacuum;<br/></li>
<li>&nbsp; &nbsp; Size&nbsp; &nbsp; &nbsp; &nbsp; est_indstats_len;<br/></li>
<li>&nbsp; &nbsp; Size&nbsp; &nbsp; &nbsp; &nbsp; est_shared_len;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_mwm = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; parallel_workers = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; querylen;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * A parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> must be requested and there must be indexes on the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * relation<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Assert(nrequested_workers &gt;= <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; Assert(nindexes &gt; <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Compute the number of parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers to launch<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; will_parallel_vacuum = (<span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> *) <a href="../utils/mmgr/mcxt.c.html#L1346" title="utils/mmgr/mcxt.c:1346">palloc0</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span>) * nindexes);<br/></li>
<li>&nbsp; &nbsp; parallel_workers = <a href="#L548" title="commands/vacuumparallel.c:548">parallel_vacuum_compute_workers</a>(indrels, nindexes,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; nrequested_workers,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; will_parallel_vacuum);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (parallel_workers &lt;= <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Can't perform <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> in parallel -- return NULL */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(will_parallel_vacuum);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; pvs = (<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *) <a href="../utils/mmgr/mcxt.c.html#L1346" title="utils/mmgr/mcxt.c:1346">palloc0</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a>));<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;indrels = indrels;<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;nindexes = nindexes;<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;will_parallel_vacuum = will_parallel_vacuum;<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;bstrategy = bstrategy;<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;heaprel = rel;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../access/transam/xact.c.html#L1048" title="access/transam/xact.c:1048">EnterParallelMode</a>();<br/></li>
<li>&nbsp; &nbsp; pcxt = <a href="../access/transam/parallel.c.html#L167" title="access/transam/parallel.c:167">CreateParallelContext</a>(<span class="Constant">&quot;postgres&quot;</span>, <span class="Constant">&quot;<a href="#L988" title="commands/vacuumparallel.c:988">parallel_vacuum_main</a>&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; parallel_workers);<br/></li>
<li>&nbsp; &nbsp; Assert(pcxt-&gt;nworkers &gt; <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;pcxt = pcxt;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Estimate size for index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> stats -- <a href="#L51" title="commands/vacuumparallel.c:51">PARALLEL_VACUUM_KEY_INDEX_STATS</a> */<br/></li>
<li></span>&nbsp; &nbsp; est_indstats_len = <a href="../storage/ipc/shmem.c.html#L510" title="storage/ipc/shmem.c:510">mul_size</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a>), nindexes);<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, est_indstats_len);<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Estimate size for shared information -- <a href="#L47" title="commands/vacuumparallel.c:47">PARALLEL_VACUUM_KEY_SHARED</a> */<br/></li>
<li></span>&nbsp; &nbsp; est_shared_len = <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(<a href="#L57" title="commands/vacuumparallel.c:57">PVShared</a>);<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, est_shared_len);<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Estimate space for BufferUsage and WalUsage --<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="#L49" title="commands/vacuumparallel.c:49">PARALLEL_VACUUM_KEY_BUFFER_USAGE</a> and <a href="#L50" title="commands/vacuumparallel.c:50">PARALLEL_VACUUM_KEY_WAL_USAGE</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * If there are no extensions loaded that care, we could <a href="../regex/regc_lex.c.html#L982" title="regex/regc_lex.c:982">skip</a> this.&nbsp; We<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * have no way of knowing whether anyone's looking at <a href="../executor/instrument.c.html#L20" title="executor/instrument.c:20">pgBufferUsage</a> or<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../executor/instrument.c.html#L22" title="executor/instrument.c:22">pgWalUsage</a>, so do it unconditionally.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/shmem.c.html#L510" title="storage/ipc/shmem.c:510">mul_size</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(BufferUsage), pcxt-&gt;nworkers));<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/shmem.c.html#L510" title="storage/ipc/shmem.c:510">mul_size</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(WalUsage), pcxt-&gt;nworkers));<br/></li>
<li>&nbsp; &nbsp; shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Finally, estimate <a href="#L48" title="commands/vacuumparallel.c:48">PARALLEL_VACUUM_KEY_QUERY_TEXT</a> space */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; querylen = strlen(<a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, querylen + <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; querylen = <span class="Constant">0</span>;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* keep compiler quiet */<br/></li>
<li></span><br/></li>
<li>&nbsp; &nbsp; <a href="../access/transam/parallel.c.html#L205" title="access/transam/parallel.c:205">InitializeParallelDSM</a>(pcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Prepare index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> stats */<br/></li>
<li></span>&nbsp; &nbsp; indstats = (<a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *) <a href="../storage/ipc/shm_toc.c.html#L88" title="storage/ipc/shm_toc.c:88">shm_toc_allocate</a>(pcxt-&gt;toc, est_indstats_len);<br/></li>
<li>&nbsp; &nbsp; MemSet(indstats, <span class="Constant">0</span>, est_indstats_len);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; nindexes; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Relation&nbsp; &nbsp; indrel = indrels[i];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; uint8&nbsp; &nbsp; &nbsp; &nbsp; vacoptions = indrel-&gt;rd_indam-&gt;amparallelvacuumoptions;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Cleanup option should be either disabled, always performing in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * parallel or conditionally performing in parallel.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; Assert(((vacoptions &amp; VACUUM_OPTION_PARALLEL_CLEANUP) == <span class="Constant">0</span>) ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; ((vacoptions &amp; VACUUM_OPTION_PARALLEL_COND_CLEANUP) == <span class="Constant">0</span>));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(vacoptions &lt;= VACUUM_OPTION_MAX_VALID_VALUE);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (!will_parallel_vacuum[i])<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">continue</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (indrel-&gt;rd_indam-&gt;amusemaintenanceworkmem)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_mwm++;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Remember the number of indexes that support parallel operation for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * each phase.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> ((vacoptions &amp; VACUUM_OPTION_PARALLEL_BULKDEL) != <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pvs-&gt;nindexes_parallel_bulkdel++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> ((vacoptions &amp; VACUUM_OPTION_PARALLEL_CLEANUP) != <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pvs-&gt;nindexes_parallel_cleanup++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> ((vacoptions &amp; VACUUM_OPTION_PARALLEL_COND_CLEANUP) != <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pvs-&gt;nindexes_parallel_condcleanup++;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L171" title="storage/ipc/shm_toc.c:171">shm_toc_insert</a>(pcxt-&gt;toc, <a href="#L51" title="commands/vacuumparallel.c:51">PARALLEL_VACUUM_KEY_INDEX_STATS</a>, indstats);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;indstats = indstats;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Prepare shared information */<br/></li>
<li></span>&nbsp; &nbsp; shared = (<a href="#L57" title="commands/vacuumparallel.c:57">PVShared</a> *) <a href="../storage/ipc/shm_toc.c.html#L88" title="storage/ipc/shm_toc.c:88">shm_toc_allocate</a>(pcxt-&gt;toc, est_shared_len);<br/></li>
<li>&nbsp; &nbsp; MemSet(shared, <span class="Constant">0</span>, est_shared_len);<br/></li>
<li>&nbsp; &nbsp; shared-&gt;relid = RelationGetRelid(rel);<br/></li>
<li>&nbsp; &nbsp; shared-&gt;elevel = elevel;<br/></li>
<li>&nbsp; &nbsp; shared-&gt;maintenance_work_mem_worker =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; (nindexes_mwm &gt; <span class="Constant">0</span>) ?<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/init/globals.c.html#L130" title="utils/init/globals.c:130">maintenance_work_mem</a> / <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(parallel_workers, nindexes_mwm) :<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/init/globals.c.html#L130" title="utils/init/globals.c:130">maintenance_work_mem</a>;<br/></li>
<li>&nbsp; &nbsp; shared-&gt;dead_items_info.max_bytes = vac_work_mem * <span class="Constant">1024L</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Prepare DSA space for dead items */<br/></li>
<li></span>&nbsp; &nbsp; dead_items = <a href="../access/common/tidstore.c.html#L213" title="access/common/tidstore.c:213">TidStoreCreateShared</a>(shared-&gt;dead_items_info.max_bytes,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LWTRANCHE_PARALLEL_VACUUM_DSA);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;dead_items = dead_items;<br/></li>
<li>&nbsp; &nbsp; shared-&gt;dead_items_handle = <a href="../access/common/tidstore.c.html#L571" title="access/common/tidstore.c:571">TidStoreGetHandle</a>(dead_items);<br/></li>
<li>&nbsp; &nbsp; shared-&gt;dead_items_dsa_handle = <a href="../utils/mmgr/dsa.c.html#L498" title="utils/mmgr/dsa.c:498">dsa_get_handle</a>(<a href="../access/common/tidstore.c.html#L563" title="access/common/tidstore.c:563">TidStoreGetDSA</a>(dead_items));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Use the same buffer size for all workers */<br/></li>
<li></span>&nbsp; &nbsp; shared-&gt;ring_nbuffers = <a href="../storage/buffer/freelist.c.html#L624" title="storage/buffer/freelist.c:624">GetAccessStrategyBufferCount</a>(bstrategy);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; pg_atomic_init_u32(&amp;(shared-&gt;cost_balance), <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; pg_atomic_init_u32(&amp;(shared-&gt;active_nworkers), <span class="Constant">0</span>);<br/></li>
<li>&nbsp; &nbsp; pg_atomic_init_u32(&amp;(shared-&gt;idx), <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L171" title="storage/ipc/shm_toc.c:171">shm_toc_insert</a>(pcxt-&gt;toc, <a href="#L47" title="commands/vacuumparallel.c:47">PARALLEL_VACUUM_KEY_SHARED</a>, shared);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;shared = shared;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Allocate space for each worker's BufferUsage and WalUsage; no need to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="../regex/rege_dfa.c.html#L731" title="regex/rege_dfa.c:731">initialize</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; buffer_usage = <a href="../storage/ipc/shm_toc.c.html#L88" title="storage/ipc/shm_toc.c:88">shm_toc_allocate</a>(pcxt-&gt;toc,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/shmem.c.html#L510" title="storage/ipc/shmem.c:510">mul_size</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(BufferUsage), pcxt-&gt;nworkers));<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L171" title="storage/ipc/shm_toc.c:171">shm_toc_insert</a>(pcxt-&gt;toc, <a href="#L49" title="commands/vacuumparallel.c:49">PARALLEL_VACUUM_KEY_BUFFER_USAGE</a>, buffer_usage);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;buffer_usage = buffer_usage;<br/></li>
<li>&nbsp; &nbsp; wal_usage = <a href="../storage/ipc/shm_toc.c.html#L88" title="storage/ipc/shm_toc.c:88">shm_toc_allocate</a>(pcxt-&gt;toc,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="../storage/ipc/shmem.c.html#L510" title="storage/ipc/shmem.c:510">mul_size</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(WalUsage), pcxt-&gt;nworkers));<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L171" title="storage/ipc/shm_toc.c:171">shm_toc_insert</a>(pcxt-&gt;toc, <a href="#L50" title="commands/vacuumparallel.c:50">PARALLEL_VACUUM_KEY_WAL_USAGE</a>, wal_usage);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;wal_usage = wal_usage;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Store query string for workers */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp;&nbsp; *sharedquery;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; sharedquery = (<span class="Type">char</span> *) <a href="../storage/ipc/shm_toc.c.html#L88" title="storage/ipc/shm_toc.c:88">shm_toc_allocate</a>(pcxt-&gt;toc, querylen + <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; memcpy(sharedquery, <a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a>, querylen + <span class="Constant">1</span>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; sharedquery[querylen] = <span class="Special">'\0'</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../storage/ipc/shm_toc.c.html#L171" title="storage/ipc/shm_toc.c:171">shm_toc_insert</a>(pcxt-&gt;toc,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="#L48" title="commands/vacuumparallel.c:48">PARALLEL_VACUUM_KEY_QUERY_TEXT</a>, sharedquery);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Success -- return parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> state */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">return</span> pvs;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Destroy the parallel context, and end parallel mode.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Since writes are not allowed during parallel mode, copy the<br/></li>
<li></span><span class="Comment"> * updated index statistics from DSM into local memory and then later use that<br/></li>
<li></span><span class="Comment"> * to update the index statistics.&nbsp; One might think that we can exit from<br/></li>
<li></span><span class="Comment"> * parallel mode, update the index statistics and then destroy parallel<br/></li>
<li></span><span class="Comment"> * context, but that won't be safe (see <a href="../access/transam/xact.c.html#L1061" title="access/transam/xact.c:1061">ExitParallelMode</a>).<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L434">&#x200c;</a></span><span class="linkable">parallel_vacuum_end</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, IndexBulkDeleteResult **istats)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; Assert(!IsParallelWorker());<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Copy the updated statistics */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; pvs-&gt;nindexes; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats = &amp;(pvs-&gt;indstats[i]);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (indstats-&gt;istat_updated)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; istats[i] = (IndexBulkDeleteResult *) <a href="../utils/mmgr/mcxt.c.html#L1346" title="utils/mmgr/mcxt.c:1346">palloc0</a>(<span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(IndexBulkDeleteResult));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; memcpy(istats[i], &amp;indstats-&gt;istat, <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(IndexBulkDeleteResult));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; istats[i] = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L328" title="access/common/tidstore.c:328">TidStoreDestroy</a>(pvs-&gt;dead_items);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../access/transam/parallel.c.html#L929" title="access/transam/parallel.c:929">DestroyParallelContext</a>(pvs-&gt;pcxt);<br/></li>
<li>&nbsp; &nbsp; <a href="../access/transam/xact.c.html#L1061" title="access/transam/xact.c:1061">ExitParallelMode</a>();<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(pvs-&gt;will_parallel_vacuum);<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(pvs);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Returns the dead items space and dead items information.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a> *<br/></li>
<li><a id="L465">&#x200c;</a><span class="linkable">parallel_vacuum_get_dead_items</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, VacDeadItemsInfo **dead_items_info_p)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; *dead_items_info_p = &amp;(pvs-&gt;shared-&gt;dead_items_info);<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> pvs-&gt;dead_items;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/* Forget all items in dead_items */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L473">&#x200c;</a></span><span class="linkable">parallel_vacuum_reset_dead_items</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a>&nbsp;&nbsp; *dead_items = pvs-&gt;dead_items;<br/></li>
<li>&nbsp; &nbsp; VacDeadItemsInfo *dead_items_info = &amp;(pvs-&gt;shared-&gt;dead_items_info);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Free the current tidstore and return allocated DSA segments to the<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * operating system. Then we recreate the tidstore with the same max_bytes<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * limitation we just used.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L328" title="access/common/tidstore.c:328">TidStoreDestroy</a>(dead_items);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;dead_items = <a href="../access/common/tidstore.c.html#L213" title="access/common/tidstore.c:213">TidStoreCreateShared</a>(dead_items_info-&gt;max_bytes,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; LWTRANCHE_PARALLEL_VACUUM_DSA);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Update the DSA pointer for dead_items to the new one */<br/></li>
<li></span>&nbsp; &nbsp; pvs-&gt;shared-&gt;dead_items_dsa_handle = <a href="../utils/mmgr/dsa.c.html#L498" title="utils/mmgr/dsa.c:498">dsa_get_handle</a>(<a href="../access/common/tidstore.c.html#L563" title="access/common/tidstore.c:563">TidStoreGetDSA</a>(dead_items));<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;shared-&gt;dead_items_handle = <a href="../access/common/tidstore.c.html#L571" title="access/common/tidstore.c:571">TidStoreGetHandle</a>(dead_items);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Reset the counter */<br/></li>
<li></span>&nbsp; &nbsp; dead_items_info-&gt;num_items = <span class="Constant">0</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Do parallel index bulk-deletion with parallel workers.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L499">&#x200c;</a></span><span class="linkable">parallel_vacuum_bulkdel_all_indexes</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, <span class="Type">long</span> num_table_tuples,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> num_index_scans)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; Assert(!IsParallelWorker());<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We can only provide an approximate value of num_heap_tuples, at least<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * for <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; pvs-&gt;shared-&gt;reltuples = num_table_tuples;<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;shared-&gt;estimated_count = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="#L610" title="commands/vacuumparallel.c:610">parallel_vacuum_process_all_indexes</a>(pvs, num_index_scans, <span class="Constant">true</span>);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Do parallel index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> with parallel workers.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L518">&#x200c;</a></span><span class="linkable">parallel_vacuum_cleanup_all_indexes</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, <span class="Type">long</span> num_table_tuples,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span> num_index_scans, <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> estimated_count)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; Assert(!IsParallelWorker());<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We can provide a better estimate of total number of surviving tuples<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * (we assume indexes are more interested in that than in the number of<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * nominally live tuples).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; pvs-&gt;shared-&gt;reltuples = num_table_tuples;<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;shared-&gt;estimated_count = estimated_count;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="#L610" title="commands/vacuumparallel.c:610">parallel_vacuum_process_all_indexes</a>(pvs, num_index_scans, <span class="Constant">false</span>);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Compute the number of parallel worker processes to request.&nbsp; Both index<br/></li>
<li></span><span class="Comment"> * <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> and index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> can be executed with parallel workers.<br/></li>
<li></span><span class="Comment"> * The index is eligible for parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> iff its size is greater than<br/></li>
<li></span><span class="Comment"> * <a href="../optimizer/path/allpaths.c.html#L82" title="optimizer/path/allpaths.c:82">min_parallel_index_scan_size</a> as invoking workers for very small indexes<br/></li>
<li></span><span class="Comment"> * can hurt performance.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * nrequested is the number of parallel workers that user requested.&nbsp; If<br/></li>
<li></span><span class="Comment"> * nrequested is 0, we compute the parallel degree based on nindexes, that is<br/></li>
<li></span><span class="Comment"> * the number of indexes that support parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.&nbsp; This function also<br/></li>
<li></span><span class="Comment"> * sets will_parallel_vacuum to remember indexes that participate in parallel<br/></li>
<li></span><span class="Comment"> * <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">int<br/></li>
<li><a id="L548">&#x200c;</a></span><span class="linkable">parallel_vacuum_compute_workers</span>(Relation *indrels, <span class="Type">int</span> nindexes, <span class="Type">int</span> nrequested,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> *will_parallel_vacuum)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_bulkdel = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_cleanup = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; parallel_workers;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We don't allow performing parallel operation in standalone backend or<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * when parallelism is disabled.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!<a href="../utils/init/globals.c.html#L117" title="utils/init/globals.c:117">IsUnderPostmaster</a> || <a href="../utils/init/globals.c.html#L131" title="utils/init/globals.c:131">max_parallel_maintenance_workers</a> == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Compute the number of indexes that can participate in parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; nindexes; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Relation&nbsp; &nbsp; indrel = indrels[i];<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; uint8&nbsp; &nbsp; &nbsp; &nbsp; vacoptions = indrel-&gt;rd_indam-&gt;amparallelvacuumoptions;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Skip index that is not a suitable target for parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (vacoptions == VACUUM_OPTION_NO_PARALLEL ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RelationGetNumberOfBlocks(indrel) &lt; <a href="../optimizer/path/allpaths.c.html#L82" title="optimizer/path/allpaths.c:82">min_parallel_index_scan_size</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">continue</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; will_parallel_vacuum[i] = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> ((vacoptions &amp; VACUUM_OPTION_PARALLEL_BULKDEL) != <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_bulkdel++;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (((vacoptions &amp; VACUUM_OPTION_PARALLEL_CLEANUP) != <span class="Constant">0</span>) ||<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ((vacoptions &amp; VACUUM_OPTION_PARALLEL_COND_CLEANUP) != <span class="Constant">0</span>))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_cleanup++;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; nindexes_parallel = Max(nindexes_parallel_bulkdel,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes_parallel_cleanup);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* The leader process takes one index */<br/></li>
<li></span>&nbsp; &nbsp; nindexes_parallel--;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* No index supports parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (nindexes_parallel &lt;= <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Compute the parallel degree */<br/></li>
<li></span>&nbsp; &nbsp; parallel_workers = (nrequested &gt; <span class="Constant">0</span>) ?<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(nrequested, nindexes_parallel) : nindexes_parallel;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Cap by <a href="../utils/init/globals.c.html#L131" title="utils/init/globals.c:131">max_parallel_maintenance_workers</a> */<br/></li>
<li></span>&nbsp; &nbsp; parallel_workers = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(parallel_workers, <a href="../utils/init/globals.c.html#L131" title="utils/init/globals.c:131">max_parallel_maintenance_workers</a>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> parallel_workers;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Perform index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> with parallel workers.&nbsp; This function<br/></li>
<li></span><span class="Comment"> * must be used by the parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> leader process.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L610">&#x200c;</a></span><span class="linkable">parallel_vacuum_process_all_indexes</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, <span class="Type">int</span> num_index_scans,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nworkers;<br/></li>
<li>&nbsp; &nbsp; <a href="#L124" title="commands/vacuumparallel.c:124">PVIndVacStatus</a> new_status;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; Assert(!IsParallelWorker());<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; new_status = PARALLEL_INDVAC_STATUS_NEED_BULKDELETE;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Determine the number of parallel workers to launch */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; nworkers = pvs-&gt;nindexes_parallel_bulkdel;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>&nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; new_status = PARALLEL_INDVAC_STATUS_NEED_CLEANUP;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Determine the number of parallel workers to launch */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; nworkers = pvs-&gt;nindexes_parallel_cleanup;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Add conditionally parallel-aware indexes if in the first time call */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (num_index_scans == <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nworkers += pvs-&gt;nindexes_parallel_condcleanup;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* The leader process will participate */<br/></li>
<li></span>&nbsp; &nbsp; nworkers--;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * It is possible that parallel context is initialized with fewer workers<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * than the number of indexes that need a separate worker in the current<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * phase, so we need to consider it.&nbsp; See<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="#L548" title="commands/vacuumparallel.c:548">parallel_vacuum_compute_workers</a>().<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; nworkers = <a href="../jit/llvm/llvmjit_inline.cpp.html#L46" title="jit/llvm/llvmjit_inline.cpp:46">Min</a>(nworkers, pvs-&gt;pcxt-&gt;nworkers);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Set index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> status and mark whether parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker can<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * process it.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; pvs-&gt;nindexes; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats = &amp;(pvs-&gt;indstats[i]);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; Assert(indstats-&gt;status == PARALLEL_INDVAC_STATUS_INITIAL);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; indstats-&gt;status = new_status;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; indstats-&gt;parallel_workers_can_process =<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (pvs-&gt;will_parallel_vacuum[i] &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="#L950" title="commands/vacuumparallel.c:950">parallel_vacuum_index_is_parallel_safe</a>(pvs-&gt;indrels[i],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_index_scans,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>));<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Reset the parallel index processing and progress counters */<br/></li>
<li></span>&nbsp; &nbsp; pg_atomic_write_u32(&amp;(pvs-&gt;shared-&gt;idx), <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Setup the shared cost-based <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> delay and launch workers */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (nworkers &gt; <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Reinitialize parallel context to relaunch parallel workers */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (num_index_scans &gt; <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/transam/parallel.c.html#L488" title="access/transam/parallel.c:488">ReinitializeParallelDSM</a>(pvs-&gt;pcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Set up shared cost balance and the number of active workers for<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> delay.&nbsp; We need to do this <a href="../regex/regc_locale.c.html#L488" title="regex/regc_locale.c:488">before</a> launching workers as<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * otherwise, they might not see the updated <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a> for these<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * parameters.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; pg_atomic_write_u32(&amp;(pvs-&gt;shared-&gt;cost_balance), <a href="../utils/init/globals.c.html#L158" title="utils/init/globals.c:158">VacuumCostBalance</a>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pg_atomic_write_u32(&amp;(pvs-&gt;shared-&gt;active_nworkers), <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * The number of workers can vary between bulkdelete and <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a><br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * phase.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/transam/parallel.c.html#L538" title="access/transam/parallel.c:538">ReinitializeParallelWorkers</a>(pvs-&gt;pcxt, nworkers);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/transam/parallel.c.html#L552" title="access/transam/parallel.c:552">LaunchParallelWorkers</a>(pvs-&gt;pcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (pvs-&gt;pcxt-&gt;nworkers_launched &gt; <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Reset the local cost <a href="../bootstrap/bootstrap.c.html#L152" title="bootstrap/bootstrap.c:152">values</a> for leader backend as we have<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * already accumulated the remaining balance of heap.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/init/globals.c.html#L158" title="utils/init/globals.c:158">VacuumCostBalance</a> = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="vacuum.c.html#L104" title="commands/vacuum.c:104">VacuumCostBalanceLocal</a> = <span class="Constant">0</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Enable shared cost balance for leader backend */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="vacuum.c.html#L102" title="commands/vacuum.c:102">VacuumSharedCostBalance</a> = &amp;(pvs-&gt;shared-&gt;cost_balance);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a> = &amp;(pvs-&gt;shared-&gt;active_nworkers);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ereport(pvs-&gt;shared-&gt;elevel,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (<a href="../utils/error/elog.c.html#L1072" title="utils/error/elog.c:1072">errmsg</a>(ngettext(<span class="Constant">&quot;launched </span><span class="Special">%d</span><span class="Constant"> parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker for index vacuuming (planned: </span><span class="Special">%d</span><span class="Constant">)&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">&quot;launched </span><span class="Special">%d</span><span class="Constant"> parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers for index vacuuming (planned: </span><span class="Special">%d</span><span class="Constant">)&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; pvs-&gt;pcxt-&gt;nworkers_launched),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pvs-&gt;pcxt-&gt;nworkers_launched, nworkers)));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">else<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ereport(pvs-&gt;shared-&gt;elevel,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (<a href="../utils/error/elog.c.html#L1072" title="utils/error/elog.c:1072">errmsg</a>(ngettext(<span class="Constant">&quot;launched </span><span class="Special">%d</span><span class="Constant"> parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker for index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> (planned: </span><span class="Special">%d</span><span class="Constant">)&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">&quot;launched </span><span class="Special">%d</span><span class="Constant"> parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers for index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> (planned: </span><span class="Special">%d</span><span class="Constant">)&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; pvs-&gt;pcxt-&gt;nworkers_launched),<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pvs-&gt;pcxt-&gt;nworkers_launched, nworkers)));<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Vacuum the indexes that can be processed by only leader process */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L827" title="commands/vacuumparallel.c:827">parallel_vacuum_process_unsafe_indexes</a>(pvs);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Join as a parallel worker.&nbsp; The leader vacuums alone processes all<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parallel-safe indexes in the case where no workers are launched.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L773" title="commands/vacuumparallel.c:773">parallel_vacuum_process_safe_indexes</a>(pvs);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Next, accumulate buffer and WAL usage.&nbsp; (This must wait for the workers<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * to finish, or we might get incomplete data.)<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (nworkers &gt; <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Wait for all <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers to finish */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../access/transam/parallel.c.html#L775" title="access/transam/parallel.c:775">WaitForParallelWorkersToFinish</a>(pvs-&gt;pcxt);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; pvs-&gt;pcxt-&gt;nworkers_launched; i++)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../executor/instrument.c.html#L218" title="executor/instrument.c:218">InstrAccumParallelQuery</a>(&amp;pvs-&gt;buffer_usage[i], &amp;pvs-&gt;wal_usage[i]);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Reset all index status back to initial (while checking that we have<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * vacuumed all indexes).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; pvs-&gt;nindexes; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats = &amp;(pvs-&gt;indstats[i]);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (indstats-&gt;status != PARALLEL_INDVAC_STATUS_COMPLETED)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elog(ERROR, <span class="Constant">&quot;parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> on index </span><span class="Special">\&quot;%s\&quot;</span><span class="Constant"> is not completed&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; RelationGetRelationName(pvs-&gt;indrels[i]));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; indstats-&gt;status = PARALLEL_INDVAC_STATUS_INITIAL;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Carry the shared balance value to heap scan and disable shared costing<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L102" title="commands/vacuum.c:102">VacuumSharedCostBalance</a>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/init/globals.c.html#L158" title="utils/init/globals.c:158">VacuumCostBalance</a> = pg_atomic_read_u32(<a href="vacuum.c.html#L102" title="commands/vacuum.c:102">VacuumSharedCostBalance</a>);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="vacuum.c.html#L102" title="commands/vacuum.c:102">VacuumSharedCostBalance</a> = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a> = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>/<a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> routine used by the leader process and parallel<br/></li>
<li></span><span class="Comment"> * <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker processes to <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> the indexes in parallel.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L773">&#x200c;</a></span><span class="linkable">parallel_vacuum_process_safe_indexes</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Increment the active worker count if we are able to launch <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> worker.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pg_atomic_add_fetch_u32(<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>, <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Loop until all indexes are vacuumed */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">for</span> (;;)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; idx;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Get an index number to process */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; idx = pg_atomic_fetch_add_u32(&amp;(pvs-&gt;shared-&gt;idx), <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Done for all indexes? */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (idx &gt;= pvs-&gt;nindexes)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; indstats = &amp;(pvs-&gt;indstats[idx]);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * Skip vacuuming index that is unsafe for workers or has an<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * unsuitable target for parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> (this is vacuumed in<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; * <a href="#L827" title="commands/vacuumparallel.c:827">parallel_vacuum_process_unsafe_indexes</a>() by the leader).<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (!indstats-&gt;parallel_workers_can_process)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">continue</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Do <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> of the index */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L864" title="commands/vacuumparallel.c:864">parallel_vacuum_process_one_index</a>(pvs, pvs-&gt;indrels[idx], indstats);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We have completed the index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> so decrement the active worker<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * count.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pg_atomic_sub_fetch_u32(<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>, <span class="Constant">1</span>);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Perform parallel vacuuming of indexes in leader process.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Handles index vacuuming (or index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>) for indexes that are not<br/></li>
<li></span><span class="Comment"> * parallel safe.&nbsp; It's possible that this will vary for a given index, based<br/></li>
<li></span><span class="Comment"> * on details like whether we're performing index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> right <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a>.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Also performs vacuuming of smaller indexes that fell under the size cutoff<br/></li>
<li></span><span class="Comment"> * enforced by <a href="#L548" title="commands/vacuumparallel.c:548">parallel_vacuum_compute_workers</a>().<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L827">&#x200c;</a></span><span class="linkable">parallel_vacuum_process_unsafe_indexes</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; Assert(!IsParallelWorker());<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Increment the active worker count if we are able to launch <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> worker.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pg_atomic_add_fetch_u32(<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>, <span class="Constant">1</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; pvs-&gt;nindexes; i++)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats = &amp;(pvs-&gt;indstats[i]);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Skip, indexes that are safe for workers */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">if</span> (indstats-&gt;parallel_workers_can_process)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">continue</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Do <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> of the index */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L864" title="commands/vacuumparallel.c:864">parallel_vacuum_process_one_index</a>(pvs, pvs-&gt;indrels[i], indstats);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * We have completed the index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> so decrement the active worker<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * count.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; pg_atomic_sub_fetch_u32(<a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a>, <span class="Constant">1</span>);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Vacuum or <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> index either by leader process or by one of the worker<br/></li>
<li></span><span class="Comment"> * process.&nbsp; After vacuuming the index this function copies the index<br/></li>
<li></span><span class="Comment"> * statistics returned from ambulkdelete and amvacuumcleanup to the DSM<br/></li>
<li></span><span class="Comment"> * segment.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L864">&#x200c;</a></span><span class="linkable">parallel_vacuum_process_one_index</span>(<a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *pvs, Relation indrel,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; IndexBulkDeleteResult *istat = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; IndexBulkDeleteResult *istat_res;<br/></li>
<li>&nbsp; &nbsp; IndexVacuumInfo ivinfo;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Update the pointer to the corresponding bulk-deletion result if someone<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * has already updated it<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (indstats-&gt;istat_updated)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; istat = &amp;(indstats-&gt;istat);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; ivinfo.index = indrel;<br/></li>
<li>&nbsp; &nbsp; ivinfo.heaprel = pvs-&gt;heaprel;<br/></li>
<li>&nbsp; &nbsp; ivinfo.analyze_only = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; ivinfo.report_progress = <span class="Constant">false</span>;<br/></li>
<li>&nbsp; &nbsp; ivinfo.message_level = DEBUG2;<br/></li>
<li>&nbsp; &nbsp; ivinfo.estimated_count = pvs-&gt;shared-&gt;estimated_count;<br/></li>
<li>&nbsp; &nbsp; ivinfo.num_heap_tuples = pvs-&gt;shared-&gt;reltuples;<br/></li>
<li>&nbsp; &nbsp; ivinfo.strategy = pvs-&gt;bstrategy;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Update error traceback information */<br/></li>
<li></span>&nbsp; &nbsp; pvs-&gt;indname = <a href="../utils/mmgr/mcxt.c.html#L1695" title="utils/mmgr/mcxt.c:1695">pstrdup</a>(RelationGetRelationName(indrel));<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;status = indstats-&gt;status;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">switch</span> (indstats-&gt;status)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PARALLEL_INDVAC_STATUS_NEED_BULKDELETE:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; istat_res = <a href="vacuum.c.html#L2490" title="commands/vacuum.c:2490">vac_bulkdel_one_index</a>(&amp;ivinfo, istat, pvs-&gt;dead_items,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;pvs-&gt;shared-&gt;dead_items_info);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PARALLEL_INDVAC_STATUS_NEED_CLEANUP:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; istat_res = <a href="vacuum.c.html#L2511" title="commands/vacuum.c:2511">vac_cleanup_one_index</a>(&amp;ivinfo, istat);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">default</span>:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elog(ERROR, <span class="Constant">&quot;unexpected parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> index status </span><span class="Special">%d</span><span class="Constant"> for index </span><span class="Special">\&quot;%s\&quot;</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; indstats-&gt;status,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; RelationGetRelationName(indrel));<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Copy the index bulk-deletion result returned from ambulkdelete and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * amvacuumcleanup to the DSM segment if it's the first cycle because they<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * allocate locally and it's possible that an index will be vacuumed by a<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * different <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> process the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> cycle.&nbsp; Copying the result normally<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * happens only the first time an index is vacuumed.&nbsp; For <a href="../utils/adt/pseudotypes.c.html#L365" title="utils/adt/pseudotypes.c:365">any</a> additional<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> pass, we directly point to the result on the DSM segment and<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * pass it to <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> index APIs so that workers can update it directly.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; *<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Since all <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers write the bulk-deletion result at different<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * slots we can write them without locking.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (!indstats-&gt;istat_updated &amp;&amp; istat_res != <span class="Constant">NULL</span>)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; memcpy(&amp;(indstats-&gt;istat), istat_res, <span class="Statement"><a href="../storage/page/itemptr.c.html#L23" title="storage/page/itemptr.c:23">sizeof</a></span>(IndexBulkDeleteResult));<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; indstats-&gt;istat_updated = <span class="Constant">true</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Comment">/* Free the locally-allocated bulk-deletion result */<br/></li>
<li></span>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(istat_res);<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Update the status to completed. No need to lock here since each worker<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * touches different indexes.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; indstats-&gt;status = PARALLEL_INDVAC_STATUS_COMPLETED;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Reset error traceback information */<br/></li>
<li></span>&nbsp; &nbsp; pvs-&gt;status = PARALLEL_INDVAC_STATUS_COMPLETED;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/mmgr/mcxt.c.html#L1520" title="utils/mmgr/mcxt.c:1520">pfree</a>(pvs-&gt;indname);<br/></li>
<li>&nbsp; &nbsp; pvs-&gt;indname = <span class="Constant">NULL</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Call the parallel variant of <a href="../utils/activity/backend_progress.c.html#L70" title="utils/activity/backend_progress.c:70">pgstat_progress_incr_param</a> so workers can<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * report progress of index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> to the leader.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../utils/activity/backend_progress.c.html#L92" title="utils/activity/backend_progress.c:92">pgstat_progress_parallel_incr_param</a>(PROGRESS_VACUUM_INDEXES_PROCESSED, <span class="Constant">1</span>);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Returns false, if the given index can't participate in the <a href="../regex/regc_lex.c.html#L200" title="regex/regc_lex.c:200">next</a> execution of<br/></li>
<li></span><span class="Comment"> * parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or parallel index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a><br/></li>
<li><a id="L950">&#x200c;</a></span><span class="linkable">parallel_vacuum_index_is_parallel_safe</span>(Relation indrel, <span class="Type">int</span> num_index_scans,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Type"><a href="../utils/fmgr/dfmgr.c.html#L28" title="utils/fmgr/dfmgr.c:28">bool</a></span> <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; uint8&nbsp; &nbsp; &nbsp; &nbsp; vacoptions;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; vacoptions = indrel-&gt;rd_indam-&gt;amparallelvacuumoptions;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* In parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> case, check if it supports parallel bulk-deletion */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (<a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> ((vacoptions &amp; VACUUM_OPTION_PARALLEL_BULKDEL) != <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Not safe, if the index does not support parallel <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (((vacoptions &amp; VACUUM_OPTION_PARALLEL_CLEANUP) == <span class="Constant">0</span>) &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ((vacoptions &amp; VACUUM_OPTION_PARALLEL_COND_CLEANUP) == <span class="Constant">0</span>))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Not safe, if the index supports parallel <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> conditionally, but we<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * have already processed the index (for bulkdelete).&nbsp; We do this to avoid<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * the need to invoke workers when parallel index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> doesn't need to<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * scan the index.&nbsp; See the comments for option<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * VACUUM_OPTION_PARALLEL_COND_CLEANUP to know when indexes support<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * parallel <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> conditionally.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <span class="Statement">if</span> (num_index_scans &gt; <span class="Constant">0</span> &amp;&amp;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; ((vacoptions &amp; VACUUM_OPTION_PARALLEL_COND_CLEANUP) != <span class="Constant">0</span>))<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">false</span>;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">return</span> <span class="Constant">true</span>;<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Perform work within a launched parallel process.<br/></li>
<li></span><span class="Comment"> *<br/></li>
<li></span><span class="Comment"> * Since parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> workers perform only index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or index <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a>,<br/></li>
<li></span><span class="Comment"> * we don't need to report progress information.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">void<br/></li>
<li><a id="L988">&#x200c;</a></span><span class="linkable">parallel_vacuum_main</span>(<a href="../storage/ipc/dsm.c.html#L66" title="storage/ipc/dsm.c:66">dsm_segment</a> *seg, <a href="../storage/ipc/shm_toc.c.html#L26" title="storage/ipc/shm_toc.c:26">shm_toc</a> *toc)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> pvs;<br/></li>
<li>&nbsp; &nbsp; Relation&nbsp; &nbsp; rel;<br/></li>
<li>&nbsp; &nbsp; Relation&nbsp;&nbsp; *indrels;<br/></li>
<li>&nbsp; &nbsp; <a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *indstats;<br/></li>
<li>&nbsp; &nbsp; <a href="#L57" title="commands/vacuumparallel.c:57">PVShared</a>&nbsp;&nbsp; *shared;<br/></li>
<li>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L114" title="access/common/tidstore.c:114">TidStore</a>&nbsp;&nbsp; *dead_items;<br/></li>
<li>&nbsp; &nbsp; BufferUsage *buffer_usage;<br/></li>
<li>&nbsp; &nbsp; WalUsage&nbsp;&nbsp; *wal_usage;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">int</span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nindexes;<br/></li>
<li>&nbsp; &nbsp; <span class="Type">char</span>&nbsp; &nbsp; &nbsp;&nbsp; *sharedquery;<br/></li>
<li>&nbsp; &nbsp; ErrorContextCallback errcallback;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * A parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker must have only PROC_IN_VACUUM flag since we<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * don't support parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> for autovacuum as of <a href="../utils/adt/timestamp.c.html#L1618" title="utils/adt/timestamp.c:1618">now</a>.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; Assert(<a href="../storage/lmgr/proc.c.html#L66" title="storage/lmgr/proc.c:66">MyProc</a>-&gt;statusFlags == PROC_IN_VACUUM);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; elog(DEBUG1, <span class="Constant">&quot;starting parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> worker&quot;</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; shared = (<a href="#L57" title="commands/vacuumparallel.c:57">PVShared</a> *) <a href="../storage/ipc/shm_toc.c.html#L232" title="storage/ipc/shm_toc.c:232">shm_toc_lookup</a>(toc, <a href="#L47" title="commands/vacuumparallel.c:47">PARALLEL_VACUUM_KEY_SHARED</a>, <span class="Constant">false</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set <a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a> for individual workers */<br/></li>
<li></span>&nbsp; &nbsp; sharedquery = <a href="../storage/ipc/shm_toc.c.html#L232" title="storage/ipc/shm_toc.c:232">shm_toc_lookup</a>(toc, <a href="#L48" title="commands/vacuumparallel.c:48">PARALLEL_VACUUM_KEY_QUERY_TEXT</a>, <span class="Constant">true</span>);<br/></li>
<li>&nbsp; &nbsp; <a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a> = sharedquery;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/activity/backend_status.c.html#L503" title="utils/activity/backend_status.c:503">pgstat_report_activity</a>(STATE_RUNNING, <a href="../tcop/postgres.c.html#L87" title="tcop/postgres.c:87">debug_query_string</a>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Open table.&nbsp; The lock mode is the same as the leader process.&nbsp; It's<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * okay because the lock mode does not conflict among the parallel<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * workers.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; rel = <a href="../access/table/table.c.html#L40" title="access/table/table.c:40">table_open</a>(shared-&gt;relid, ShareUpdateExclusiveLock);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/*<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * Open all indexes. indrels are sorted in order by OID, which should be<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; * matched to the leader's one.<br/></li>
<li></span><span class="Comment">&nbsp; &nbsp;&nbsp; */<br/></li>
<li></span>&nbsp; &nbsp; <a href="vacuum.c.html#L2272" title="commands/vacuum.c:2272">vac_open_indexes</a>(rel, RowExclusiveLock, &amp;nindexes, &amp;indrels);<br/></li>
<li>&nbsp; &nbsp; Assert(nindexes &gt; <span class="Constant">0</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">if</span> (shared-&gt;maintenance_work_mem_worker &gt; <span class="Constant">0</span>)<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/init/globals.c.html#L130" title="utils/init/globals.c:130">maintenance_work_mem</a> = shared-&gt;maintenance_work_mem_worker;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set index statistics */<br/></li>
<li></span>&nbsp; &nbsp; indstats = (<a href="#L136" title="commands/vacuumparallel.c:136">PVIndStats</a> *) <a href="../storage/ipc/shm_toc.c.html#L232" title="storage/ipc/shm_toc.c:232">shm_toc_lookup</a>(toc,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <a href="#L51" title="commands/vacuumparallel.c:51">PARALLEL_VACUUM_KEY_INDEX_STATS</a>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; <span class="Constant">false</span>);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Find dead_items in shared memory */<br/></li>
<li></span>&nbsp; &nbsp; dead_items = <a href="../access/common/tidstore.c.html#L255" title="access/common/tidstore.c:255">TidStoreAttach</a>(shared-&gt;dead_items_dsa_handle,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; shared-&gt;dead_items_handle);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set cost-based <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> delay */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../postmaster/autovacuum.c.html#L1633" title="postmaster/autovacuum.c:1633">VacuumUpdateCosts</a>();<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/init/globals.c.html#L158" title="utils/init/globals.c:158">VacuumCostBalance</a> = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/init/globals.c.html#L154" title="utils/init/globals.c:154">VacuumPageHit</a> = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/init/globals.c.html#L155" title="utils/init/globals.c:155">VacuumPageMiss</a> = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/init/globals.c.html#L156" title="utils/init/globals.c:156">VacuumPageDirty</a> = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <a href="vacuum.c.html#L104" title="commands/vacuum.c:104">VacuumCostBalanceLocal</a> = <span class="Constant">0</span>;<br/></li>
<li>&nbsp; &nbsp; <a href="vacuum.c.html#L102" title="commands/vacuum.c:102">VacuumSharedCostBalance</a> = &amp;(shared-&gt;cost_balance);<br/></li>
<li>&nbsp; &nbsp; <a href="vacuum.c.html#L103" title="commands/vacuum.c:103">VacuumActiveNWorkers</a> = &amp;(shared-&gt;active_nworkers);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Set parallel <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> state */<br/></li>
<li></span>&nbsp; &nbsp; pvs.indrels = indrels;<br/></li>
<li>&nbsp; &nbsp; pvs.nindexes = nindexes;<br/></li>
<li>&nbsp; &nbsp; pvs.indstats = indstats;<br/></li>
<li>&nbsp; &nbsp; pvs.shared = shared;<br/></li>
<li>&nbsp; &nbsp; pvs.dead_items = dead_items;<br/></li>
<li>&nbsp; &nbsp; pvs.relnamespace = <a href="../utils/cache/lsyscache.c.html#L3366" title="utils/cache/lsyscache.c:3366">get_namespace_name</a>(RelationGetNamespace(rel));<br/></li>
<li>&nbsp; &nbsp; pvs.relname = <a href="../utils/mmgr/mcxt.c.html#L1695" title="utils/mmgr/mcxt.c:1695">pstrdup</a>(RelationGetRelationName(rel));<br/></li>
<li>&nbsp; &nbsp; pvs.heaprel = rel;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* These fields will be filled during index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a> or <a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> */<br/></li>
<li></span>&nbsp; &nbsp; pvs.indname = <span class="Constant">NULL</span>;<br/></li>
<li>&nbsp; &nbsp; pvs.status = PARALLEL_INDVAC_STATUS_INITIAL;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Each parallel VACUUM worker gets its own access strategy. */<br/></li>
<li></span>&nbsp; &nbsp; pvs.bstrategy = <a href="../storage/buffer/freelist.c.html#L584" title="storage/buffer/freelist.c:584">GetAccessStrategyWithSize</a>(BAS_VACUUM,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; shared-&gt;ring_nbuffers * (BLCKSZ / <span class="Constant">1024</span>));<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Setup error traceback support for ereport() */<br/></li>
<li></span>&nbsp; &nbsp; errcallback.callback = <a href="#L1106" title="commands/vacuumparallel.c:1106">parallel_vacuum_error_callback</a>;<br/></li>
<li>&nbsp; &nbsp; errcallback.arg = &amp;pvs;<br/></li>
<li>&nbsp; &nbsp; errcallback.previous = <a href="../utils/error/elog.c.html#L94" title="utils/error/elog.c:94">error_context_stack</a>;<br/></li>
<li>&nbsp; &nbsp; <a href="../utils/error/elog.c.html#L94" title="utils/error/elog.c:94">error_context_stack</a> = &amp;errcallback;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Prepare to track buffer usage during parallel execution */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../executor/instrument.c.html#L200" title="executor/instrument.c:200">InstrStartParallelQuery</a>();<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Process indexes to perform <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>/<a href="../regex/regc_nfa.c.html#L2929" title="regex/regc_nfa.c:2929">cleanup</a> */<br/></li>
<li></span>&nbsp; &nbsp; <a href="#L773" title="commands/vacuumparallel.c:773">parallel_vacuum_process_safe_indexes</a>(&amp;pvs);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Report buffer/WAL usage during parallel execution */<br/></li>
<li></span>&nbsp; &nbsp; buffer_usage = <a href="../storage/ipc/shm_toc.c.html#L232" title="storage/ipc/shm_toc.c:232">shm_toc_lookup</a>(toc, <a href="#L49" title="commands/vacuumparallel.c:49">PARALLEL_VACUUM_KEY_BUFFER_USAGE</a>, <span class="Constant">false</span>);<br/></li>
<li>&nbsp; &nbsp; wal_usage = <a href="../storage/ipc/shm_toc.c.html#L232" title="storage/ipc/shm_toc.c:232">shm_toc_lookup</a>(toc, <a href="#L50" title="commands/vacuumparallel.c:50">PARALLEL_VACUUM_KEY_WAL_USAGE</a>, <span class="Constant">false</span>);<br/></li>
<li>&nbsp; &nbsp; <a href="../executor/instrument.c.html#L208" title="executor/instrument.c:208">InstrEndParallelQuery</a>(&amp;buffer_usage[<a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a>],<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;wal_usage[<a href="../access/transam/parallel.c.html#L112" title="access/transam/parallel.c:112">ParallelWorkerNumber</a>]);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="../access/common/tidstore.c.html#L280" title="access/common/tidstore.c:280">TidStoreDetach</a>(dead_items);<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Comment">/* Pop the error context stack */<br/></li>
<li></span>&nbsp; &nbsp; <a href="../utils/error/elog.c.html#L94" title="utils/error/elog.c:94">error_context_stack</a> = errcallback.previous;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <a href="vacuum.c.html#L2315" title="commands/vacuum.c:2315">vac_close_indexes</a>(nindexes, indrels, RowExclusiveLock);<br/></li>
<li>&nbsp; &nbsp; <a href="../access/table/table.c.html#L126" title="access/table/table.c:126">table_close</a>(rel, ShareUpdateExclusiveLock);<br/></li>
<li>&nbsp; &nbsp; <a href="../storage/buffer/freelist.c.html#L681" title="storage/buffer/freelist.c:681">FreeAccessStrategy</a>(pvs.bstrategy);<br/></li>
<li>}<br/></li>
<li><br/></li>
<li><span class="Comment">/*<br/></li>
<li></span><span class="Comment"> * Error context callback for errors occurring during parallel index <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a>.<br/></li>
<li></span><span class="Comment"> * The error context messages should match the messages set in the lazy <a href="vacuum.c.html#L478" title="commands/vacuum.c:478">vacuum</a><br/></li>
<li></span><span class="Comment"> * error context.&nbsp; If you change this function, change <a href="../access/heap/vacuumlazy.c.html#L3099" title="access/heap/vacuumlazy.c:3099">vacuum_error_callback</a>()<br/></li>
<li></span><span class="Comment"> * as well.<br/></li>
<li></span><span class="Comment"> */<br/></li>
<li></span><span class="Type">static</span> <span class="Type">void<br/></li>
<li><a id="L1106">&#x200c;</a></span><span class="linkable">parallel_vacuum_error_callback</span>(<span class="Type">void</span> *arg)<br/></li>
<li>{<br/></li>
<li>&nbsp; &nbsp; <a href="#L161" title="commands/vacuumparallel.c:161">ParallelVacuumState</a> *errinfo = arg;<br/></li>
<li><br/></li>
<li>&nbsp; &nbsp; <span class="Statement">switch</span> (errinfo-&gt;status)<br/></li>
<li>&nbsp; &nbsp; {<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PARALLEL_INDVAC_STATUS_NEED_BULKDELETE:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; errcontext(<span class="Constant">&quot;while vacuuming index </span><span class="Special">\&quot;%s\&quot;</span><span class="Constant"> of relation </span><span class="Special">\&quot;%s</span><span class="Constant">.</span><span class="Special">%s\&quot;</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; errinfo-&gt;indname,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; errinfo-&gt;relnamespace,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; errinfo-&gt;relname);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PARALLEL_INDVAC_STATUS_NEED_CLEANUP:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; errcontext(<span class="Constant">&quot;while cleaning up index </span><span class="Special">\&quot;%s\&quot;</span><span class="Constant"> of relation </span><span class="Special">\&quot;%s</span><span class="Constant">.</span><span class="Special">%s\&quot;</span><span class="Constant">&quot;</span>,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; errinfo-&gt;indname,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; errinfo-&gt;relnamespace,<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; errinfo-&gt;relname);<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">break</span>;<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PARALLEL_INDVAC_STATUS_INITIAL:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">case</span> PARALLEL_INDVAC_STATUS_COMPLETED:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">default</span>:<br/></li>
<li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="Statement">return</span>;<br/></li>
<li>&nbsp; &nbsp; }<br/></li>
<li>}<br/></li>
</ol></code>
 <p class="nav-bar">
  <span class="nav-link"><a href="./index.html">One Level Up</a></span>
  <span class="nav-link"><a href="../index.html">Top Level</a></span>
 </p>

 </body>
</html>
